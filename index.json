[{"authors":["admin"],"categories":null,"content":"I am a postdoctoral researcher at the Zuse Institute Berlin, in the Mathematical Optimization Methods group and associated to the MODAL-SynLab project.\nI graduated with a double PhD (cotutelle) between École Polytechnique of Montréal, at the GERAD lab and Centrale Lille, at INRIA \u0026amp; the Cristal lab, in mathematical optimization.\nMy thesis, defended in December 2020, focuses on bilevel optimization, an extension coined near-optimality robustness, and pricing for demand response in smart grids. It was co-supervised by Luce Brotcorne (INRIA) \u0026amp; Miguel F. Anjos (University of Edinburgh).\nI am involved in several open-source projects around optimization and scientific computing in the Julia programming language and around JuMP but like looking around on new development in scientific programming. Before starting the PhD, I worked in various industries, from an IoT startup to steel manufacturing. I did my joint Bachelor-Master in Process Engineering at the UTC with a semester at the TUBS and Polytechnique Montreal.\nOn a personal note, I read both fiction (mostly detective, thrillers and fantasy) and non-fiction books, on economic policy, strategy, and entrepreneurship (a more detailed list can be found on goodread. I also enjoy games in various formats (tabletop, video, board, card) and cooking.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1613030432,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://matbesancon.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a postdoctoral researcher at the Zuse Institute Berlin, in the Mathematical Optimization Methods group and associated to the MODAL-SynLab project.\nI graduated with a double PhD (cotutelle) between École Polytechnique of Montréal, at the GERAD lab and Centrale Lille, at INRIA \u0026amp; the Cristal lab, in mathematical optimization.\nMy thesis, defended in December 2020, focuses on bilevel optimization, an extension coined near-optimality robustness, and pricing for demand response in smart grids.","tags":null,"title":"Mathieu Besançon","type":"authors"},{"authors":null,"categories":null,"content":"In a previous post, I detailed some of the features of MathOptSetDistances.jl and the evolution of the idea behind it. This is part II focusing on derivatives.\nTable of Contents  Meet ChainRules.jl Projection derivative Example on the nonnegative orthant Forward rule Reverse rules Conclusion Notes   The most interesting part of the packages is the projection onto a set. For some applications, what we need is not only the projection but also the derivative of this projection.\nOne answer here would be to let Automatic Differentiation (AD) do the work. However:\n Just like there are closed-form expressions for the projection, many sets admit closed-form projection derivatives that can be computed cheaply, Some projections may require to perform steps impossible or expensive with AD, as a root-finding procedure1 or an eigendecomposition2; Some functions might make calls into deeper water. JuMP for instance supports a lot of optimization solvers implemented in C and called as shared libraries. AD will not propagate through these calls.  For these reasons, AD systems often let users implement some derivatives themselves, but as a library developer, I do not want to depend on a full AD package (and force downstream users to do so).\nMeet ChainRules.jl ChainRules.jl is a Julia package addressing exactly the issue mentioned above: it defines a set of primitives to talk about derivatives in Julia. Library developers can implement custom derivatives for their own functions and types. Finally, AD library developers can leverage ChainRules.jl to obtain derivatives from functions when available, and otherwise use AD mechanisms to obtain them from more elementary functions.\nThe logic and motivation is explained in more details in Lyndon\u0026rsquo;s talk at JuliaCon 2020 and the package documentation which is very instructive on AD in general.\nProjection derivative We are interested in computing $D\\Pi_{\\mathcal{S}}(v)$, the derivative of the projection with respect to the initial point. As a refresher, if $\\Pi_s(\\cdot)$ is a function from $V$ onto itself, and if $V$ then the derivative $D\\Pi$ maps a point in $V$ onto a linear map from the *tangent space* of $V$ onto itself. The tangent space of $V$ is roughly speaking the space where differences of values in $V$ live. If $V$ corresponds to real numbers, then the tangent space will also be real numbers, but if $V$ is a space of time/dates, then the tangent space is a duration/time period. See here3 for more references. Again, roughly speaking, this linear map takes perturbations of the input $\\Delta v$ and maps them to perturbation of the projected point $\\Delta v_p$.\nAs an example warm-up:\n $S$ is the whole domain of $v$ $\\Rightarrow$ the projection is $v$ itself, $D\\Pi_{\\mathcal{S}}(v)$ is the identity operator. $S$ is $\\{0\\}^n$ $\\Rightarrow$ the projection is always $\\{0\\}^n$, $D\\Pi_{\\mathcal{S}}(v)$ maps every $Δv$ to a zero vector: perturbations in the input do not change the output.  $D\\Pi_{\\mathcal{S}}(v)$ is a linear map from $\\mathcal{V}$ to $\\mathcal{V}$. If $v \\in \\mathbb{R}^n$, it can be represented as a $n\\times n$ matrix. There are several ways of representing linear maps, see the LinearOperators.jl package for some insight. Two approaches (for now) are implemented for set distances:\n Matrix approach: given $v \\in \\mathbb{R}^n$, return the linear operator as an $n\\times n$ matrix. Forward mode: given $v$ and a direction $\\Delta v$, provide the directional derivative $D\\Pi_{\\mathcal{S}}(v) \\Delta v$. Reverse mode: given $v$, provide a closure corresponding to the adjoint of the derivative.  (1) has been implemented by Akshay for many sets during his GSoC this summer, along with the projections themselves.\n(1) corresponds to computing the derivative eagerly as a full matrix, thus paying storage and computation cost upfront. The advantage is the simplicity for standard vectors, take v, s, build and return the matrix. (2) is the building block for forward-mode differentiation: given a point $v$ and an input perturbation $\\Delta v$, compute the output perturbation. (3) corresponds to a building block for reverse-mode differentiation. An aspect of the matrix approach is that it works well for 1-D arrays but gets complex quite quickly for other structures, including multi-argument functions or matrices. Concatenating everything into a vector is too rigid.\nExample on the nonnegative orthant The nonnegative orthant cone is the set $\\mathbb{R}^n_+$; it is represented in MOI as MOI.Nonnegatives(n) with n the dimension. The projection is simple because it can be done elementwise: $$ (\\Pi_S(v))_i = max(v_i, 0) \\,\\,\\forall i. $$\nIn other terms, any non-diagonal term of the gradient matrix is 0 for any $v$. Here is a visualization made with haste for $n=2$ using the very promising Javis.jl:\nThe red circle is a vector in the plane and the blue square its projection.4\nThe Julia implementation follows the same idea, here in a simplified version:\nfunction projection_on_set(v::AbstractVector{T}, s::MOI.Nonnegatives) where {T} return max.(v, zero(T)) end For each component $i \\in 1..n$, there are two cases to compute its derivative, either the constraint is active or not.\n$$ \\begin{align} v_i \u0026lt; 0 \u0026amp; \\Rightarrow \\frac{\\partial \\Pi_i}{\\partial v_i}(v) = 0\\\\\nv_i \u0026gt; 0 \u0026amp; \\Rightarrow \\frac{\\partial \\Pi_i}{\\partial v_i}(v) = 1. \\end{align} $$\nThe projection is not differentiable on points where one of the components is 0. The convention usually taken is to return any quantity on such point (to the best of my knowledge, no system guarantees a subgradient). The Julia implementation holds on two lines:\nfunction projection_gradient_on_set(v::AbstractVector{T}, ::MOI.Nonnegatives) where {T} y = (sign.(v) .+ one(T)) / 2 return LinearAlgebra.Diagonal(y) end First the diagonal of the matrix is computed using broadcasting and the sign function. Then a LinearAlgebra.Diagonal matrix is constructed. This matrix type is sparsity-aware, in the sense that it encodes the information of having only non-zero entries on the diagonal. We save on space, using $O(n)$ memory instead of $O(n^2)$ for a full matrix, and can benefit from specialized methods down the line.\nWe implemented the matrix approach from scratch. Even though we materialize the derivative as a diagonal matrix, it still costs storage, which will become a burden when we compose this projection with other functions and compute derivatives on the composition.\nForward rule For a function f, value v and tangent Δv, the forward rule, or frule in ChainRules.jl does two things at once:\n Compute the function value y = f(v), Compute the directional derivative ∂y = Df(v) Δv.  The motivation for computing the two values at once is detailed in the documentation. Quite often, computing the derivative will require computing f(v) itself so it is likely to be interesting to return it anyway instead of forcing the user to call the function again.\nThe exact signature of ChainRulesCore.frule involves some details we want to ignore for now, but the essence is as follows:\nfunction frule((Δself, v...), ::typeof(f), v...; kwargs...) ... return y, ∂y end ∂Y is the directional derivative using the direction Δx. Note here the variadic Δx and x, since we do not want to impose a rigid, single-argument structure to functions. The Δself argument is out of scope for this post but you can read on its use in the docs.\nFor our set projection, it may look like this:\nfunction ChainRulesCore.frule( (_, Δv, _), ::typeof(projection_on_set), v::AbstractVector{T}, s::MOI.Nonnegatives) where {T} vproj = projection_on_set(v, s) ∂vproj = Δv .* (v .\u0026gt;= 0) return vproj, ∂vproj end The last computation line leverages broadcast to express elementwise the multiplication of Δv with the indicator of v[i] being nonnegative. The important thing to note here is that we never build the derivative as a data structure. Instead, we implement it as a function. An equivalent using our projection_gradient_on_set would be:\nfunction projection_directional_derivative(v, Δv, s) vproj = projection_on_set(v, s) DΠ = projection_gradient_on_set(v, s) ∂vproj = DΠ * Δv return vproj, ∂vproj end Notice the additional allocation and matrix-vector product.\nReverse rules The forward mode is fairly intuitive, the backward mode less so. The motivation for using it, and the reason it is the favoured one for several important fields using AD, is that it can differentiate a composition of functions with only matrix-vector products, instead of requiring matrix-matrix products. What it computed is, given a perturbation in the output (or seed), provide the corresponding perturbation in the input. There are great resources online which will explain it in better terms than I could so we will leave it at that.\nLooking at the rrule signature from ChainRules.jl:\nfunction rrule(::typeof(f), x...; kwargs...) y = f(x...) function pullback_f(Δy) # implement the pullback here return ∂self, ∂x end return y, pullback_f end This is a bit denser. rrule takes the function as input and its arguments. So far so good. It returns two things, the value y of the function, similalry to frule and a pullback. This term comes from differential geometry and in the context of AD, is also referred to as a backpropagator. Again, the ChainRules docs got your back with great explanations.\nIt also corresponds to the Jacobian-transpose vector product if you prefer the term. In the body of pullback_f, we compute the variation of the output with respect to each input. If we give the pullback a 1 or 1-like as input, we compute the gradient, the partial derivative of f with respect to each input x[i] evaluated at the point x.\nHere is the result for our positive orthant (again, simplified for conciseness):\nfunction ChainRulesCore.rrule(::typeof(projection_on_set), v, s::MOI.Nonnegatives) vproj = projection_on_set(v, s) function pullback(Δvproj) n = length(v) v̄ = zeros(eltype(Δvproj), n) for i in 1:n if vproj[i] == v[i] v̄[i] = Δvproj[i] end end return (ChainRulesCore.NO_FIELDS, v̄, ChainRulesCore.DoesNotExist()) end return (vproj, pullback) end The first step is computing the projection, here we do not bother with saving for loops and just call the projection function. For each index i of the vector, if the i-th projection component is equal to the i-th initial point, $v_i$ is in the positive orthant and variations of the output are directly equal to variations of the input. Otherwise, this means the non-negativity constraint is tight, the projection lies on the boundary vproj[i] = 0, and output variations are not propagated to the input since the partial derivative is zero.\nWe see here that a tuple of 3 elements is returned. The first corresponds to ∂self, out of the scope for this package. The second is the interesting one, v̄, the derivative with respect to the input point. The last one ChainRulesCore.DoesNotExist() indicates that there is no derivative with respect to the last argument of projection_on_set, namely the set s. This makes sense because there is nothing to differentiate in the set.\nAn interesting point to notice is that the implementation, not the types defines the derivatives. A non-trivial example would be a floating-point argument p only used to extract the sign bit. This means it would not have a notion of local perturbation. The type (a floating-point) would be interpreted as differentiable. To my understanding, Swift for Tensorflow uses a type-first approach, where types indicate what field gets differentiated.\nIf you imagine using this in practice, in an AD library for instance, one would first call rrule forward, computing primal values and collecting the successive pullbacks. Once we arrive at the end of our chain of functions, we could backpropagate from $\\Delta Y_{final} = 1$, walking our way back to the primary input parameters.\nConclusion This post comes after a few weeks of work on MathOptSetDistances.jl, the package with the actual implementation of the presented features. There is still a lot to learn and do on the topic, including solutions to more projections and derivatives thereof, but also interesting things to build upon. Defining derivatives and projections is after all a foundation for greater things to happen.\nNotes   See H. Friberg\u0026rsquo;s talk on exponential cone projection in Mosek at ISMP 2018 \u0026#x21a9;\u0026#xfe0e;\n An example case for the projection onto the Positive Semidefinite cone \u0026#x21a9;\u0026#xfe0e;\n If like me you haven\u0026rsquo;t spent much time lying around differential geometry books, the ChainRules.jl documentation has a great developer-oriented explanation. For more visual explanations, Keno Fischer had a recent talk on the topic. \u0026#x21a9;\u0026#xfe0e;\n See the source code here. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1608764400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608832353,"objectID":"af1fca7a2fd7b549324bff047bfbad7d","permalink":"https://matbesancon.github.io/post/2020-12-24-chains_sets2/","publishdate":"2020-12-24T00:00:00+01:00","relpermalink":"/post/2020-12-24-chains_sets2/","section":"post","summary":"Differentiating set projections.\n","tags":["julia","optimization","jump","automatic-differentiation"],"title":"Sets, chains and rules - part II","type":"post"},{"authors":null,"categories":null,"content":"Table of Contents  MathOptInterface and the motivation Examples Set projections User-defined distance notions Bonus   In this post, I will develop the process through which the MathOptSetDistances.jl package has been created and evolved. In the second one, I will go over the differentiation part.\nMathOptInterface and the motivation MathOptInterface.jl or MOI for short is a Julia package to unify structured constrained optimization problems. The abstract representation of problems MOI addresses is as follows:\n$$ \\begin{align} \\min_{x}\\,\\, \u0026amp; F(x) \\\\\\\\\n\\text{s.t.}\\,\\, \u0026amp; G_k(x) \\in \\mathcal{S}_k \\,\\, \\forall k \\\\\\\\\n\u0026amp; x \\in \\mathcal{X}. \\end{align} $$\n$\\mathcal{X}$ is the domain of the decision variables, $F$ is the objective function, mapping values of the variables to the real line. The constrained aspect comes from the constraints $G_k(x) \\in \\mathcal{S}_k$, some mappings of the variables $G_k$ have to belong to a certain set $\\mathcal{S}_k$. See this recent paper on MOI for more information on this representation.\nThe structured aspect comes from the fact that a specific form of $F$, $G$ and $\\mathcal{S}$ is known in advance by the modeller. In other words, MOI does not deal with arbitrary unknown functions or black-box sets. For such cases, other tools are more adapted.\nFrom a given problem in this representation, two operations can be of interest within a solution algorithm or from a user perspective:\n Given a value for $x$, evaluating a function $F(x)$ or $G(x)$, Given a value $v$ in the co-domain of $G_k$, asserting whether $v \\in S_k$.  The first point is addressed by the function eval_variables in the MOI.Utilities submodule (documentation).\nThe second point appears as simple (or at least it did to me) but is trickier. What tolerance should be set? Most solvers include a numerical tolerance on constraint violations, should this be propagated from user choices, and how?\nThe deceivingly simple feature ended up opening one of the longest discussions in the MOI repository.\n Fairly straightforward[\u0026hellip;]\n Optimistic me, beginning of the PR, February 2020\nA more meaningful query for solvers is, given a value $v$, what is the distance from $v$ to the set $\\mathcal{S}$:\n$$ \\begin{align} (\\text{δ(v, s)})\\,\\,\\min_{v_p}\\,\\, \u0026amp; \\text{dist}(v_p, v) \\\\\\\\\n\\text{s.t.}\\,\\, \u0026amp; v_p \\in \\mathcal{S}. \\end{align} $$\nThe optimal value of the problem above noted $δ(v, s)$ depends on the notion of the distance taken between two values in the domain $\\mathcal{V}$, noted $dist(\\cdot,\\cdot)$ here. In terms of implementation, the signature is roughly:\ndistance_to_set(v::V, s::S) -\u0026gt; Real Aside: this is an example where multiple dispatch brings great value to the design: the implementation of distance_to_set depends on both the value type V and the type of set S. See why it\u0026rsquo;s useful in the Bonus section.\nIf $\\mathcal{S}$ was a generic set, computing this distance would be as hard as solving an optimization problem with constraints $v \\in \\mathcal{S}$ but since we are dealing with structured optimization, many particular sets have closed-form solutions for the problem above.\nExamples $\\|\\cdot\\|$ will denote the $l_2-$norm if not specified.\nThe distance computation problem defined by the following data:\n$$ \\begin{align} \u0026amp; v \\in \\mathcal{V} = \\mathbb{R}^n,\\\\\n\u0026amp; \\mathcal{S} = \\mathbb{Z}^n,\\\\\n\u0026amp; dist(a, b) = \\|a - b\\| \\end{align} $$\nconsists of rounding element-wise to the closest integer.\nThe following data:\n$$ \\begin{align} \u0026amp; v \\in \\mathcal{V} = \\mathbb{R}^n,\\\\\n\u0026amp; \\mathcal{S} = \\mathbb{R}^n_+,\\\\\n\u0026amp; dist(a, b) = \\|a - b\\| \\end{align} $$\nfind the closest point in the positive orthant, with a result:\n$$ v_{p}\\left[i\\right] = \\text{max}(v\\left[i\\right], 0) \\,\\, \\forall i \\in \\{1..n\\}. $$\nSet projections The distance from a point to a set tells us how far a given candidate is from respecting a constraint. But for many algorithms, the quantity of interest is the projection itself:\n$$ \\Pi_{\\mathcal{S}}(v) \\equiv \\text{arg} \\min_{v_p \\in \\mathcal{S}} \\text{dist}(v, v_p). $$\nLike the optimal distance, the best projection onto a set can often be defined in closed form i.e. without using generic optimization methods.\nWe also keep the convention that the projection of a point already in the set is always itself: $$ δ(v, \\mathcal{S}) = 0 \\,\\, \\Leftrightarrow \\,\\, v \\in \\mathcal{S} \\,\\, \\Leftrightarrow \\,\\, \\Pi_{\\mathcal{S}}(v) = v. $$\nThe interesting thing about projections is that once obtained, a distance can be computed easily, although only computing the distance can be slightly more efficient, since we do not need to allocate the projected point.\nUser-defined distance notions Imagine a set defined using two functions: $$ \\begin{align} \\mathcal{S} = \\{v \\in \\mathcal{V}\\,|\\, f(v) \\leq 0, g(v)\\leq 0 \\}. \\end{align} $$\nThe distance must be evaluated with respect to two values: $$ (max(f(v), 0), max(g(v), 0)). $$\nHere, the choice boils down to a norm, but hard-coding it seems harsh and rigid for users. Even if we plan correctly and add most norms people would expect, someone will end up with new exotic problems on sets, complex numbers or function spaces.\nThe solution that came up after discussions is adding a type to dispatch on, specifying the notion of distance used:\nfunction distance_to_set(d::D, v::V, s::S) where {D \u0026lt;: AbstractDistance, V, S \u0026lt;: MOI.AbstractSet} # ... end which can for instance encode a p-norm or anything else. In many cases, there is no ambiguity, and the package defines DefaultDistance() exactly for this.\nBonus If you are coming from a class-based object-oriented background, a common design choice is to define a Set abstract class with a method project_on_set(v::V) to implement. This would work for most situations, since a set often implies a domain V. What about the following:\n# Projecting onto the reals (no-op) project_on_set(v::AbstractVector{T}, s::Reals) where {T \u0026lt;: Real} # Projecting onto the reals (actual work) project_on_set(v::AbstractVector{T}, s::Reals) where {T \u0026lt;: Complex} Which \u0026ldquo;class\u0026rdquo; should own the implementation in that case? From what I observed, libraries end up with either an enumeration:\nif typeof(v) == AbstractVector{\u0026lt;:Reals} # ... elseif # ... end or when the number of possible domains is expected to be low, with several methods:\n# in the set class Reals function project_real(v::AbstractVector{T}) where {T \u0026lt;: Real} end function project_complex(v::AbstractVector{T}) where {T \u0026lt;: Complex} end function project_scalar(v::T) where {T \u0026lt;: Real} end As a last remark, one may wonder why would one define trivial sets as the MOI.Reals or the MOI.Zeros. A good example where this is needed is the polyhedral cone: $$ A x = 0 $$ with $x$ a vector. This makes more sense to define $Ax$ as the function and\nMOI.Zeros as the set.\n","date":1608678000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608892714,"objectID":"e50e14e89d79888840e9eec101bbf986","permalink":"https://matbesancon.github.io/post/2020-12-23-chains_sets/","publishdate":"2020-12-23T00:00:00+01:00","relpermalink":"/post/2020-12-23-chains_sets/","section":"post","summary":"The Pandora box from simple set membership.\n","tags":["julia","optimization","jump","automatic-differentiation"],"title":"Sets, chains and rules - part I","type":"post"},{"authors":null,"categories":null,"content":"Image source 1.\nTable of Contents  Communicating vessels and optimization formulation Vessel equilibrium as an optimization problem Computing a direction Projecting on the manifold Putting it all together Conclusion and perspective Acknowledgment Bonus Sources   Fluid mechanics was one of my favourite topics in the Process Engineering program I followed (some people will quit reading at this point and never talk to me again) so without surprise, I could not resist diving into this new blog post on SIAM News. This is the second time a post from Mark Levi caught my attention, the last was on heat exchangers, on which I also wrote a post, toying with parallel and counter-current heat exchangers.\nThis new post from Mark Levi illustrates a key concept in constrained optimization: Lagrange multipliers and a nice interpretation in a problem of communicating vessels.\nCommunicating vessels and optimization formulation If you are familiar with fluid mechanics, feel free to skip this section. Imagine $N$ vessels filled with water, all connected through a pipe at the bottom as shown on the top figure. The problem statement is, given initial levels of water $x_k$ in each $k-th$ vessel:\n how does the state evolve? what equilibrium, if any, is eventually reached?  Otherwise, consider the weight of water creates pressure within it. The lower a point in the water, the higher the pressure, since there is more water above which exercises its weight. A difference in pressure between two points will create a motion of the water, until the pressure equalizes. Put differently, some fluid moves from the full part of the vessel (with more pressure) to empty parts (with less pressure) until the pressure equalizes.\n2\nSince the pressure at a point depends on the height of the fluid above this point, two points have equal pressure when the height of water above them is equal. This is a phenomenon we often experience, with a watering can for instance.\nVessel equilibrium as an optimization problem A system reaches an equilibrium at the minimum of its potential energy. Feel free to skip this part if you read the blog post by Mark Levi, we basically go over the problem formulation once again. An equilibrium state (where the state does not evolve anymore) can be found by solving the optimization problem minimizing the potential energy, subject to the respect of the laws of physics. These laws state two things:\n No water loss: the mass of liquid is preserved, and since we are working with an incompressible liquid, the total volume too is constant. No negative volume: the different vessels exchange water, their volume increasing or decreasing with time, but at no point can a vessel reach a negative volume.  Each vessel $k$ will be described by a profile, an area as function of the height $f_k(x)$. We assume that these functions $f_k$ are all continuous. The state at any point in time is the height in each vessel $x_k$. The total volume of water in the vessel is given by: $$V_k(x_k) = \\int_0^{x_k} f_k(h) dh.$$\nThe conservation of volume can be expressed as:\n$$V_{0} = \\sum_{k=1}^N V_k(x_k) = \\sum_{k=1}^N \\int_0^{x_k} f_k(h) dh$$\nwhere $V_{0}$ is the initial total volume water. The nonnegativity of water volume in each vessel can be expressed as: $$\\int_0^{x_k} f_k(h) dh \\geq 0,,, \\forall k \\in \\{1..N\\} $$\nThe area at any height $f_k(x)$ is positive or null, so this constraint can be simplified as: $$x_k \\geq 0 ,,, \\forall k \\in \\{1..N\\} $$\nThe potential function, the objective minimized by the problem, is the last thing we miss. It consists of the total potential function of the water in the vessels, caused by gravity only. Each infinitesimal slice of water from $x$ to $x + dx$ exercises its weight, which is proportional to its volume $f_k(x) dx$ times height $x$. By integrating over a whole vessel $k$, this gives a potential of: $$ \\int_0^{x_k} h f_k(h) M dh$$ with M a constant of appropriate dimension. Since we are minimizing the sum of these functions, we will get rid of the constant (sorry for shocking physicists), yielding an objective:\n$$ F(x) = \\sum_{k=1}^N \\int_0^{x_k} h f_k(h)dh.$$\nTo sum it all, the optimization problem finding an equilibrium is:\n$$ \\begin{align} \\min_{x} \u0026amp; \\sum_{k=1}^N \\int_0^{x_k} h f_k(h)dh \\\\\\\\\n\u0026amp; \\text{subject to:} \\\\\\\n\u0026amp; G(x) = \\sum_{k=1}^N \\int_0^{x_k} f_k(h) dh - V_0 = 0\\\\\\\\\n\u0026amp; x_k \\geq 0 ,,, \\forall k \\in \\{1..N\\} \\end{align} $$\nIf you read the blog post, you saw the best way to solve this problem is by relaxing the positivity constraints and write the first-order Karush-Kuhn-Tucker (KKT) conditions:\n$$ \\begin{align} \u0026amp; \\nabla F(x) = \\lambda \\nabla G(x) \u0026amp; \\Leftrightarrow\\\\\\\n\u0026amp; x_k f_k(x_k) = \\lambda f_k(x_k) ,,,\\forall k \\in \\{1..N\\} \u0026amp; \\Leftrightarrow \\\\\\\n\u0026amp; x_k = \\lambda ,,,\\forall k \\in \\{1..N\\} \\end{align} $$\nSo the multiplier $\\lambda$ ends up being the height of water across all vessels, the equations come back to the intuitive result. Between the second and third line, we implicitly eliminate the case $f_k(x_k) = 0$, which would be a section of the vessel of area 0. Let us implement $F$, $G$ and their gradients in Julia to reproduce this result numerically. We will use four vessels of various shapes:\nimport QuadGK const funcs = ( x -\u0026gt; oneunit(x), x -\u0026gt; 2x, x -\u0026gt; 2 * sqrt(x), x -\u0026gt; 2 * x^2 ) const N = length(funcs) g(x) = sum(1:N) do k QuadGK.quadgk(funcs[k], 0, x[k])[1] end f(x) = sum(1:N) do k x[k] * QuadGK.quadgk(funcs[k], 0, x[k])[1] end QuadGK.quadgk from the Gauss–Kronrod package computes a numerical integral of a function on an interval. We are in an interesting case where the gradient of the functions are much easier to compute than the functions themselves, since they remove the integrals:\n∇f(x) = [x[k] * funcs[k](x[k]) for k in 1:N] ∇g(x) = [funcs[k](x[k]) for k in 1:N] If we pick a starting point, such that all four vessels have the same height:\nx0_height = rand() x0_uniform = [x0_height for _ in 1:N] we can verify the first-order KKT conditions as expressed in Mark Levi\u0026rsquo;s post:\n∇f(x0_uniform) - x0_height * ∇g(x0_uniform) and we obtain a vector of zeros as planned.\nThe rest of this post will be about trying to find the optimal height that is reached by this system, implementing an iterative algorithm solving the problem in a generic form. This will require several parts:\n From a given iterate, find a direction to follow; Ensure each iterate respects the constraints defined above (no thugs in physicstown); Converge to the feasible solution (which we know from Mark Levi\u0026rsquo;s post, but no cheating); Define stopping criteria.  An interesting point on the structure of the problem, this is not a generic equality-constrained non-linear problem, the domain defined by $G(x) = 0$ is a manifold, which is a smooth subspace of $\\mathbb{R}^N$. Other than throwing fancy words, having this structure lets us use specific optimization methods which have been developed for manifolds. A whole ecosystem has been developed in Julia to model and solve optimization problems over manifolds. We will not be using it and will build our method from scratch, inefficient but preferred for unknown reasons, like your sourdough starter in lockdown.\nComputing a direction From a given solution, we need to be able to find a direction in which we can progress. Fair warning, this is the most \u0026ldquo;optimization-heavy\u0026rdquo; section.\nLet us start from a random point. Use the same seed if you want to reproduce the results:\nRandom.seed!(42) # 4 uniform random points between [0,2] x0 = 2 * rand(4) V0 = g(x0) # 1.9273890036845946 With the vessel shape functions defined above, this looks roughly like this:\n(source code available in the bonus section).\nIn unconstrained optimization, the gradient provides us with information on the steepest ascent direction, by following the opposite direction, the function will decrease, at least locally.\nxnew = x_i - γ * ∇f(xinit) See this good blog post by Ju Yang several with really good illustrations to grasp an intuition. If we naively follow the descent direction minimizing $F$, we likely leave the manifold, the region where $G(x) = 0$.\nThink of the curve as the feasible region where we are supposed remain. $x_i$ is our current iterate and the direction points to the steepest descent of $F(x)$, i.e. $-\\nabla F(x)$.\nMoving in this direction will drive our iterates away from the feasible region, which is not desired. Instead, we will want to project this direction to follow the equality constraints, like the red direction:\nOf course, by following a fixed direction, the iterate ends up not on the curve, but not \u0026ldquo;too far\u0026rdquo;. More importantly, we will have ensured that the point has not been moved for nothing, which would be the case if we simply get away from the manifold. We are looking for a search direction $d$:\n which improves the objective function as much as possible: $\\langle ∇F(x_{i}), d\\rangle$ as low as possible, or equivalently $\\langle -∇F(x_i), d\\rangle$ maximized; tangent to the manifold.  For the last requirement, we need a direction in the tangent space to the manifold, so $\\langle \\nabla G(x_i), d\\rangle = 0$, we end up requiring the vector rejection (the residual of a vector projection):\n$$ \\begin{align} \u0026amp; d = -\\nabla F(x_i) - \\frac{-\\nabla F(x_i) \\cdot \\nabla G(x_i)}{\\|\\nabla G(x_i)\\|^2} \\nabla G(x_i) \\Leftrightarrow \\\\\\\n\u0026amp; d = \\frac{\\nabla F(x_i) \\cdot \\nabla G(x_i)}{\\|\\nabla G(x_i)\\|^2} \\nabla G(x_i) -\\nabla F(x_i) \\end{align} $$\nfunction compute_direction(grad_f, grad_g) return -grad_f + grad_g * (grad_f ⋅ grad_g) / (grad_g ⋅ grad_g) end Note: in a first version of this post, the projection was implemented as a Second-Order Cone problem (SOCP) in JuMP, which is computationally more expensive, just the first thing I thought of. When you are used to hammers, all projections look like nails. For curiosity, you will find it below:\n$$ \\begin{align} \\min_{d, t} \u0026amp; \\langle\\nabla F(x_i), d \\rangle \\\\\\\n\u0026amp; \\text{subject to:} \\\\\\\n\u0026amp; \\langle \\nabla G(x_i), d\\rangle = 0 \\\\\\\n\u0026amp; t = 1 \\\\\\\n\u0026amp; \\|d\\| \\leq t \\end{align} $$\nThe second-order cone constraint is $\\|d\\| \\leq t$. Note that the direction is restricted to have unit $l_2$-norm, unlike the vector rejection above.\nusing JuMP import ECOS function compute_direction_SOCP(grad_f, grad_g) N = length(grad_f) m = Model(ECOS.Optimizer) MOI.set(m, MOI.Silent(), true) @variable(m, d[1:N]) @constraint(m, grad_g ⋅ d == 0) @variable(m, t == 1) @constraint(m, [t;d] in SecondOrderCone()) @objective(m, Min, d ⋅ grad_f) optimize!(m) termination_status(m) == MOI.OPTIMAL || error(\u0026#34;Something wrong?\u0026#34;) return JuMP.value.(d) end Also in the first version of this post, I had set the norm of $d$ to be equal to that of $\\nabla F(x_i)$, which is a bad idea$^{TM}$. You will find in the bonus section the resulting descent.\nOn the point x0 defined above, the naive descent direction yields:\n∇f(x0) # 4-element Array{Float64,1}: # 1.0663660320877226 # 1.649139647696062 # 0.013306072041938516 # 0.08274729914625051 and the projected gradient:\nd = compute_direction(∇f(x0), ∇g(x0)) # 4-element Array{Float64,1}: # -0.7980557152422237 # 0.0054117074806136894 # 1.66214850442488 # 0.6812946467870831 Note that all elements in $∇f(x0)$ are positive, which makes sense from the intuition of the physics, the water in each vessel has a weight, thus exercising a pressure downwards.\nThere is still one thing we forgot once the direction is found. Remember the positivity constraint $x_k \\geq 0$? It ensures the solution found makes sense, and that fluid mechanics specialists won\u0026rsquo;t laugh at the solutions computed. If one of the coordinates of the found point is negative, what we can do is maintain the direction, but reduce the step. Notice that one of our containers has an area of $2\\sqrt{x}$, reaching $x=0$ could lead to odd behaviour, we will maintain the constraint x_k \u0026lt;= minval with minval a small positive number.\nfunction corrected_step(x, d, γ = 0.05; minval = 0.005) res = x + γ * d for k in eachindex(res) if res[k] \u0026lt; minval γ = (minval - x[k]) / d[k] res = x + γ * d end end return res end Note: in a general setting, a more appropriate method like the active set method would have handled inequality constraints in a cleaner way. In our case, if a height is close to 0, it will not stay there but \u0026ldquo;bounce back\u0026rdquo;, so keeping track of active sets is unnecessary.\nSo we now have an iterate, the res variable returned from corrected_step, which will always respect the positivity constraints and be improving the objective in general.\nProjecting on the manifold We know in which direction $d$ the next iterate must be searched and have found an adequate step size $\\gamma$, but a straight line can never perfectly stick to a curved surface. So once the direction is found and a new iterate $x_i + \\gamma d$ computed, we need to project this iterate on the manifold, i.e. find the solution to:\n$$ \\begin{align} \\min_{x}\\,\\, \u0026amp; dist(x, x_i + \\gamma d) \\\\\\\n\u0026amp; \\text{subject to:} \\\\\\\n\u0026amp; G(x) = 0 \\end{align} $$\nSadly, this is where we need evaluations of $G(x)$, which is notably more expensive than its gradient. Evaluating $G(x_i + \\gamma d)$ gives us either 0 (the volume conservation holds), a positive or negative quantity (for a volume creation or destruction). We can shift all the vessel heights by a same scalar $\\alpha$ until $G(x_i + \\gamma d + \\alpha) = 0$.\nfunction h(x) function(α) g(x .+ α) - V0 end end h(corrected_step(x0, d, 1.5))(-0.5) # -1.4234221843048611 h(corrected_step(x0, d, 1.5))(0.5) # 3.5464645750853023 The problem then becomes a root-finding problem on $h(x)(\\alpha)$. Typical methods for solving a root-finding problem are Newton-type methods, bisections. We will use the Roots.jl package, this post is already too long to implement one from scratch.\n# computes the good alpha, starting from 0 root = Roots.find_zero(h(corrected_step(x0, d, 1.5)), 0.0) # -0.07526921814981354 g(corrected_step(x0, d, 1.5) .+ root) - V0 # 0.0 Putting it all together We now have all the ingredients to make this algorithm work:\nCompute a gradient, correct it for negative points, project it on the manifold (with the simple vector rejection or the SOCP), re-project the resulting point with root-finding on alpha. We will stop the algorithm either:\n If a number of iterations is reached (which is considered a failure since we did not converge); The norm of the projected gradient is almost zero and we would not move to a new iterate; The distance between two successive iterates is low enough.  function find_equilibrium(funcs, x0; mingradnorm=10e-5, maxiter = 1000, γ = 0.05, mindiff=10e-4) xs = [x0] niter = 0 while niter \u0026lt;= maxiter x = xs[end] # last iterate # compute projected direction d = compute_direction(∇f(x), ∇g(x)) # keep new point in positive orthant xpos = corrected_step(x, d, γ) # project point on Manifold α = Roots.find_zero(h(xpos), 0.0) xnew = xpos .+ α push!(xs, xnew) niter += 1 if norm(d) \u0026lt; mingradnorm @info \u0026#34;Min gradient condition reached\u0026#34; return xs end if norm(x - xnew) \u0026lt; mindiff @info \u0026#34;Min difference condition reached\u0026#34; return xs end end @info \u0026#34;Max iterations reached without convergence\u0026#34; return xs end Giving it a try with a first rough idea of parameters:\nxs = find_equilibrium(funcs, x0, γ = 0.005, maxiter = 5000, mindiff=10e-6) # Info: Min difference condition reached We converged because the successive iterates were close enough, let us check the solution profile:\nxs_pivot = map(1:4) do k getindex.(xs, k) end plot(xs_pivot) Fair enough, still, 1400 iterates should not be necessary for a 4-dimensional problem. Since convergence seems reached around the equilibrium point (the solution does not bounce around it), we can increase the step size, which was taken rather conservatively:\nLet us zoom in:\nxs = find_equilibrium(funcs, x0, γ = 0.05, maxiter = 5000, mindiff=10e-6) plot(map(k -\u0026gt; getindex.(xs, k), 1:4)) We reduce the number of iterations to 192, while not hindering convergence.\nConclusion and perspective I wanted to add a section on the corresponding dynamical system, namely a differential algebraic equation (DAE) system, but this is clearly long enough, and I couldn\u0026rsquo;t get anything to work.\nTL;DR: the techniques to find the equilibrium rely on local optimization tools. The problem structure allowed us to express the gradient and estimate projection steps using cheap enough methods, namely vector rejection and root finding on a univariate function.\nInteresting thing to do on top of this:\n Leverage the toolbox already present and coming in JuliaManifolds; Replace the gradient-based method used here with a higher-order one such as quasi-Newton, L-BFGS, which should come cheaply from the decomposability of both $F$ and $G$.  For the first point in particular, the direction projection can be seen as a retraction on the manifold. Thanks Ronny Bergmann for pointing it out!\nA fixed step size worked out well in our case because the problem structure is smooth enough, a better way would be doing a line search in the direction of $d$. The LineSearches.jl package is readily available, one could directly plug one of the available methods in the corrected_step function.\nFinally, going back to the initial motivation of Mark Levi in the SIAM post, one can express the KKT conditions on a Manifold-constrained problem as developed in this article.\nAcknowledgment Special thanks to Pierre for reading this post and spotting errors quicker than I could type them, Antoine Levitt for highlighting the SOCP approach was awfully overkill for a gradient projection, this also made me spot an other error, and Ronny Bergmann for encouraging words and detailed feedback and discussion on different parts of the talk, from links with JuliaManifolds to incorrect terminology and improvement perspective. Thanks also to Chris for the conversation on DAEs, for another post maybe, Odelin for the suggestion on the variable notations. And as often, thanks Pierre-Yves for the infaillible proof-reading as usual.\nBonus What happens when the norm of the direction vector is proportional to $\\nabla F(x_i)$ instead of the projected vector (or constant)? Don\u0026rsquo;t reproduce at home:\nAs promised, the plot to represent the vessels with the initial level of filling:\np = plot(xaxis=nothing, yaxis=nothing) xtop = 1.2 xks = collect(0.0:0.01:xtop) center_points = (-4N:4N) for k in 1:N center_point = center_points[4k] rhs = [funcs[k](xki)/2 + center_point for xki in xks] lhs = [-funcs[k](xki)/2 + center_point for xki in xks] plot!(p, rhs, xks, color = \u0026#34;black\u0026#34;, label = \u0026#34;\u0026#34;) plot!(p, lhs, xks, color = \u0026#34;black\u0026#34;, label = \u0026#34;\u0026#34;) plot!( p, [-funcs[k](x0[k])/2 + center_point, funcs[k](x0[k])/2 + center_point], [x0[k], x0[k]], label = \u0026#34;\u0026#34;, color = \u0026#34;blue\u0026#34;, width = 3, ) end The result is the plot presented in the introduction. A nice way to observe the evolution of the system is with this format directly:\nfunction plot_containers(x, xaxis=nothing, yaxis=nothing, iter = 100) xtop = 1.2 xks = collect(0.0:0.01:xtop) center_points = (-4N:4N) for k in 1:N center_point = center_points[4k] rhs = [funcs[k](xki)/2 + center_point for xki in xks] lhs = [-funcs[k](xki)/2 + center_point for xki in xks] plot!(p, rhs, xks, color = \u0026#34;black\u0026#34;, label = \u0026#34;\u0026#34;) plot!(p, lhs, xks, color = \u0026#34;black\u0026#34;, label = \u0026#34;\u0026#34;) plot!( p, [-funcs[k](x[k])/2 + center_point, funcs[k](x[k])/2 + center_point], [x[k], x[k]], label = \u0026#34;\u0026#34;, color = \u0026#34;blue\u0026#34;, width = 3, alpha = iter / 300, ) end p end p = plot(xaxis=nothing, yaxis=nothing) res = @gif for (iter, x) in enumerate(xs[1:20:end]) plot_containers(x, p, iter) end The result is not the kind of art that some manage with plots, but cool enough to see what is happening:\nSources Some ideas for this post came from a talk by Antoine Levitt at the Julia Paris meetup, where he presented some applications of optimization on manifolds for quantum physics (if I recall?).\n  Wikimedia \u0026#x21a9;\u0026#xfe0e;\n Wikimedia \u0026#x21a9;\u0026#xfe0e;\n   ","date":1588975200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608832353,"objectID":"5aca70310fd50348c5b4968275471fcb","permalink":"https://matbesancon.github.io/post/2020-05-09-volumes/","publishdate":"2020-05-09T00:00:00+02:00","relpermalink":"/post/2020-05-09-volumes/","section":"post","summary":"Constrained optimization on a fundamental engineering problem\n","tags":["julia","optimization","jump"],"title":"Experiments on communicating vessels, constrained optimization and manifolds","type":"post"},{"authors":null,"categories":null,"content":"One of the luxuries of a PhD in applied maths / computer science is the possibility to work from home. By possibility, I imply both the technical feasibility (my project does not require special equipment), and social acceptability (I never worked in labs enforcing presenteeism).\nOf course, working from home or from my usual corner coffee shop once every other week is very different from these exceptional circumstances. I should also highlight I do not have to take care of children or sick family members, which comes as a priority, big congrats to those who manage it. This post should not be seen as how things should be done, simply how I cope and as a list of ideas to pick from if you are in a similar situation. The context is also very special for me as I just moved to the UK for an academic visit at the University of Edinburgh, I had just settled at a new city, flat and office when things started to escalate.\n🎉🏴󠁧󠁢󠁳󠁣󠁴󠁿\nWith an apartment found and tickets bought, this is now official, I\u0026#39;ll be in Edinburgh in March \u0026amp; April for an academic visit at @UoEMaths ERGO\n\u0026mdash; Mathieu Besançon (@matbesancon) February 23, 2020  I decided to stay in Edinburgh instead of coming back to France because the trip itself would be irresponsible, travelling through the UK, sleeping in London and then crossing the border with continental Europe, but also because I was settled in comfortably enough to spend the rough months of the epidemic here. However, this meant adjusting in different ways.\nOverall routine Being in Europe with many friends \u0026amp; contacts in North America, I used the circumstances to slightly shift my day, waking up between 8.30 and 9.15, and going to bed a bit later, sharing more hours of the day with them. This would normally be more complicated with things to attend to where I am, but allow me to attend European late morning and afternoon remote events, North-American morning and early-afternoon events. I take a quick breakfast in the kitchen (no hot drink), make a batch of tea or coffee to keep while at my desk. I use the morning to catch up on emails, work on research, writing code and prose (with breaks, see below). I do not go back to eat while not hungry, and not before 1.30PM. The afternoon is a blend of research work and semi-work-related activities. I usually have figured out something to cook by the end of the day, depending on how much I estimate this will take I start late-afternoon or early evening. Depending on the mood and tasks, I work a bit after dinner, before closing all work tabs and windows (yes, all) to switch to leisure time, including films, calling people, etc. I keep at least one hour at the end of the day for reading, these days fiction (the Poppy War, the Alienist and Death in the East at the moment), and only in paper versions, since I don\u0026rsquo;t have a reader and I get enough screen time in the day.\nSocial media and work breaks First things first, these things suck up your time and attention the rest of the year, now they also build up your anxiety like never before. I\u0026rsquo;m not telling you to resist (I don\u0026rsquo;t), just to separate the time where you work from the social media time in small blocks; pomodoro is your friend there. With this setting, being distracted is okay, when you suddenly find yourself on non-work related things, just stop the work timer, take your break, and restart it when you are ready to restart. My breaks vary between 5 and 30 minutes, either texting friends, reading non-work news articles, scrolling or playing mines: Well how is YOUR discovery of gravity going? pic.twitter.com/Q8jaDPq6Tg\n\u0026mdash; Mathieu Besançon (@matbesancon) March 26, 2020  The rest of the time, I close distracting browser tabs (including emails) and toss my phone out of reach.\nBroadening work activities Staying focused on work is clearly harder; one way to cope with it is to broaden work activities and even if it does not serve you in the short term, consider it work, no need to drown in guilt. My semi-work activities include open-source software, reading papers and books in my domain but not directly relevant to my research, following MOOCs, even on some things I assume I already know to see a different perspective. You may have noticed lots of university seminars are maintained in an online format. Since you do not need to run to the building on the other side of the campus, it can be a good opportunity to spend 45 minutes on other topics for your general scientific culture.\nSetup and spacial separation This section is to take with a pinch of salt, it assumes some financial comfort and a big enough flat. Early in the epidemic when it felt like we were going for gradual home isolation, I started setting up my office in a way that felt good, not for two hours in the evening any more, but for 8+ hours in the day.\nFirst, the second monitor. I don\u0026rsquo;t think more than two active screens is necessary, but it may vary with activities, beware of excessive multi-tasking though. The only new thing I invested in is a keyboard, which I had not brought to the UK. It\u0026rsquo;s a DREVO Gramr mechanical keyboard with brown switches, reasonably priced and with a nice-enough touch. It also gave me the opportunity to finally re-switch to qwerty layout and stick to it. The biggest point for me of having an external keyboard is improving my posture. My screens are further away and higher thanks to few books, allowing me to keep my back straighter and relax my eyes. Working with a laptop alone is nice for few hours in a coffee shop or on a couch, but terrible for your eyes, arms, hands and back, forget the lap of laptop.\nThe spatial separation is fairly simple: work remains at my desk, I keep the living room for eating, drinks, films, chatting with my flatmate. If you have an office space to separate it from your bedroom, even better. This is also why I cannot blame Parisians leaving the capital for family houses, the lifestyle is not adapted to actually living in your $15m^2$ flat.\nVirtual conferences and social aspects There was a discussion on the remote thesis during the epidemic on the Grand Labo (in French). Among different subjects, I chose to speak of something which may appear very privileged (and is to some extent), which is the impact of cancelled academic events (conferences, workshops, seminars), especially on young academics, in which I include everyone being evaluated on their work now for a future position or promotion (master\u0026rsquo;s, PhDs, postdoctoral researchers, professors subject to the tenure clock).\nThe summary of the discussion is that scientific aspects of the events can be emulated though online seminars, but the networking aspects are much harder. The reason young academics are more heavily impacted is because we are the ones looking for contacts for what we will do afterwards, and both discovering and getting in touch with those contacts depends on such events. I do not have a perfect solution for this, and I\u0026rsquo;m not sure there is.\nKeeping your locals afloat Again this section is to take relatively to what you can afford. If you are not financially comfortable (and this is a post for PhDs so it might very well be the case, feel free to pick the pieces you want). One thing that will happen with everything shut down is that businesses and service workers that depend on a local activity will suffer. For tech workers, here is a great thread, although US-centric so some of the consequences will be hopefully nuanced in your country:\nThe US govt has failed to contain this outbreak\nIt\u0026#39;s now up to us, as individuals, to protect and support our communities\nTechies and other financially privileged people, this thread is for YOU:\n\u0026mdash; bletchley punk (@alicegoldfuss) March 16, 2020  Restaurants\n- Find out if your local faves are providing sick leave and pay for their workers. Shame them into doing it.\n- Order delivery to keep people paid\n- Have delivery drops in your lobby or stoop for their protection\n- TIP DIGITALLY don\u0026#39;t make them touch your grubby cash\n\u0026mdash; bletchley punk (@alicegoldfuss) March 16, 2020  The key point of this thread is your local restaurant, bar, pub. You do not want it closed and replaced by a chain (I assume?), and you do not want the employees that made it a great place without a job in these times where finding a new one will be hard. Check if they do delivery and / or take-away, at least allow yourself one treat a week, plus for special occasions (article submitted, came back from review, published, accepted, pushed as preprint). Contact them to know if they kept their staff, favour the ones who did. If they offer vouchers to use when they re-open, take some, otherwise suggest them so. This also goes for corner coffee \u0026amp; tea shop, they may still do take-away and need you now. I am trying to do so in Edinburgh, on the recommendations of my flatmates, friends and locals on Reddit, while I hope others do the same in my neighbourhood in Lille.\nWe got this One thing that was highlighted in the PhD panel with the Grand Labo was the overwhelming guilt, which is always latent in academia and comes out even stronger in these times. Keep in mind this is some never-seen event, re-writing much of how we live, work and socialize. Some parts are crisis measures that will gradually fade away, but some aspects will remain after the shock. Even coping at our best does not make the situation remotely \u0026ldquo;fine\u0026rdquo; for many of us, but we got this.\nIf you want more and better tips on working from home for tech workers in the epidemic time, this post, from the same author as the restaurant recommendations above, is worth it. If you read French, feel free to also check this thread:\n[THREAD DOCTORAT]\nBonjour à tous, comme la plupart des doctorants du territoires nous avons été encouragés à faire du télétravail à partir de lundi, puis en quelques heures aujourd’hui la situation s’est dégradée. Nous ne pouvons plus accéder à nos laboratoire ,à nos manips, rien\n\u0026mdash; Mathilde 👩🏼‍💻 (@BienDansMaThese) March 16, 2020  where Mathilde documents the progress and of setting up a workflow and new habits in these bizarre times, that fell on academia in France with little warning or preparation.\n","date":1585177200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586030387,"objectID":"da50879797d14d3aa7110f06301464aa","permalink":"https://matbesancon.github.io/post/2020-03-26-confined-phd/","publishdate":"2020-03-26T00:00:00+01:00","relpermalink":"/post/2020-03-26-confined-phd/","section":"post","summary":"Calling it a guide would imply I figured it out, this is merely documenting what works... okay?\n","tags":["phd","academia"],"title":"Coping with a confined PhD, a naive report","type":"post"},{"authors":null,"categories":null,"content":"In continuous convex optimization, duality is often the theoretical foundation for computing the sensibility of the optimal value of a problem to one of its parameters. In the non-linear domain, it is fairly standard to assume one can compute at any point of the domain the function $f(x)$ and gradient $\\nabla f(x)$.\nWhat about discrete optimization?\nThe first thought would be that differentiating the resolution of a discrete problem does not make sense, the information it yields since infinitesimal variations in the domain of the variables do not make sense.\nHowever, three cases come to mind for which asking for gradients makes perfect sense:\n  In mixed-integer linear problems, some variables take continuous values. All linear expressions are differentiable, and every constraint coefficient, right-hand-side and objective coefficient can have an attached partial derivative.\n  Even in pure-integer problems, the objective value will be a continuous function of the coefficients, possibly locally smooth, for which one can get the partial derivative associated with each weight.\n  We might be interested in computing the derivative of some expression of the variables with respect to some parameters, without this expression being the objective.\n  For these points, some duality-based techniques and reformulations can be used, sometimes very expensive when the input size grows. One common approach is to first solve the problem, then fixing the integer variables and re-solving the continuous part of the problem to compute the dual values associated with each constraint, and the reduced cost coefficients. This leads to solving a NP-hard problem, followed by a second solution from scratch of a linear optimization problem, still, it somehow works.\nMore than just solving the model and computing results, one major use case is embarking the result of an optimization problem into another more complete program. The tricks developed above cannot be integrated with an automated way of computing derivatives.\nAutomatic Differentiation Automatic Differentiation is far from new, but has known a gain in attention in the last decade with its used in ML, increasing the usability of the available libraries. It consists in getting an augmented information out of a function.\nIf a function has a type signature f: a -\u0026gt; b, the goal is, without modifying the function, to compute a derivative, which is also a function, which to every point in the domain, yields a linear map from domain to co-domain df: a -\u0026gt; (a -o b), where a -o b denotes a linear map, regardless of underlying representation (matrix, function, \u0026hellip;). See the talk and paper1 for a type-based formalism of AD if you are ok with programming language formalism.\nAutomatic differentiation on a pure-Julia solver ConstraintSolver.jl is a recent project by Wikunia. As the name indicates, it is a constraint programming solver, a more Computer-Science-flavoured approach to integer optimization. As a Julia solver, it can leverage both multiple dispatch and the type system to benefit from some features for free. One example of such feature is automatic differentiation: if your function is generic enough (not relying on a specific implementation of number types, such as Float64), gradients with respect to some parameters can be computed by calling the function just once (forward-mode automatic differentiation).\nExample problem: weighted independent set Let us consider a classical problem in combinatorial optimization, given an undirected graph $G = (V, E)$, finding a subset of the vertices, such that no two vertices in the subset are connected by an edge, and that the total weight of the chosen vertices is maximized.\nOptimization model of the weighted independent set Formulated as an optimization problem, it looks as follows:\n$$\\begin{align} (\\mathcal{P}): \\max_{x} \u0026amp; \\sum_{i \\in V} w_i x_i \\\\\\\\\n\\text{s.t.} \\\\\\\\\n\u0026amp; x_i + x_j \\leq 1 \\,\\, \\forall (i,j) \\in E \\\\\\\\\n\u0026amp; x \\in \\mathbb{B}^{|V|} \\end{align} $$\nTranslated to English, this would be maximizing the weighted sum of picked vertices, which are decisions living in the $|V|$-th dimensional binary space, such that for each edge, no two vertices can be chosen. The differentiable function here is the objective value of such optimization problem, and the parameters we differentiate with respect to are the weights attached to each vertex $w_i$. We will denote it $f(w) = \\max_x (\\mathcal{P}_w)$.\nIf a vertex $i$ is not chosen in a solution, there are two cases:\n the vertex has the same weight as at least one other, say $j$, such that swapping $i$ and $j$ in the selected subset does not change the optimal value. of $\\mathcal{P}$. In that case, there is a kink in the function, a discontinuity of the derivative, which may not be computed correctly by automatic differentiation. This is related to the phenomenon of degeneracy in the simplex algorithm, multiple variables could be chosen equivalently to enter the base. there is no other vertex with the same weight, such that swapping the two maintains the same objective value. In that case, the derivative is $0$, small enough variations of the weight does not change the solution nor the objective.  If a vertex $i$ is chosen in a solution, then $x_i = 1$, and the corresponding partial derivative of the weight is $\\frac{\\partial f(w)}{\\partial w_i} = 1$.\nA Julia implementation We will import a few packages, mostly MathOptInterface.jl (MOI), the foundation for constrained optimization, the solver itself, the Test standard lib, and ForwardDiff.jl for automatic differentiation.\nusing Test import ConstraintSolver const CS = ConstraintSolver import MathOptInterface const MOI = MathOptInterface import ForwardDiff Let us first write an implementation for the max-weight independent set problem. We will use a 4-vertex graph, looking as such:\nThe optimal answer here is to pick vertices 1 and 4 (in orange).\n@testset \u0026#34;Max independent set MOI\u0026#34; begin matrix = [ 0 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0 ] model = CS.Optimizer() x = [MOI.add_constrained_variable(model, MOI.ZeroOne()) for _ in 1:4] for i in 1:4, j in 1:4 if matrix[i,j] == 1 \u0026amp;\u0026amp; i \u0026lt; j (z, _) = MOI.add_constrained_variable(model, MOI.GreaterThan(0.0)) MOI.add_constraint(model, z, MOI.Integer()) MOI.add_constraint(model, z, MOI.LessThan(1.0)) f = MOI.ScalarAffineFunction( [ MOI.ScalarAffineTerm(1.0, x[i][1]), MOI.ScalarAffineTerm(1.0, x[j][1]), MOI.ScalarAffineTerm(1.0, z), ], 0.0 ) MOI.add_constraint(model, f, MOI.EqualTo(1.0)) end end weights = [0.2, 0.1, 0.2, 0.1] terms = [MOI.ScalarAffineTerm(weights[i], x[i][1]) for i in eachindex(x)] objective = MOI.ScalarAffineFunction(terms, 0.0) MOI.set(model, MOI.ObjectiveFunction{typeof(objective)}(), objective) MOI.set(model, MOI.ObjectiveSense(), MOI.MAX_SENSE) MOI.optimize!(model) # add some tests end Why the additional code with(z, _) = MOI.add_constrained_variable(model, MOI.GreaterThan(0.0))? ConstraintSolver.jl does not yet support constraints of the type a x + b y \u0026lt;= c, but linear equality constraints are fine, so we can derive equivalent formulations by adding a slack variable z.\nFor this problem, the tests could be on both the solution and objective value, as follows:\n@test MOI.get(model, MOI.VariablePrimal(), x[4][1]) == 1 @test MOI.get(model, MOI.VariablePrimal(), x[1][1]) == 1 @test MOI.get(model, MOI.ObjectiveValue()) ≈ 0.3 An equivalent JuMP version would look look this:\nmatrix = [ 0 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0 ] m = Model(with_optimizer(CS.Optimizer)) x = @variable(m, x[1:4], Bin) for i in 1:4, j in i+1:4 if matrix[i,j] == 1 zcomp = @variable(m) JuMP.set_binary(zcomp) @constraint(m, x[i] + x[j] + zcomp == 1) end end w = [0.2, 0.1, 0.2, 0.1] @objective(m, Max, dot(w, x)) optimize!(m) Why are we not using JuMP, which is much more concise and closer to the mathematical formulation?\nJuMP uses Float64 for all value types, which means we do not get the benefit of generic types, while MathOptInterface types are parameterized by the numeric type used. To be fair, maintaining type genericity on a project as large as JuMP is hard without making performance compromises. JuMP is not built of functions, but of a model object which contains a mutable state of the problem being constructed, and building an Algebraic Modelling Language without this incremental build of the model has not proved successful till now. One day, we may get a powerful declarative DSL for mathematical optimization, but it has not come yet.\nBack to our problem, we now have a way to compute the optimal value and solution. Let us implement our function $f(w)$:\nfunction weighted_stable_set(w) matrix = [ 0 1 1 0 1 0 1 0 1 1 0 1 0 0 1 0 ] model = CS.Optimizer(solution_type = Real) x = [MOI.add_constrained_variable(model, MOI.ZeroOne()) for _ in 1:4] for i in 1:4, j in 1:4 if matrix[i,j] == 1 \u0026amp;\u0026amp; i \u0026lt; j (z, _) = MOI.add_constrained_variable(model, MOI.GreaterThan(0.0)) MOI.add_constraint(model, z, MOI.Integer()) MOI.add_constraint(model, z, MOI.LessThan(1.0)) f = MOI.ScalarAffineFunction( [ MOI.ScalarAffineTerm(1.0, x[i][1]), MOI.ScalarAffineTerm(1.0, x[j][1]), MOI.ScalarAffineTerm(1.0, z), ], 0.0 ) MOI.add_constraint(model, f, MOI.EqualTo(1.0)) end end terms = [MOI.ScalarAffineTerm(w[i], x[i][1]) for i in eachindex(x)] objective = MOI.ScalarAffineFunction(terms, zero(eltype(w))) MOI.set(model, MOI.ObjectiveFunction{typeof(objective)}(), objective) MOI.set(model, MOI.ObjectiveSense(), MOI.MAX_SENSE) MOI.optimize!(model) return MOI.get(model, MOI.ObjectiveValue()) end We can now compute the gradient in one function call with ForwardDiff:\n@testset \u0026#34;Differentiating stable set\u0026#34; begin weights = [0.2, 0.1, 0.2, 0.1] ∇w = ForwardDiff.gradient(weighted_stable_set, weights) @test ∇w[1] ≈ 1 @test ∇w[4] ≈ 1 @test ∇w[2] ≈ ∇w[3] ≈ 0 end To understand how this derivative computation can work with just few function calls (proportional to the size of the input), one must dig a bit deeper in Dual Numbers. I will shamelessly refer to my slides at the Lambda Lille meetup for an example implementation in Haskell.\nWhy not reverse-mode? I mentioned that the cost of computing the value \u0026amp; derivatives is proportional to the size of the input, which can increase rapidly for real-world problems. This is specific to so-called forward mode automatic differentiation. We will not go over the inner details of forward versus reverse. As a rule of thumb, forward-mode has less overhead, and is better when the dimension of the output far exceeds the dimension of the input, while reverse-mode is better when the dimension of the input exceeds the one of the output.\nGiving reverse with Zygote a shot Getting back to our question, the answer is rather down-to-earth, the reverse-mode I tried simply did not work there. Reverse-mode requires tracing the normal function call, building a \u0026ldquo;tape\u0026rdquo;, this means that it needs a representation of the function (as a graph or other). I gave Zygote.jl a try, which can be done by replacing ForwardDiff.gradient(f,x) with Zygote.gradient(f, x) in the snippet above. Building a representation of the function means Zygote must have a representation of all operations performed. For the moment, this is still restricted to a subset of the Julia language (which is far more complex than commonly encountered mathematical functions built as a single expression). This subset still excludes throwing and handling exceptions, which is quite present in both ConstraintSolver.jl and MathOptInterface.\nI have not tried the other reverse tools for the sake of conciseness (and time), so feel free to check out Nabla.jl, ReverseDiff.jl and Tracker.jl.\nHow could this be improved? A first solution could be to move the idiom of Julia from throw/try/catch to handling errors as values, using something like the Result/Either type in Scala / Haskell / Rust and corresponding libraries.\nAnother alternative, currently happening is to keep pushing Zygote to support more features from Julia, going in the direction of supporting differentiation of any program, as dynamic as it gets.\nOne last option for the particular problem of exception handling would be to be able to opt-out of input validation, with some @validate expr, with expr potentially throwing or handling an error, and a @nocheck or @nothrows macro in front of the function call, considering the function will remain on the happy path and not guaranteeing validity or error messages otherwise. This works exactly like the @boundscheck, @inbounds pair for index validation.\nConclusion, speculation, prospect This post is already too long so we\u0026rsquo;ll stop there. The biggest highlights here are that:\n In discrete problems, we also have some continuous parts. Julia\u0026rsquo;s type system allows AD to work almost out of the box in most cases. With JuMP and MOI, solving optimization problems is just another algorithmic building block in your Julia program, spitting out results, and derivatives if you make them. I believe that\u0026rsquo;s why plugging in solvers developed in C/C++ is fine, but not always what we want. I would be ready to take a performance hit on the computation time of my algorithms to have some hackable, type-generic MILP solver in pure Julia.2  Special mentions Thanks a lot to Wikunia, first for developing ConstraintSolver.jl, without which none of this would have been possible, and for the open discussion on the multiple issues I posted. Don\u0026rsquo;t hesitate to check out his blog, where the whole journey from 0 to a constraint solver is documented.\n  The simple essence of automatic differentiation, Conal Elliott, Proceedings of the ACM on Programming Languages (ICFP), 2018 \u0026#x21a9;\u0026#xfe0e;\n I believe a pure-Julia solver could be made as fast as a C/C++ solver, but developing solvers is an enormous amount of work and micro-optimizations, tests on industrial cases. The new HiGHS solver however shows that one can get pretty good results by developing a linear solver from scratch with all modern techniques already baked in. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1579734000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596200698,"objectID":"d3cd0d097b8f6111c7d33839ee6ada63","permalink":"https://matbesancon.github.io/post/2020-01-23-discrete-diff/","publishdate":"2020-01-23T00:00:00+01:00","relpermalink":"/post/2020-01-23-discrete-diff/","section":"post","summary":"What can automated gradient computations bring to mathematical optimizers, what does it take to compute?\n","tags":["julia","automatic-differentiation","optimization","integer","jump"],"title":"Differentiating the discrete: Automatic Differentiation meets Integer Optimization","type":"post"},{"authors":null,"categories":null,"content":"Unlike other ecosystems in the scientific programming world, scientists and engineers working with Julia usually prefer a whole stack in Julia for many reasons. The compiler is doing way better when able to infer what is going on in a piece of code; when an error is thrown, the stack trace looks much nicer when only pure Julia code is involved, functions and types can be defined as generic as wanted without hard-coded container or number types for instance.\nSometimes however, inter-operability with native code is needed to use some external native libraries. By that I mean natively built libraries (*.so files on Linux systems, *.dylib on OSX, *.dll on Windows). In this post, we will explore some tools to work with native libraries in Julia. In the last couple weeks, I tinkered a bit with the HiGHS solver developed at the University of Edinburgh, which I will use as an example throughout this post. It is still work in progress, but has nice promises as the next-generation linear optimization solver in the COIN-OR suite.\nWhat does a native lib look like? Looking at the repository, it is a pretty standard CMake-based C++ project producing both an executable and library which can be called through a C interface. The two initial components are:\n The source code producing the library, this can be written in any language producing native code (C, C++, Rust) The header file defining the C API to call the library from other programs.  This interface is defined in a single header file src/interfaces/highs_c_api.h, header files may define a bunch of types (structs, unions, enums) but most importantly they define function prototypes looking like:\nint preprocess_variables(int* values, double offset, float coefficient); When using the function from Julia, the call to the native library looks like the following:\nccall( (my_library_name, :preprocess_variables), CInt, # return type (Ptr{Cint}, Cdouble, Cfloat), # tuple of argument types (pointer(my_array), 3.5, 4.5f) # tuple of arguments ) Let us dive in.\nSolution 1: build and link For this approach, the first step is to build the HiGHS library and have the library available. Following the documentation, the instructions are:\ncd HiGHS # where HiGHS is installed mkdir build cd build cmake .. # generate makefiles make # build everything here in the build directory Like often with native packages, some dependencies might be implicitly assumed, here is a Dockerfile building the project on an alpine machine, you should be able to reproduce this with Docker installed.\nFROMalpine:3.7RUN apk add git cmake g++ gcc clang makeWORKDIR/optpreprocess_variablesRUN git clone https://github.com/ERGO-Code/HiGHS.gitRUN mkdir -p HiGHS/buildWORKDIR/opt/HiGHS/buildRUN cmake .. \u0026amp;\u0026amp; makeRUN make testRUN make install # optionalNow back to the Julia side, say we assume the library is available at a given path, one can write the Julia functions corresponding to the interface. It is preferable not to expose error-prone C calls to the user. In the example of the preprocess_variables function defined above, a Julia wrapper would look like:\nfunction preprocess_variables(my_array::Vector{Cint}, offset::Cdouble, coefficient::Cfloat) result = ccall( (:preprocess_variables, my_library_name), Cint, (Ptr{Cint}, Cdouble, Cfloat), (pointer(my_array), 3.5, 4.5f) ) return result end Once these wrapper functions are defined, users can convert their values to the corresponding expected argument types and call them. The last thing needed is my_library_name, which must be the path to the library object. Hard-coding or assuming paths should be avoided, it makes software harder to install on some systems. One thing that can be done is asking the user to pass the library path as an environment variable:\nENV[\u0026#34;HIGHS_DIR\u0026#34;] # should contain the path to the HIGHS directory joinpath(ENV[\u0026#34;HIGHS_DIR\u0026#34;], \u0026#34;build\u0026#34;, \u0026#34;lib\u0026#34;, \u0026#34;libhighs.so\u0026#34;) Doing this every time is however not convenient. Since library paths are not changing at every call, one can check for this path at the installation of the package. For this purpose, a file deps/build.jl can be added in every package and will be run at the installation of the package or when the Pkg.build command is called. A build.jl for our purpose could look like:\nconst highs_location = ENV[\u0026#34;HIGHS_DIR\u0026#34;] const libhighs = joinpath(highs_location, \u0026#34;build\u0026#34;, \u0026#34;lib\u0026#34;, \u0026#34;libhighs.so\u0026#34;) const depsfile = joinpath(@__DIR__, \u0026#34;deps.jl\u0026#34;) open(depsfile, \u0026#34;w\u0026#34;) do f print(f, \u0026#34;const libhighs = \u0026#34;) print(f, libhighs) println(f) end The snippet above looks for the libhighs.so library, using the environment variable as location of the base directory of HiGHS. Placed in build.jl, the script will create a deps.jl file in the deps folder of the Julia package, and write const libhighs = \u0026quot;/my/path/to/highs/lib/libhighs.so\u0026quot;. This is more or less what happens with the SCIP.jl wrapper v0.9. Once the build step succeeds, one can add in the main module in /src:\nmodule HiGHS const deps_file = joinpath(dirname(@__FILE__),\u0026#34;..\u0026#34;,\u0026#34;deps\u0026#34;,\u0026#34;deps.jl\u0026#34;) if isfile(deps_file) include(deps_file) else error(\u0026#34;HiGHS not properly installed. Please run import Pkg; Pkg.build(\\\u0026#34;HiGHS\\\u0026#34;)\u0026#34;) end # other things end # module The global constant libhighs can then be used for ccall. We now have a functional package wrapping a native library downloaded and built separately. Summing up what we have, the Julia wrapper package looks as follows:\n$ tree . ├── Project.toml ├── README.md ├── deps │ ├── build.jl │ ├── build.log │ ├── deps.jl ├── src │ └── HiGHS.jl └── test └── runtests.jl deps/build.log and deps/deps.jl are not committed in the repository but generated when installing and/or building the Julia package.\nLifting maintainers' burden: generating wrapper functions with Clang.jl One time-consuming task in the previous steps is going from the C header file describing the API to Julia functions wrapping the ccall. The task is mostly repetitive and can be automated using Clang.jl. This package will generate the appropriate functions from a header file, a reduced example looks like:\nimport Clang # HIGHS_DIR = \u0026#34;path/to/highs/dir\u0026#34; const header_file = joinpath(HIGHS_DIR, \u0026#34;include\u0026#34;, \u0026#34;interfaces\u0026#34;, \u0026#34;highs_c_api.h\u0026#34;) const LIB_HEADERS = [header_file] const ctx = Clang.DefaultContext() Clang.parse_headers!(ctx, LIB_HEADERS, includes=[Clang.CLANG_INCLUDE], ) ctx.libname = \u0026#34;libhighs\u0026#34; ctx.options[\u0026#34;is_function_strictly_typed\u0026#34;] = true ctx.options[\u0026#34;is_struct_mutable\u0026#34;] = false const api_file = joinpath(@__DIR__, \u0026#34;../src/wrapper\u0026#34;, \u0026#34;$(ctx.libname)_api.jl\u0026#34;) open(api_file, \u0026#34;w\u0026#34;) do f # write each generated function # ... end This snippet can be placed in a /gen folder of the Julia wrapper package and writes to src/wrapper all the functions wrapping C calls. It is less error-prone compared to manually writing the Julia interface and can save a great deal of time when managing updates of the native library. Again, the SCIP.jl wrapper uses this method and can be used as example. Since the wrapper generation has different requirements than the package itself, we can provide it a Project.toml. Our package structure now looks like this:\n$ tree . ├── Project.toml ├── README.md ├── deps │ ├── build.jl │ ├── build.log │ ├── deps.jl ├── gen │ ├── Project.toml │ └── gen.jl ├── src │ ├── HiGHS.jl │ └── wrapper │ ├── libhighs_api.jl │ └── libhighs_common.jl └── test └── runtests.jl Lifting the user\u0026rsquo;s burden: BinaryBuilder \u0026amp; BinaryProvider For non-open-source software, what we did up to here this is the best you can get: let users download and install the library, pass the path once at build time and partly generate the Julia wrapper for ccall through Clang.jl. For open-source libraries however, could we go a step further and do everything for the user when they install the Julia package?\nThat\u0026rsquo;s where BinaryBuilder and BinaryProvider come in. See the Docker file above, BinaryBuilder uses the same technology and arcane tricks to cross-compile the binary artifacts (executables and libraries) natively. It does so by letting you install the library as you would on your own machine, using cmake, make, make install, etc. The result of running BinaryBuilder is a single Julia script build_tarballs.jl describing the commands run to produce the artifacts. This is placed in a repository with Continuous Integration support, which creates releases for all specified architectures, OS, compilers. You can see examples for the Clp solver here and for HiGHS there.\nBack to the Julia package, we can now modify the deps/build.jl script to use BinaryProvider, fetching the binaries corresponding to the current system. Without knowing anything about what\u0026rsquo;s going under the hood and how the library is built, users can simply perform Pkg.add(\u0026quot;ThePackage\u0026quot;) which will build automatically and explicitly specify when a given OS or architecture is not supported. Take a look at the modified build file using BinaryProvider.\nThey don\u0026rsquo;t need to guarantee that they have the same compiler, make and cmake version to have a repeatable \u0026amp; smooth installation of the package.\nWrapping up The process from 0 to a fully ready Julia package built on top of a binary library is still not straightforward. Special appreciation goes to the BinaryBuilder developers and contributors who helped me figure out some tricky bits. But the key take-away of this is that once the pipeline is built, updating the binary version or Julia wrapper is the same workflow one is used to with standard Julia packages. Keep building pure Julia software for all its benefits, but these tools I presented make it as great as possible to work with binaries.\nEdits Some design work is in progress on the Pkg side to be able to reason with artifacts, a post can be found here.\nMany thanks to staticfloat and giordano for the feedback and additional information.\n","date":1572822000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573160074,"objectID":"89650771389e61b39211727f99876766","permalink":"https://matbesancon.github.io/post/2019-11-04-binary-julia/","publishdate":"2019-11-04T00:00:00+01:00","relpermalink":"/post/2019-11-04-binary-julia/","section":"post","summary":"When going native is the only option, at least do it once and well.\n","tags":["julia"],"title":"Working with binary libraries for optimization in Julia","type":"post"},{"authors":null,"categories":null,"content":" A couple weeks ago, I had a wonderful evening thanks to the Skype a Scientist program, a 4th grade class from the US (think 9-10 years old if like me, you have no idea what grades stand for) and their super-dedicated teacher. It was a fun time but the most surprising part was discovering the questions they had prepared. I thought it would be worth it to list them and record some answers as I remember them. I grouped the questions in four arbitrary categories. The list also does not reflect the order in which the questions were asked.\n👨‍🔬 So\u0026hellip; you\u0026rsquo;re a scientist? Why did you decide to be a scientist? Curiosity mostly, but also I wanted to challenge myself on open questions.\nHow did you become a scientist? What school did you go to? Anyone can become a scientist by doing science, the schools we go matters less than the will to explore science. I guess I became a full-time scientist when I started my PhD two years ago.\nWhat kind of place do you work in? I work in a \u0026ldquo;lab\u0026rdquo;, but in my case this is an office (no white lab coat, no smoking tubes) with two other people. The office is located in a research institute, where other scientists and professors work on their research.\nWhat science experiments do you do? I write mathematical models to make better decisions in complex environments, for example in power grids. With specific models, the computers are really good at finding the best decisions.\nHow many days a week do you work? I work from Monday to Friday, so 5 days. Sometimes I take vacations off, sometimes I work a bit more, depending on the emergency of what I am doing.\nWhat research are you working on? I am working on models for better decisions in what is called the power grid. The power grid is the network connecting everything to electricity sources. Whether you are in your class or your kitchen at home, when you turn on the light, electricity is flowing all the way from places where it is produced (like the water network). These days, there are more and more renewable sources like solar panels and wind farms, but sometimes there is no sun or wind, so we have to anticipate better what is happening and make our consumption flexible.\n🏢 Life in a lab Have you seen a chemical reaction? Yes, and so have you! Cooking food on a frying pan for example will start chemical reactions, if you leave it for too long, it\u0026rsquo;s getting brown and burned.\nHow much workspace do you have? If we talk about physical workspace, I use a full table, where I have my laptop, a keyboard, and a mess of papers, draft notes, books. I\u0026rsquo;m a messy scientist.\nDo you any experiments with animals? Nope!\nWhat do you do in your lab? (if you work in a lab?) Once I have developed models and obtained interesting answers from computers, I write articles for other scientists to read. Other than that, I discuss with other people to find ideas on the models we write or how to write better computer programs, I drink coffee and eat cookies even when I shouldn\u0026rsquo;t.\n📈 Maths, again? Do you make models of anything? I haven\u0026rsquo;t found counter-examples yet so I\u0026rsquo;ll go with yes, you can make models of anything. A model is a way we represent something in a way that is easier to grasp, either for us humans, or for a computer.\nHow did the language of math get created? I am not an expert in the history of science, but from what I remember of old mathematical papers I saw, the language of mathematics was created piece by piece, by iterations. First, concepts would be created, like adding two numbers together into a bigger number. Then, some scientist, not necessarily the person who developed the concept, would find way to represent this abstract concept, for example with a cross symbol: $+$.\nSometimes, several ways to represent the same thing would exist in parallel, and people would only agree later on which one should be kept.\nSee this timeline when different modern symbols were introduced: Source.\nWhy is math so hard? Because it\u0026rsquo;s both:\n A new language to learn (how to say or write things) New concepts (new things we are able to say)  Things get easier with practice once you can relate the concept to things you already know or visualize. That\u0026rsquo;s also why you are learning multiplications with different models to see which one helps you relate the concept to what it applies to.\nHow are there so many different strategies for math? From the explanations the teacher gave me on what the class is working on, the question probably refers to how they learn about multiplications using different visual techniques, like ratio tables or the box \u0026amp; array methods.\nThe simple answer is that everyone is different, with some people finding easier to understand multiplication using boxes while another would see it clearly with the concept of ratio or lines. Whatever works for you is always the best.\n💻 Working with computers Have you ever seen the inside of a computer? Yes, a colleague of mine often opens up some workstations to increase their memory. Other than that, I worked at a company building tiny computers one can use in outdoor activities.\nDo you help make computers? No, I use computers every day but have no idea how to build one, it requires very specific skills to make both the physical system (called hardware) and the minimum software component on top.\nHave you ever seen a super computer? Sadly no, but I\u0026rsquo;d like to!\nHave you ever created an app? I have never created a mobile app alone, but I helped a bit on the app of my previous company. I created some computer apps, one was a snake game (I think the kids were too young to know it, made me feel old).\n","date":1571608800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571758677,"objectID":"56a06bab223c098f329ddba10eeaf26f","permalink":"https://matbesancon.github.io/post/2019-10-21-skype-a-scientist/","publishdate":"2019-10-21T00:00:00+02:00","relpermalink":"/post/2019-10-21-skype-a-scientist/","section":"post","summary":"\n","tags":[],"title":"Questions and answers from 4th graders","type":"post"},{"authors":null,"categories":null,"content":" Constructors are a basic building block of object-oriented programming (OOP). They expose ways to build specific types of objects consistently, using arbitrary rules to validate properties. Still, constructors are odd beasts in the OOP world. In Java, this is usually the first case of function overloading that learning programmers meet, often without knowing the term. An overloaded constructor is shown in the following example:\nclass Car { private Motor motor; public Car(Motor m) { this.motor = m; } public Car() { this.motor = new Motor(); } } Scala and Kotlin, which are both languages on the Java Virtual Machine designed after and learning from Java, made the design choice of imposing a primary constructor, which all other constructors have to call. Constructors are weird beasts because they act partly as a function, partly as a method. Moreover, they expose a special use of this as a method call instead of being a pointer to the current object:\nclass Car { private Motor motor; public Car(Motor m) { // \u0026#39;this\u0026#39; as an object reference  this.motor = m; } public Car(int power) { Motor m = new Motor(power); // this as a method  this(m); } } This has been in my experience confusing and harder to teach on my side because it forces the learner to get a grasp of many specific tricks at the same time. Another hard-to-grasp point is this(motor), which has never been defined has such. The definition it corresponds to is Car(Motor m), the required mental load here is just unnecessary. This is why I appreciate Kotlin and Scala having made constructors more restrictive, removing the need for hand-wavy explanations for bad design. This great blog post gives an overview of constructors in different mainstream languages and compare them with the trait-based system of Rust.\nConstructors outside class-based OOP I will focus here on composite types or struct. There is a whole section of the Julia docs on constructors, but I would summarize things as:\n There is a primary constructor which must provide values for all fields. All other constructors are just functions, no magic is involved, and constructors are just multiple methods in the context of multiple dispatch.  This way of building objects as simple structures holding data in different fields is not new, Kotlin and Scala have a similar pattern as we mentioned above. Languages like Rust and Go take a different path by having structures being plain structures, initialized by providing all fields directly: // rust example  struct Motor { pub power: u8, } struct Car { pub motor : Motor } // let m = Motor{power : 33}; \n// go example  type Motor struct { Power uint } // m := Motor{33}  Both languages have conventions for calling a standard constructing function, namely fn new(args) -\u0026gt; T and func NewT(args) for Rust and Go respectively, but those are not special and remain a simple convention without additional language complexity.\nTwo lessons learned Two interesting Pull Requests are about to be merged in Distributions.jl, which is the main package for working with probability distributions in Julia. Both revolve around a revision of the work of constructors. I will use them to make a point which I believe generalizes well to other systems. No probability theory should be needed here, it is merely a motivating example.\nLesson 1: product distributions and constructor promises Given multiple random variables: $ X_{i}, i = 1..n $ we define a **product distribution** as the vector random variable built by stacking the different $ X_i $:\n$$ X = [ X_i | i \\in 1..n ] $$\nThey arrived in Distributions.jl in this PR if you are curious. One thing to be careful about is that the term \u0026ldquo;product distribution\u0026rdquo; does not correspond with the eponymous Wikipedia entry. What we refer to here is the product type in the sense of tuple construction and not the arithmetic product. EDIT: the correct corresponding Wikipedia entry is the one on Product measure, thanks Chad for pointing it out. One important property is that the entries of the product type are independent distributions, which helps a great deal deducing properties of the product distribution.\nAn example product type could be the product of two univariate Gaussian distributions:\n$$ X_1 \\sim \\mathcal{N}(0, 1)$$ $$ X_2 \\sim \\mathcal{N}(0, 2)$$ $$ X = [X_1, X_2]$$\nThe implementation of the Product type stores the vector of univariate distributions, sampling and computing the PDF/CDF is done on a per-entry basis. The corresponding code would look like this: using Distributions: Normal, Product, pdf Xs = [Normal(0, 1), Normal(0, 2)] p = Product(Xs) # sample from p rand(p) # compute PDF at (x1 = 0, x2 = 1) pdf(p, [0.0, 1.0])\nOne problem we have here is that we know some specialized, faster techniques can be used in specific cases. Our product here for example, is nothing more than a multivariate Gaussian distribution with independent components: $$ X \\sim \\mathcal{N}([0, 0], diag([1, 2]))$$ with $diag(\\cdot)$ constructing a diagonal matrix from a vector.\nSampling and computing quantities of interest for such multivariate would be much faster by using a multivariate directly. Our new design can leverage multiple dispatch, and would look as follows:\nfunction Product(distributions::Vector{\u0026lt;:Gaussian}) # construct multivariate gaussian end function Product(distributions::Vector{\u0026lt;:Uniform}) # construct multivariate uniform end function Product(distributions::Vector{\u0026lt;:UnivariateDistribution}) # construct generic Product end It is all fine and type-stable; if you don\u0026rsquo;t know what it means, just think sound from a type perspective. One issue here though is that we break the promise of a constructor. A constructor of Product is supposed to return a Product and exactly this. If you work in a language that uses algebraic data types for possible failures and absence as Maybe/Either/Result/Option, the constructor should return the type and not one of these.\nstruct T # type fields end \u0026#34;\u0026#34;\u0026#34; T constructor \u0026#34;\u0026#34;\u0026#34; T(args) = # ... value = T(args) # the following should always be true typeof(value) \u0026lt;: T In our cases, a more efficient implementation cannot be returned from a constructor. This means the construction of our type must be left to another method which could return it or something else. In the case of product distributions, it was done in this PR, adding the function product_distribution in Distributions.jl, which can have various methods returning a Product or something else. With this design, it is left possible for a distribution to define a special product type, while the default Product will work reasonably well.\nThe lesson learned here is to be wary of exposing constructors when many paths are possible, and a dispatch system might be preferable. Constructors should always return the same type and are not ideal for a specialization system.\nLesson 2: main constructors should remain lean Many constructors for probability distributions include a verification of the parameters. When constructing a uniform distribution $\\mathcal{U}(a, b)$, one would want to verify that $a \\leq b$. For a Gaussian distribution, one would verify that the standard deviation is positive. These checks are fine, but have a runtime cost and may interrupt the construction of the object. There are many cases in which the parameters are guaranteed to be valid, two of them being:\n Constructing an object by copy. Constructing an object with default parameters.  struct T # fields end function T() # default parameters are valid end function T(t::T) # t is already constructed, and is therefore valid end Throwing errors in a constructor is ill-advised, because again, the promise of a constructor is to construct the object. In languages where throwing is not advised, it means the constructor would return a Maybe{T} / Either{_, T}, which again breaks the promise. The problem is that if checking is not the default, users are less likely to call the checking function. The solution found here is to use a keyword in all constructors:\nstruct D{T \u0026lt;: Real} \u0026lt;: Distribution param::T end function D(p::T; check_arg = true) where {T} if check_arg verify_parameter(p) end return D{T}(p) end The default is still to check the validity of parameters, but objects of type D can now be constructed with opt-out checking. Another way to do it is with multiple dispatch:\n\u0026#34;\u0026#34;\u0026#34; A flag structure to avoid checking arguments. \u0026#34;\u0026#34;\u0026#34; struct NoArgCheck end struct D{T \u0026lt;: Real} \u0026lt;: Distribution param::T end # standard constructor, validates the parameter function D(p::T) where {T \u0026lt;: Real} verify_parameter(p) return D{T}(p) end # faster constructor, no argument checking function D(p::T, ::NoArgCheck) where {T} return D{T}(p) end In either cases, users can now take the responsibility of checking parameters themselves. In recent Julia version, the compiler optimization of boolean constants will make the two roughly equivalent. One general rule to highlight here for scientific programming work is that the constructor is a fixed cost imposed on all users, treat additional checks and operations carefully.\nIf you found this post useful (or not) or want to react in some way, feel free to reach out on Twitter and/or Reddit.\nEdit: thanks Alec for spotting redundant code. Another blog post on the subject was posted on Reddit (thanks Paul for pointing it out).\n","date":1569276000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569922241,"objectID":"d5e5daacba605742e8192c6381fc973d","permalink":"https://matbesancon.github.io/post/2019-09-23-constructors/","publishdate":"2019-09-24T00:00:00+02:00","relpermalink":"/post/2019-09-23-constructors/","section":"post","summary":"Constructors are a basic building block of object-oriented programming (OOP). They expose ways to build specific types of objects consistently, using arbitrary rules to validate properties. Still, constructors are odd beasts in the OOP world. In Java, this is usually the first case of function overloading that learning programmers meet, often without knowing the term. An overloaded constructor is shown in the following example:\nclass Car { private Motor motor; public Car(Motor m) { this.","tags":["julia","rust","java"],"title":"Lessons learned on object constructors","type":"post"},{"authors":null,"categories":null,"content":" The progress of mathematical optimization as a domain has been tightly coupled with the development and improvement of computational methods and their implementations as computer programs. As observed in the recent MIPLIB compilation 1, the quantification of method performance in optimization cannot really be split from the experimental settings, solver performance is far from a theoretical science.\nDifferent methods and implementations manipulate different data structures to represent the same optimization problem. Reformulating optimization models has often been the role and responsibility of the practitioner, transforming the application problem at hand to fit a standard form that a given solver accepts as input for a solution method. Interested readers may find work on formal representation of optimization problems as data structures by Liberti et al23. Mapping a user-facing representation of an object into a semantically equivalent internal representation is the role of compilers. For mathematical optimization specifically, Algebraic Modelling Languages (AML) are domain-specific languages (and often an associated compiler and runtime) turning a user-specified code into data structures passed to solvers. Examples of such languages are JuMP, Pyomo, GAMS or AMPL; the first two being embedded in a host language (Julia and Python respectively), while the two last are stand-alone with their own compiler and runtime.\nWe will focus in this post on MathOptInterface.jl (MOI) which acts as a second layer of the compilation phase of an AML. The main direct user-facing language for this is JuMP, which has already been covered in other resources45. When passed to MOI, the problem has been read from the user code but not reformulated yet. In compiler terms, MOI appears after the parsing phase: the user code has been recognized and transformed into corresponding internal structures.\nRe-formulating problems using multiple dispatch Multiple dispatch is the specialization of code depending on the arity and type of arguments. When multiple definitions (methods) exist for a function, the types of the different arguments are used to determine which definition is compatible. If several definitions are compatible, the most specific with respect to the position in the type hierarchy is selected. If several definitions are compatible without a total ordering by specificity, the method call is ambiguous, which raises an error. More information on the dispatch system in Julia can be found in the seminal article and the recent talk on multiple dispatch. See the following examples for the basic syntax:\nf(x) = 3 # same as f(x::Any) = 3 f(x::Int) = 2x # dispatch on arity f(x, y) = 2 # defining and dispatching on a custom type struct X value::Float64 end f(x::X) = 3 * x.value In this section, we will consider the reformulation of problems using multiple dispatch. In a generic form, an optimization problem can be written as:\n$$\\begin{align} \\min_{x} ,,\u0026amp; f(x) \\\\ \\text{s.t.}\\\\ \u0026amp; F_i(x) \\in S_i \u0026amp; \\forall i \\end{align} $$\nThe example of linear constraints We will build a reformulation system leveraging multiple dispatch. Assuming the user code is already parsed, the problem input can be represented as function-set pairs $(F_i, S_i)$. If we restrict this to individual linear constraints, all functions are of the form: $$ F_i(x) = a_i^T x $$\nThe three types of sets are:\n LessThan(b): $ y \\in S_i \\Leftrightarrow y \\leq b $ GreaterThan(b): $ y \\in S_i \\Leftrightarrow y \\geq b $ EqualTo(b): $ y \\in S_i \\Leftrightarrow y = b $  abstract type ConstraintSet end struct LessThan{T} \u0026lt;: ConstraintSet b::T end struct GreaterThan{T} \u0026lt;: ConstraintSet b::T end struct EqualTo{T} \u0026lt;: ConstraintSet b::T end abstract type ScalarFunction end struct ScalarAffineFunction{T} \u0026lt;: ScalarFunction a::Vector{T} x::Vector{VariableIndex} end Now that the fundamental structures are there, let us think of a solver based on the simplex method, accepting only less-or-equal linear constraints. We will assume a Model type has been defined, which supports a function add_constraint!(m::Model, f::F, s::S), which adds a constraint of type F in S.\nfunction add_constraint!(m::Model, f::ScalarAffineFunction, s::LessThan) pass_to_solver(m.solver_pointer, f, s) end function add_constraint!(m::Model, f::ScalarAffineFunction{T}, s::GreaterThan{T}) where {T} # a^T x \u0026gt;= b \u0026lt;=\u0026gt; -a^T x \u0026lt;= b leq_set = LessThan{T}(-s.b) leq_function = ScalarAffineFunction(-f.a, f.x) add_constraint!(m, leq_function, leq_set) end function add_constraint!(m::Model, f::ScalarAffineFunction, s::EqualTo) # a^T x == b \u0026lt;=\u0026gt; a^T x \u0026lt;= b \u0026amp;\u0026amp; a^T x \u0026gt;= b leq_set = LessThan(s.b) geq_set = LessThan(s.b) leq_function = copy(f) geq_function = copy(f) add_constraint!(m, leq_function, leq_set) add_constraint!(m, geq_function, geq_set) end The dispatching rules of that program can be determined statically and define the sequence of method calls:\ngraph TD; E[EqualTo] --\u0026gt; G[GreaterThan]; E[EqualTo] --\u0026gt; L[LessThan]; G[GreaterThan] --\u0026gt; L[LessThan]; L[LessThan] --\u0026gt; S[Solver]; At each call site, exactly one method is determined to be the appropriate one to use by the dispatch mechanism.\nUnique dispatch and multiple solvers Let us now consider that another solver is integrated into our dispatch-based optimization framework, but supporting only GreaterThan constraints. The new method call diagram is:\ngraph TD; E[EqualTo] --\u0026gt; G[GreaterThan]; E[EqualTo] --\u0026gt; L[LessThan]; L[LessThan] --\u0026gt; G[GreaterThan]; G[GreaterThan] --\u0026gt; S[Solver]; Considering that we wish to define one reformulation graph for all solvers, two possibilities occur:\n Which path should be used is encoded in types. The method called from a given node depends on runtime parameters.  The first option could appear more efficient, but as the number of nodes, arcs and solvers grow, compilation is rendered impossible, as one would have to recompute complete programs based on the addition of solvers or reformulations. The second option requires tools other than dispatch, since this mechanism uses precisely the types to determine the method. It is to tackle this problem of reformulating problems in graph above that the bridge system was developed in MOI.\nThe bridge system The bridge system emerged as a solution to tackle the rapidly-growing number of supported functions, sets and constraints as function-set pairs. A bridge is the instantiation in the reformulation system of an arc in the diagram presented above. It is defined by:\n The type of constraint it is replacing, represented by its function-set pair $(F_0, S_0)$. The type of constraints which must be supported for the reformulation, as a collection of function-set pairs $[(F_i, S_i)]$. The reformulation method itself which takes the initial constraint, creates the necessary variables and constraints and adds them to the model. In a Haskell-like notation, the declarative part of the bridge can be modelled with the following signature: $$ ([x_0], F_0, S_0) \\rightarrow ([x_1], [(F_i,S_i)]) $$  where $[x_0]$ is a collection of variables used by the initial constraint, $[x_1]$ is the collection of newly created variables, and the $(F_i,S_i)$ are the newly created constraints.\nBridge implementation The bridge definition and most implementations live in the MathOptInterface.Bridges module. It consists of an abstract type AbstractBridge and some functions that bridges must implement.\nWe will see the greatly reduced example of a bridge type MyBridge adding support for two types of constraints. The following code declares what the bridge does:\nabstract type AbstractBridge end struct MyBridge1 \u0026lt;: AbstractBridge end struct MyBridge2 \u0026lt;: AbstractBridge end \u0026#34;\u0026#34;\u0026#34; By default, bridges do not support a constraint `F-in-S` \u0026#34;\u0026#34;\u0026#34; function MOI.supports_constraint(::Type{\u0026lt;:AbstractBridge}, ::Type{F}, ::Type{S}) where {F, S} return false end \u0026#34;\u0026#34;\u0026#34; MyBridge1 supports `F1 in S1` \u0026#34;\u0026#34;\u0026#34; function MOI.supports_constraint(::Type{MyBridge1}, ::Type{F1}, ::Type{S1}) return true end \u0026#34;\u0026#34;\u0026#34; MyBridge2 supports `F2 in S2` \u0026#34;\u0026#34;\u0026#34; function MOI.supports_constraint(::Type{MyBridge2{F2,S2}}, ::Type{F2}, ::Type{S2}) return true end \u0026#34;\u0026#34;\u0026#34; Bridging a `F1 in S1` with `MyBridge1` requires creating constraints of type `F3 in S3` and `F3 in S4` \u0026#34;\u0026#34;\u0026#34; added_constraint_types(::Type{MyBridge1}) return [(F3, S3), (F3, S4)] end \u0026#34;\u0026#34;\u0026#34; Bridging a `F2 in S2` with `MyBridge2` requires creating constraints of type `F3 in S3` \u0026#34;\u0026#34;\u0026#34; added_constraint_types(::Type{MyBridge2}) return [(F3, S3)] end What these method implementations declare is the following structure:\ngraph LR; F1[F1 in S1] -- B1 --\u0026gt; F33[F3 in S3]; F1[F1 in S1] -- B1 --\u0026gt; F34[F3 in S4]; F2[F2 in S2] -- B2 --\u0026gt; F33[F3 in S3]; Unlike dispatch, multiple possible bridges can be defined for a given constraint $F_1 \\in S_1$. In optimization, this corresponds to multiple possible reformulations of a given constraint.\nNow that the bridges behaviour have been defined, their implementation have to be given, again in a trimmed version of the real MOI code:\nfunction bridge_constraint(::Type{MyBridge1}, model::MOI.ModelLike, f::F1, s::S1) (f3, s3) = transform_constraint_first_component(f, s) s4 = transform_constraint_second_set(f, s) new_constraint3 = MOI.add_constraint(model, f3, s3) new_constraint4 = MOI.add_constraint(model, f3, s4) return MyBridge1(new_constraint3, new_constraint4) end function bridge_constraint(::Type{MyBridge2}, model::MOI.ModelLike, f::F2, s::S2) (f3, s3) = transform_constraint_first_component(f, s) new_constraint3 = MOI.add_constraint(model, f3, s3) return MyBridge2(new_constraint3) end Finally, the graph is for the moment split across different bridges. The multiple dispatch mechanism uses a method table, the bridge system uses a bridge optimizer which stores all bridges and thus contains the necessary information to convert a constraint to a supported form.\nProblem reformulation heuristics A bridge optimizer takes a given problem, a solver and the set of bridges, all of which representable in a single hyper-graph, a graph with possibly multiple edges between two given nodes.\n$P$ represents the initial problem, pointing to the constraints it contains. There is an edge from $C_i$ to $C_j$ for each bridge reformulating $C_i$ using at least a $C_j$ constraint. A constraint $C_i$ points to $S$ if the solver natively supports the constraint.\nSome bridges require defining multiple new constraints. That is the case of $B_5$ reformulating $C_6$ using $C_3$ and $C_4$. On the contrary, $C_3$ can be re-formulated either in $C_2$ using $B_2$ or in $C_4$ using $B_3$. In this setting, reformulating it in $C_2$ is appropriate, but may change depending on the solver. A potential large number of bridges could be introduced without being on any problem-solver path. For instance, there will likely be no semi-definite cone constraint when the problem at hand is linear, and $S$ a simplex-based solver. Without reasoning on specific constraints, it is hard to picture which reformulation is efficient.\nThe current bridging decision is based on a shortest-path heuristic. One bridge is considered a unit distance, and a shortest path from all user-facing constraints to all solver-compatible constraints is determined. More precisely, a Bellman-Ford type shortest path is used.\nPerspective \u0026amp; conclusion MathOptInterface.jl may be one of the greatest strength of the JuMP ecosystem: setting the abstractions right allows the developers to integrate more exotic constraint types in a consistent manner. Optimization practitioners do not limit themselves to linear and mixed-integer problems, following improvements in performance and variety of solvers, the recent JuMP session at JuliaCon 20196 lays out the motivation and structure of MOI, and recent developments it enabled. The type-based Function in Set structure keeps the underlying machinery familiar to both optimization scientists formulating problems in a close fashion and Julia programmers leveraging multiple dispatch.\nTransforming optimization problems using the bridge system is transparent, leaving the option for advanced users to pick which paths are chosen in the hypergraph. In the scenario where MOI was not performing these operations, the two options are:\n Reformulations by the modelling language: this may mean a systematic overhead cost of using the user-facing modelling language, especially if the used reformulation is not ideal for a specific problem. This also creates a barrier for other modelling languages to emerge, since a great deal of work has gone in reformulations of the user-input. The two-layer structure of JuMP + MOI has enabled different languages such as Parametron.jl or Convex.jl to emerge, sharing the same solver interfaces and middle infrastructure. The monolithic modelling environments historically dominant in mathematical optimization may explain to some extent why a large part of the optimization literature is working with solver APIs directly, thus loosing any ability to switch solver later. Reformulations by the solver: this is currently done for a lot of constraints, without always being transparent on which reformulation is applied and what the end-model is. This can lead to surprising behaviour when switching solvers or passing a different formulation of the same problem, without having access to what happens under the hood in a black-box proprietary solver.  The MOI system thus helps present and future researchers to avoid the pitfalls of the two-language problem of mathematical optimization.\nFurther resources The diagrams were designed using MermaidJS \u0026amp; draw.io.\n  MIPLIB 2017: Data-Driven Compilation of the 6th Mixed-Integer Programming Library, Gleixner, Ambros and Achterberg, Tobias and Christophel, Philipp and Lübbecke, Marco and Ralphs, Ted K and Hendel, Gregor and Gamrath, Gerald and Bastubbe, Michael and Berthold, Timo and Jarck, Kati and others, 2019. \u0026#x21a9;\u0026#xfe0e;\n Liberti, Leo. \u0026ldquo;Reformulations in mathematical programming: Definitions and systematics.\u0026rdquo; RAIRO-Operations Research 43.1 (2009): 55-85. Preprint \u0026#x21a9;\u0026#xfe0e;\n Liberti, Leo and Cafieri, Sonia and Tarissan, Fabien, Reformulations in Mathematical Programming: A Computational Approach, DOI, Preprint \u0026#x21a9;\u0026#xfe0e;\n JuMP initial paper https://doi.org/10.1137/15M1020575 \u0026#x21a9;\u0026#xfe0e;\n JuMP tutorial at JuliaCon2018: https://www.youtube.com/watch?v=7tzFRIiseJI \u0026#x21a9;\u0026#xfe0e;\n MathOptInterface, JuMP extensions and MOI-based solvers at JuliaCon2019: https://www.youtube.com/watch?v=cTmqmPcroFo \u0026#x21a9;\u0026#xfe0e;\n   ","date":1568239200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570717459,"objectID":"406fa142b0191f91da7f2b94f9ed344c","permalink":"https://matbesancon.github.io/post/2019-09-12-bridging-indicator/","publishdate":"2019-09-12T00:00:00+02:00","relpermalink":"/post/2019-09-12-bridging-indicator/","section":"post","summary":"Compiling mathematical optimization problems in a multiple-dispatch context.\n","tags":["julia","jump","optimization","graphs"],"title":"Bridges as an extended dispatch system","type":"post"},{"authors":[],"categories":[],"content":"In a previous post, we pushed the boundaries of the LightGraphs.jl abstraction to see how conforming the algorithms are to the declared interface, noticing some implied assumptions that were not stated. This has led to the development of VertexSafeGraphs.jl and soon to some work on LightGraphs.jl itself.\nAnother way to push the abstraction came out of the JuliaNantes workshop: leveraging some special structure of graphs to optimize some specific operations. A good parallel can be established be with the LinearAlgebra package from Julia Base, which defines special matrices such as Diagonal and Symmetric and Adjoint, implementing the AbstractMatrix interface but without storing all the entries.\nA basic example Suppose you have a path graph or chain, this means any vertex is connected to its predecessor and successor only, except the first and last vertices. Such graph can be represented by a LightGraphs.SimpleGraph: import LightGraphs const LG = LightGraphs g = LG.path_graph(10) for v in 1:9 @assert LG.has_edge(g, v, v+1) # should not explode end\nThis is all fine, but we are encoding in an adjacency list some structure that we are aware of from the beginning. If you are used to thinking in such way, \u0026ldquo;knowing it from the beginning\u0026rdquo; can be a hint that it can be encoded in terms of types and made zero-cost abstractions. The real only runtime information of a path graph (which is not available before receiving the actual graph) is its size $n$. The only thing to do is implement the handful of methods from the LightGraphs interface.\nstruct PathGraph{T \u0026lt;: Integer} \u0026lt;: LG.AbstractGraph{T} nv::Int end LG.edgetype(::PathGraph) = LG.Edge{Int} LG.is_directed(::Type{\u0026lt;:PathGraph}) = false LG.nv(g::PathGraph) = g.nv LG.ne(g::PathGraph) = LG.nv(g) - 1 LG.vertices(g::PathGraph) = 1:LG.nv(g) LG.edges(g::PathGraph) = [LG.Edge(i, i+1) for i in 1:LG.nv(g)-1] LG.has_vertex(g::PathGraph, v) = 1 \u0026lt;= v \u0026lt;= LG.nv(g) function LG.outneighbors(g::PathGraph, v) LG.has_vertex(g, v) || return Int[] LG.nv(g) \u0026gt; 1 || return Int[] if v == 1 return [2] end if v == LG.nv(g) return [LG.nv(g)-1] end return [v-1, v+1] end LightGraphs.inneighbors(g::PathGraph, v) = outneighbors(g, v) function LightGraphs.has_edge(g::PathGraph, v1, v2) if !has_vertex(g, v1) || !has_vertex(g, v2) return false end return abs(v1-v2) == 1 end A more striking example PathGraph may leave you skeptical as to the necessity of such machinery, and you are right. A more interesting example might be complete graphs. Again for these, the only required piece of information is the number of vertices, which is a lot lighter than storing all the possible edges. We can make a parallel with FillArrays.jl, implicitly representing the entries of a matrix.\nUse cases The question of when to use a special-encoded graph is quite open. This type can be used with all functions assuming a graph-like behaviour, but is immutable, it is therefore not the most useful when you construct these special graphs as a starting point for an algorithm mutating them.\nPerformance As of now, simple benchmarks will show that the construction of special graphs is cheaper than the creation of the adjacency lists for LightGraphs.SimpleGraph. Actually using them for \u0026ldquo;global\u0026rdquo; algorithms is another story:\nfunction f(G, nv) g = G(nv) pr = pagerank(g) km = kruskal_mst(g) return (g, pr, km) end Trying to benchmark this function on PathGraph shows it is way worse than the corresponding SimpleGraph structure, the CompleteGraph implementation is about the same order of allocations and runtime as its list-y counterpart.\nThe suspect for the lack of speedup is the edges operation, optimized with a custom edge iterator in LightGraphs and returning a heap-allocated Array in SpecialGraphs for now. Taking performance seriously will requiring tackling this before anything else. Other opportunities for optimization may include returning StaticArrays and re-implementing optional methods such as LightGraphs.adjacency_matrix using specialized matrix types.\nConclusion and further reading The work on these graph structures is happening in SpecialGraphs.jl, feel free to file issues and submit pull requests. Also check out the matrix-based graph prototype in this post.\n","date":1564071283,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564131147,"objectID":"c408ebcd62bd8e71a54688d5696b823b","permalink":"https://matbesancon.github.io/post/2019-07-25-special-graphs/","publishdate":"2019-07-25T18:14:43+02:00","relpermalink":"/post/2019-07-25-special-graphs/","section":"post","summary":"In a previous post, we pushed the boundaries of the LightGraphs.jl abstraction to see how conforming the algorithms are to the declared interface, noticing some implied assumptions that were not stated. This has led to the development of VertexSafeGraphs.jl and soon to some work on LightGraphs.jl itself.\nAnother way to push the abstraction came out of the JuliaNantes workshop: leveraging some special structure of graphs to optimize some specific operations. A good parallel can be established be with the LinearAlgebra package from Julia Base, which defines special matrices such as Diagonal and Symmetric and Adjoint, implementing the AbstractMatrix interface but without storing all the entries.","tags":["julia","graphs","interface"],"title":"Leveraging special graph shapes in LightGraphs","type":"post"},{"authors":null,"categories":null,"content":"LightGraphs has become the central package for working with graphs in Julia, exposing an interface for both directed and undirected graphs, a concrete and simple implementation of this interface and a set of essential graph algorithms. After a quick tour of the package features, we will show how algorithms developed using the interface work with different graph types, and how to develop our own specialized graph type as a user.\n","date":1561327200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574350889,"objectID":"a4b4367f83f948e26a7bf420ed188dfd","permalink":"https://matbesancon.github.io/talk/optimization_nantes/","publishdate":"2019-06-24T00:00:00+02:00","relpermalink":"/talk/optimization_nantes/","section":"talk","summary":"LightGraphs has become the central package for working with graphs in Julia, exposing an interface for both directed and undirected graphs, a concrete and simple implementation of this interface and a set of essential graph algorithms. After a quick tour of the package features, we will show how algorithms developed using the interface work with different graph types, and how to develop our own specialized graph type as a user.","tags":null,"title":"LightGraphs, structure, abstractions and algorithms","type":"talk"},{"authors":[],"categories":[],"content":"In various graph-related algorithms, a graph is modified through successive operations, merging, creating and deleting vertices. That\u0026rsquo;s the case for the Blossom algorithm finding a best matching in a graph and using contractions of nodes. In such cases, it can be useful to remove only the vertex being contracted, and maintain the number of all other vertices.\nLightGraphs.jl offers a set of abstractions, types and algorithms to get started with graphs. The claim of the abstraction is simple: whatever the underlying structure representing your graph, if it implements the AbstractGraph interface, it can be used out of the box with all algorithms built on LightGraphs.jl. The main concrete type presented by LightGraphs.jl is SimpleGraph and its directed counterpart SimpleDiGraph, only storing edges as adjacency lists, meaning vertices are just the integers from 1 to the length of the list. This means that in a graph with 6 vertices, deleting vertex 4 will re-label vertex 6 as 4. Hopefully, the interface should allow us to build a graph type on top of another graph, re-implementing only vertex removal.\nA simple vertex-safe implementation First things first, we will build it as a struct, using LightGraphs:\nimport LightGraphs const LG = LightGraphs struct VSafeGraph{T, G\u0026lt;:LG.AbstractGraph{T}, V\u0026lt;:AbstractVector{Int}} \u0026lt;: LG.AbstractGraph{T} g::G deleted_vertices::V VSafeGraph(g::G, v::V) where {T, G\u0026lt;:LG.AbstractGraph{T}, V\u0026lt;:AbstractVector{Int}} = new{T, G, V}(g, v) end VSafeGraph(g::G) where {G\u0026lt;:LG.AbstractGraph} = VSafeGraph(g, Vector{Int}()) VSafeGraph(nv::Integer) = VSafeGraph(LG.SimpleGraph(nv)) We added simple default constructors for convenience. The structure holds two elements:\n An inner abstract graph g A list of vertices already deleted: deleted_vertices.  The interface can now be implemented for our type, starting with the trivial parts:\nLG.edges(g::VSafeGraph) = LG.edges(g.g) LG.edgetype(g::VSafeGraph) = LG.edgetype(g.g) LG.is_directed(g::VSafeGraph) = LG.is_directed(g.g) LG.is_directed(::Type{\u0026lt;:VSafeGraph{T,G}}) where {T,G} = LG.is_directed(G) LG.ne(g::VSafeGraph) = LG.ne(g.g) LG.nv(g::VSafeGraph) = LG.nv(g.g) - length(g.deleted_vertices) LG.vertices(g::VSafeGraph) = (v for v in LG.vertices(g.g) if !(v in g.deleted_vertices)) LG.outneighbors(g::VSafeGraph, v) = LG.outneighbors(g.g, v) LG.inneighbors(g::VSafeGraph, v) = LG.inneighbors(g.g, v) LG.has_vertex(g::VSafeGraph, v) = LG.has_vertex(g.g, v) \u0026amp;\u0026amp; !(v in g.deleted_vertices) LG.has_edge(g::VSafeGraph, e) = LG.has_edge(g.g, e) LG.add_vertex!(g::VSafeGraph) = LG.add_vertex!(g.g) LG.rem_edge!(g::VSafeGraph, v1, v2) = LG.rem_edge!(g.g, v1, v2) Base.copy(g::VSafeGraph) = VSafeGraph(copy(g.g), copy(g.deleteed_vertices)) For most of these, we only re-call the method on the inner graph type. Only for LG.nv, which computes the number of vertices in the inner graph, minus the number of vertices in our removed list. Now the tricky parts, adding an edge and removing a vertex, which require a bit more verifications:\nfunction LG.add_edge!(g::VSafeGraph, v1, v2) if !LG.has_vertex(g, v1) || !LG.has_vertex(g, v2) return false end LG.add_edge!(g.g, v1, v2) end function LG.rem_vertex!(g::VSafeGraph, v1) if !LG.has_vertex(g, v1) || v1 in g.deleted_vertices return false end for v2 in LG.outneighbors(g, v1) LG.rem_edge!(g, v1, v2) end for v2 in LG.inneighbors(g, v1) LG.rem_edge!(g, v2, v1) end push!(g.deleted_vertices, v1) return true end Instead of removing the vertex v1 from the inner graph, the function removes all edges pointing to and from v1, and then adds it to the removed list.\nSpecific and generic tests So far so good, we can add some basic tests to check our type behaves as expected:\n@testset \u0026#34;Graph construction and basic interface\u0026#34; begin nv = 20 g1 = VSafeGraph(nv) @test LG.nv(g1) == nv @test LG.nv(g1.g) == nv g2_inner = LG.CompleteGraph(nv) g2 = VSafeGraph(g2_inner) @test LG.nv(g2) == LG.nv(g2_inner) @test LG.ne(g2) == LG.ne(g2_inner) @test all(sort(collect(LG.vertices(g2))) .== sort(collect(LG.vertices(g2_inner)))) g3 = VSafeGraph(LG.CompleteDiGraph(30)) @test LG.is_directed(g3) @test !LG.is_directed(g2) end @testset \u0026#34;Vertex deletion\u0026#34; begin Random.seed!(33) nv = 45 inner = LG.CompleteGraph(nv) g = VSafeGraph(inner) @test LG.ne(inner) == LG.ne(g) @test LG.nv(inner) == LG.nv(g) nrm = 0 for _ in 1:15 removed_ok = LG.rem_vertex!(g, rand(1:nv)) if !removed_ok continue end nrm += 1 @test LG.nv(inner) == nv @test LG.nv(g) == nv - nrm @test length(g.deleted_vertices) == nrm @test LG.ne(inner) == LG.ne(g) end end So far so good. Now, with the promise of generic graphs and the AbstractGraph interface, we should be able to use any algorithm in LightGraphs.jl, let us try to compute a page rank and a Kruskal minimum spanning tree:\nnv = 45 inner = LG.CompleteGraph(nv) g = VSafeGraph(inner) removed_ok = LG.rem_vertex!(g, rand(1:nv)) @test removed_ok # LG broken here @test_throws BoundsError LG.pagerank(g) @test_throws BoundsError LG.kruskal_mst(g) Yikes, what\u0026rsquo;s happening here? Many parts of LightGraphs.jl use vertices computed from vertices(g) as indices for structures indexed by them. So if you remove vertex 4 in a 6-vertex graph, vertices will be {1,2,3,5,6}, and the rank algorithm will try to access the 6th rank, even though only 5 exist.\nFixes and proposal It would be too bad to throw the interface altogether, but we need to do something for the broken behaviour. The underlying assumption here is that vertices behave like indices for anything vertex-related. So the way we implement this interface for VSafeGraph is correct, but the implicit contract is not, the way it is used in algorithms such as pagerank and Kruskal leak the underlying implementation for SimpleGraph: a contiguous list of integers from 1 to the number of vertices. It reminds me of this great talk on paying attention to the contract of an interface in Go, the type is telling you what to expect in and out, but not how it is supposed or will be used.\nThe first fix is to make vertices return 1:nv(g) for VSafeGraph, but if you think about it, it means it needs to do such with any graph type, which means the vertices function is redundant with other functions of the interface and should not be mandatory. The other option is to fix breaking code to really use the interface signalled and documented and not the leaked implementation.\nWe still have some good news though:\n Changing the code here is strictly non-breaking, since we would just remove the assumption that vertices are indices. If we want to keep this assumption for some pieces of code, it means these pieces are not generic but specialized, something we can handle well using either dispatch on types or traits, which LightGraphs.jl already does. There is a IsDirected trait associated with the fact that a graph is directed or not, there could also be a HasContiguousVertices trait signalling whether this assumption is validated for a type.  Edit: refined proposal Following some discussions with fellow LightGraphs.jl developers and users, a softer transition could be:\n Add the functions vertex_indices(g) and vertex_values(g) to the interface, vertex_values could default to vertex_indices, which could itself default on 1:nv(g). Deprecate vertices(g), with a fallback to vertex_indices. Replace all calls to vertex with either vertex_indices or vertex_values depending on which makes sense for the use case.  This change is non-breaking and only deprecating vertices, making the interface more explicit. By keeping the two functions, we avoid having to use enumerate(vertices_values(g)) every time we need indices.\nEdit 2: Corrections to the functions I have corrected various functions following Pankaj\u0026rsquo;s much needed Pull Request on the corresponding repository, thanks!\nEdit 3 Seth Bromberger spotted an error in my assumptions, Swap-and-pop is used for vertex removal, so the last vertex will take the place of the removed one in the re-labelling.\n","date":1559207683,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578325251,"objectID":"732b9b8a8f3f03fb4cee321f67ba5ca4","permalink":"https://matbesancon.github.io/post/2019-05-30-vertex-safe-removal/","publishdate":"2019-05-30T11:14:43+02:00","relpermalink":"/post/2019-05-30-vertex-safe-removal/","section":"post","summary":"In various graph-related algorithms, a graph is modified through successive operations, merging, creating and deleting vertices. That\u0026rsquo;s the case for the Blossom algorithm finding a best matching in a graph and using contractions of nodes. In such cases, it can be useful to remove only the vertex being contracted, and maintain the number of all other vertices.\nLightGraphs.jl offers a set of abstractions, types and algorithms to get started with graphs.","tags":["julia","graphs","interface"],"title":"Vertex removal in LightGraphs","type":"post"},{"authors":null,"categories":null,"content":"Last Friday was a great seminar of the Combinatorial Optimization group in Paris, celebrating the 85th birthday of Jack Edmonds, one of the founding researchers of combinatorial optimization, with the notable Blossom matching algorithm. .@SoniaVanier opened the workshop and organized a great party at Sorbonne for Jack Edmonds. I had a great honor to be one of the speakers at this event #orms pic.twitter.com/oHwKvg43Zm\n\u0026mdash; Ivana Ljubic (@ILjubic) May 3, 2019  Laurence Wolsey and Ivana Ljubic were both giving talks on applications and developments in Benders decompositions. It also made me want to refresh my knowledge of the subject and play a bit with a simple implementation.\nLaurence Wolsey talks about Benders decomposition at the Jack Edmonds birthday workshop at Sorbonne #orms pic.twitter.com/K8hjdqKmwQ\n\u0026mdash; Ivana Ljubic (@ILjubic) May 3, 2019  High-level idea Problem decompositions are used on large-scale optimization problems with a particular structure. The decomposition turns a compact, hard-to-solve formulation into an easier one but of great size. In the case of Benders, great size means a number of constraints growing exponentially with the size of the input problem. Adding all constraints upfront would be too costly. Furthermore, in general, only a small fraction of these constraints will be active in a final solution, the associated algorithm is to generate them incrementally, re-solve the problem with the new constraint until no relevant constraint can be found anymore.\nWe can establish a more general pattern of on-the-fly addition of information to an optimization problem, which entails two components:\n An incrementally-built problem, called Restricted Master Problem (RMP) in decomposition. An oracle or sub-problem, taking the problem state and building the new required structure (here a new constraint).  Sounds familiar? Benders can be seen as the \u0026ldquo;dual twin\u0026rdquo; of the Dantzig-Wolfe decomposition I had played with in a previous post.\nDigging into the structure Now that we have a general idea of the problem at hand, let\u0026rsquo;s see the specifics. Consider a problem such as: $$ \\min_{x,y} f(y) + c^T x $$ s.t. $$ G(y) \\in \\mathcal{S}$$ $$ A x + D y \\geq b $$ $$ x \\in \\mathbb{R}^{n_1}_{+}, y \\in \\mathcal{Y} $$\nWe will not consider the constraints specific to $y$ (the first row) nor the $y$-component of the objective. The key assumption of Benders is that if the $y$ are fixed, the problem on the $x$ variables is fast to solve. Lots of heuristics use this idea of \u0026ldquo;fix-and-optimize\u0026rdquo; to avoid incorporating the \u0026ldquo;hard\u0026rdquo; variables in the problem, Benders leverages several properties to bring the idea to exact methods (exact in the sense of proven optimality).\nTaking the problem above, we can simplify the structure by abstracting away (i.e. projecting out) the $x$ part: $$ \\min_{y} f(y) + \\phi(y) $$ s.t. $$ G(y) \\in \\mathcal{S}$$ $$ y \\in \\mathcal{Y} $$\nWhere: $$ \\phi(y) = \\min_{x} \\{c^T x, Ax \\geq b - Dy, x \\geq 0 \\} $$\n$\\phi(y)$ is a non-smooth function, with $, dom\\ \\phi ,$ the feasible domain of the problem. If you are familiar with bilevel optimization, this could remind you of the optimal value function used to describe lower-level problems. We will call $SP$ the sub-problem defined in the function $\\phi$.\nThe essence of Benders is to start from an outer-approximation (overly optimistic) by replacing $\\phi$ with a variable $\\eta$ which might be higher than the min value, and then add cuts which progressively constrain the problem. The initial outer-approximation is:\n$$ \\min_{y,\\eta} f(y) + \\eta $$ s.t. $$ G(y) \\in \\mathcal{S}$$ $$ y \\in \\mathcal{Y} $$\nOf course since $\\eta$ is unconstrained, the problem will start unbounded. What are valid cuts for this? Let us define the dual of the sub-problem $SP$, which we will name $DSP$: $$ \\max_{\\alpha} (b - Dy)^T \\alpha $$ s.t. $$ A^T \\alpha \\leq c $$ $$ \\alpha \\geq 0 $$\nGiven that $\\eta \\geq min SP$, by duality, $\\eta \\geq max DSP$. Furthermore, by strong duality of linear problems, if $\\eta = \\min \\max_{y} DSP$, it is exactly equal to the minimum of $\\phi(y)$ and yields the optimal solution.\nOne thing to note about the feasible domain of $DSP$, it does not depend on the value of $y$. This means $z$ feasible for all values of the dual is equivalent to being feasible for all extreme points and rays of the dual polyhedron. Each of these can yield a new cut to add to the relaxed problem. For the sake of conciseness, I will not go into details on the case when the sub-problem is not feasible for a $y$ solution. Briefly, this is equivalent to the dual being unbounded, it thus defines an extreme ray which must be cut out. For more details, you can check these lecture notes.\nA JuMP implementation We will define a simple implementation using JuMP, a generic optimization modeling library on top of Julia, usable with various solvers. Since the master and sub-problem resolutions are completely independent, they can be solved in separated software components, even with different solvers. To highlight this, we will use SCIP to solve the master problem and COIN-OR\u0026rsquo;s Clp to solve the sub-problem.\nWe can start by importing the required packages:\nusing JuMP import SCIP import Clp using LinearAlgebra: dot Defining and solving dual sub-problems Let us store static sub-problem data in a structure:\nstruct SubProblemData b::Vector{Float64} D::Matrix{Float64} A::Matrix{Float64} c::Vector{Float64} end And the dual sub-problem is entirely contained in another structure:\nstruct DualSubProblem data::SubProblemData α::Vector{VariableRef} m::Model end function DualSubProblem(d::SubProblemData, m::Model) α = @variable(m, α[i = 1:size(d.A, 1)] \u0026gt;= 0) @constraint(m, dot(d.A, α) .\u0026lt;= d.c) return DualSubProblem(d, α, m) end The DualSubProblem is constructed from the static data and a JuMP model. We mentioned that the feasible space of the sub-problem is independent of the value of $y$, thus we can add the constraint right away. Only to optimize it do we require the $\\hat{y}$ value, which is used to set the objective. We can then either return a feasibility cut or optimality cut depending on the solution status of the dual sub-problem:\nfunction JuMP.optimize!(sp::DualSubProblem, yh) obj = sp.data.b .- sp.data.D * yh @objective(sp.m, Max, dot(obj, sp.α)) optimize!(sp.m) st = termination_status(sp.m) if st == MOI.OPTIMAL α = JuMP.value.(sp.α) return (:OptimalityCut, α) elseif st == MOI.DUAL_INFEASIBLE return (:FeasibilityCut, α) else error(\u0026#34;DualSubProblem error: status $status\u0026#34;) end end Iterating on the master problem The main part of the resolution holds here in three steps.\n Initialize a master problem with variables $(y,\\eta)$ Optimize and pass the $\\hat{y}$ value to the sub-problem. Get back a dual value $\\alpha$ from the dual sub-problem Is the constraint generated by the $\\alpha$ value already respected?   If yes, the solution is optimal. If no, add the corresponding cut to the master problem, return to 2.  function benders_optimize!(m::Model, y::Vector{VariableRef}, sd::SubProblemData, sp_optimizer, f::Union{Function,Type}; eta_bound::Real = -1000.0) subproblem = Model(with_optimizer(sp_optimizer)) dsp = DualSubProblem(sd, subproblem) @variable(m, η \u0026gt;= eta_bound) @objective(m, Min, f(y) + η) optimize!(m) st = MOI.get(m, MOI.TerminationStatus()) # restricted master has a solution or is unbounded nopt_cons, nfeas_cons = (0, 0) @info \u0026#34;Initial status $st\u0026#34; cuts = Tuple{Symbol, Vector{Float64}}[] while (st == MOI.DUAL_INFEASIBLE) || (st == MOI.OPTIMAL) optimize!(m) st = MOI.get(m, MOI.TerminationStatus()) ŷ = JuMP.value.(y) η0 = JuMP.value(η) (res, α) = optimize!(dsp, ŷ) if res == :OptimalityCut @info \u0026#34;Optimality cut found\u0026#34; if η0 ≥ dot(α, (dsp.data.b - dsp.data.D * ŷ)) break else nopt_cons += 1 @constraint(m, η ≥ dot(α, (dsp.data.b - dsp.data.D * y))) end else @info \u0026#34;Feasibility cut found\u0026#34; nfeas_cons += 1 @constraint(m, 0 ≥ dot(α, (dsp.data.b - dsp.data.D * y))) end push!(cuts, (res, α)) end return (m, y, cuts, nopt_cons, nfeas_cons) end Note that we pass the function an already-built model with variable $y$ defined. This allows for a prior flexible definition of constraints of the type: $$y \\in \\mathcal{Y}$$ $$G(y) \\in \\mathcal{S}$$\nAlso, we return the $\\alpha$ values found by the sub-problems and the number of cuts of each type. Finally, one \u0026ldquo;hack\u0026rdquo; I\u0026rsquo;m using is to give an arbitrary lower bound on the $\\eta$ value, making it (almost) sure to have a bounded initial problem and thus a defined initial solution $y$.\nWe will re-use the small example from the lecture notes above:\nfunction test_data() c = [2., 3.] A = [1 2;2 -1] D = zeros(2, 1) .+ [1, 3] b = [3, 4] return SimpleBenders.SubProblemData(b, D, A, c) end data = test_data() # objective function on y f(v) = 2v[1] # initialize the problem m = Model(with_optimizer(SCIP.Optimizer)) @variable(m, y[j=1:1] \u0026gt;= 0) # solve and voilà (m, y, cuts, nopt_cons, nfeas_cons) = SimpleBenders.benders_optimize!(m, y, data, () -\u0026gt; Clp.Optimizer(LogLevel = 0), f) The full code is available on Github, run it, modify it and don\u0026rsquo;t hesitate to submit pull requests and issues, I\u0026rsquo;m sure there are :)\nBenders is a central pillar for various problems in optimization, research is still very active to bring it to non-linear convex or non-convex sub-problems where duality cannot be used. If you liked this post or have questions, don\u0026rsquo;t hesitate to react or ping me on Twitter.\n ","date":1557266400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568024137,"objectID":"ae82b16499db373e4a45c725fcd1b8b9","permalink":"https://matbesancon.github.io/post/2019-05-08-simple-benders/","publishdate":"2019-05-08T00:00:00+02:00","relpermalink":"/post/2019-05-08-simple-benders/","section":"post","summary":"Cracking Benders decomposition, one cut at a time.\n","tags":["optimization","jump","integer-optimization","julia"],"title":"A take on Benders decomposition in JuMP","type":"post"},{"authors":null,"categories":null,"content":"This week, I came across Richard Oberdieck\u0026rsquo;s post, \u0026ldquo;Why \u0026lsquo;evaluate\u0026rsquo; is the feature I am missing the most from commercial MIP solvers\u0026rdquo;. It would indeed be practical to have for the reasons listed by the author, but some barriers stand to have it as it is expressed in the snippets presented.\nInitial problem statement The author first tests the optimization of a non-linear function through scipy as such:\nfunc = lambda x: np.cos(14.5 * x - 0.3) + (x + 0.2) * x func(5) # 25.001603108415402 So far so good, we are defining a scalar function, passing it a scalar value at which it evaluates and returns the value, which is what it is supposed to do.\nNow the real gripe comes when moving on to developing against a black box solver (often commercial, closed-source), commonly used for linear, mixed-integer problems: import xpress as xp # Define the model and variables Model = xp.problem() x = xp.var(lb=0, ub=10) Model.addVariable(x) # Define the objective and solve test_objective = 5*x Model.setObjective(test_objective) Model.solve() # test_objective(5) does not work\nOne first problem to notice here is that test_objective is at best an expression, not a function, meaning it does not depend on an input argument but on decision variables declared globally. That is one point why it cannot be called.\nNow, the rest of this article will be some thoughts on how optimization problems could be structured and represented in a programming language.\nOne hack that could be used is being able to set the values of x, but this needs to be done at the global level: x = xp.var(lb=0, ub=10) Model.addVariable(x) # Define the objective test_objective = 5*x x.set(5) # evaluates test_objective with the set value of x xp.evaluale(test_objective)\nHaving to use the global scope, with an action on one object (the variable x) modifying another (the test_objective expression) is called a side-effect and quickly makes things confusing as your program grows in complexity. You have to contain the state in some way and keep track. Keeping track of value changes is more or less fine, but the hardest part is keeping track of value definitions. Consider the following example: x = xp.var(lb=0, ub=10) Model.addVariable(x) y = xp.var(lb=0, ub=10) Model.addVariable(y) # Define the objective and solve test_objective = 5*x + 2*y xp.evaluale(test_objective) # no variable set, what should this return? x.set(5) xp.evaluale(test_objective) # y is not set, what should this return?\nA terminology problem We are touching a more fundamental problem here, variables are not values and cannot be considered as such. Merging the term \u0026ldquo;variable\u0026rdquo; for variables of your Python/Julia/other program with the decision variables from an optimization problem creates a great confusion. Just like variables, the term function is confusing here: most optimization techniques exploit the problem structure, think linear, disciplined convex, semi-definite; anything beyond non-linear differentiable or black-box optimization will use the specific structure in a specialized algorithm. If standard functions from your programming language are used, no structure can be leveraged by the solver, which only sees a function pointer it can pass values to. So working with mathematical optimization forces you to re-think what you call \u0026ldquo;variables\u0026rdquo; and what you call \u0026ldquo;functions\u0026rdquo;.\nThere is something we can do for the function part, which is defining arithmetic rules over variables and expressions, which is for instance what the JuMP modelling framework does: using JuMP m = Model() @variable(m, x1 \u0026gt;= 0) @variable(m, x2 \u0026gt;= 0) # random affine function f(a, b) = π + 3a + 2b f(x1, x2) # returns a JuMP.GenericAffExpr{Float64,VariableRef} @variable(m, y) f(x1, x2) + y # also builds a JuMP.GenericAffExpr{Float64,VariableRef}\nThis works especially well with affine functions because composing affine expressions builds other affine expressions but gets more complex any time other types of constraints are added. For some great resource on types and functions for mathematical optimization, watch Prof. Madeleine Udell\u0026rsquo;s talk at JuliaCon17 (the Julia syntax is from a pre-1.0 version, it may look funny).\nEncoding possibilities as sum-types Getting back to evaluation, to make this work, you need to know what values variables hold. What if the model hasn\u0026rsquo;t been optimized yet? You could take:\n A numerical approach and return NaN (floating point value for Not-A-Number) An imperative approach and throw an error when we evaluate an expression without values set or the model optimized A typed functional approach and describe the possibility of presence/absence of a value through types  The first approach was JuMP 0.18 and prior, the second is JuMP 0.19 and onward, the third is the one of interest to us, if we want to describe what is happening through types.\nIf you show these three options to a developer used to statically-typed functional programming, they would tell you that the first option coming to mind is an option, a type which can be either some value or nothing. In the case of an optimization model, it would be some numerical value if we have a value to return (that is, we optimized the model and found a solution). The problem is, there are many reasons for which you may have or not a value. What you could do in that case is get more advanced information from your model. This is the approach JuMP is taking with a bunch of model attributes you can query at any time, see the documentation for things you can query at any time.\nThe problem is that querying information on the status of the problem (solved, unsolved, impossible to solve\u0026hellip;) and getting values attached to variables can be unrelated. m = Model() @variable(m, x \u0026gt;= 0) @variable(m, y \u0026gt;= 0) # getting status: nothing because not optimized termination_status(m) # OPTIMIZE_NOT_CALLED::TerminationStatusCode = 0 primal_status(m) # NO_SOLUTION::ResultStatusCode = 0 JuMP.value(x) # ERROR: NoOptimizer() # woops, we forgot that we hadn\u0026#39;t optimized yet\nThis is indeed because x does not exist by itself, there is a \u0026ldquo;magic bridge\u0026rdquo; between the variable x and the model m. The computer science term for this \u0026ldquo;magic bridge\u0026rdquo; is a side-effect, the same kind as mentioned earlier when we set the value of a variable at the global scope. Again, they are fine at a small scale but are often the parts making a program confusing. Every time I\u0026rsquo;m reviewing some code by researchers starting out, the first thing I encourage them to do is to create self-contained bits of code within functions and remove mutable global state.\nA typed solution for describing mathematical problems We stated that the variables and model are bound together. In that case, let us not split them but describe them as one thing and since this one thing accepts different possible states, we will use tagged unions, which you can think of as C enumerations with associated values. Other synonyms for this construct are sum types (as in OCaml and Haskell).\nWe can think of the solution process of an optimization problem at a high level as a function:\nsolve(Model(Variables, Constraints, Objective)) -\u0026gt; OptimizationResult Where OptimizationResult is a sum type:\nOptimizationResult = Infeasible(info) | Unbounded(info) | Optimal(info) | NearOptimal(info) ... In this case, everything can stay immutable, expressions including objective and constraints are only used to build the model in input, they can be evaluated at any points and just describe some expressions of variables. The value of the variables resulting from the optimization are on available in cases where it makes sense. If the results are stored in the solution info structure, we can query values where it makes sense only, here in the Optimal and NearOptimal cases, with a syntax like:\nmatch OptimizationResult { Optimal(info) -\u0026gt; value(info, x) # or info.value(x) Infeasible(info) -\u0026gt; ... Unbounded(info) -\u0026gt; ... } Internally, info would keep an association from variables to corresponding values. No more confusion on what binding of your computer program represents what symbolic variable of your problem.\nSo why would we keep using these bindings associated with variables, if they have never been independent from the problem in the first place? The obvious reason that comes to mind is practical syntax, we can write expressions in a quasi-mathematical way (here in JuMP): @expression(m, 3x + 2x^2 \u0026lt;= 4y)\nWhile if variables were attached to the model, the required syntax would be in the flavour of: @expression(m, 3m[:x] + 2m[:x]^2 \u0026lt;= 4m[:y])\nWhich quickly becomes hard to read. Can we do better?\nStealing a solution elsewhere I stumbled upon an interesting solution to such problem while reading the documentation for various probabilistic programming languages built on top of Julia. Here is one example from Turing.jl @model gdemo(x, y) = begin s ~ InverseGamma(2,3) m ~ Normal(0,sqrt(s)) x ~ Normal(m, sqrt(s)) y ~ Normal(m, sqrt(s)) end # sample from the model using an algorithm chn = sample(gdemo(1.5, 2), HMC(1000, 0.1, 5))\nIt\u0026rsquo;s just one step away from imagining the same for optimization: @optim_model linmodel(a, b) = begin x[1:10] \u0026gt;= 0 5 \u0026lt;= y \u0026lt;= 10 z ∈ 𝔹 cons1: y - 5 \u0026lt;= 5z cons2: x + y \u0026gt;= 3 Min x end result = optimize(linmodel)\nNaming the constraints would be necessary to retrieve associated dual values. Retrieving values associated with variables could be done in an associative structure (think a dictionary/hash map). This structure removes any confusion as to what belongs where in an optimization model. The variables x, y, z are indeed defined within a given model and explicitly belong to it.\nWhy are interfaces not built this way? Warning, speculative opinions below:\nOne reason is the ubiquity of C \u0026amp; C++ in optimization. The vast majority of commonly used solvers is built in either of these, supporting limited programming constructs and based on passing pointers around to change the values pointed to. Because the solvers are built like this, interfaces follow the same constructions. Once a dominant number of interfaces are identical, building something widely different is a disadvantage with a steeper learning curve.\nAnother more nuanced reason is that declarative software is hard to get right. One often has to build everything upfront, here in the @optim_model block. Getting meaningful errors is much harder, and debugging optimization models is already a tricky business.\nLastly, lots of algorithms are based on incremental modifications of models (think column and row generation), or combinations with other bricks. This requires some \u0026ldquo;hackability\u0026rdquo; of the model. If one looks at Algebraic Modelling Languages, everything seems to fall apart once you try to implement decompositions. Usually it involves a completely different syntax for the decomposition scheme (the imperative part) and for the model declaration (the declarative part).\nSo overall, even though side-effects are a central part of the barrier to the expression of mathematical optimization in a mathematical, type-based declarative way, they are needed because of the legacy of solvers and some algorithms which become hairy to express without it.\nFurther resources As pointed above, Prof. Madeleine Udell\u0026rsquo;s talk gives some great perspectives on leveraging types for expressive optimization modelling. For the brave and avid readers, this PhD thesis tackles the semantics of a formal language for optimization problems. If you have further resources on the subject, please reach out.\nThanks Richard for the initial post and the following discussion which led to this post. For shorter and nicely written posts on optimization, go read his blog.\nNote: I try never to use the terms \u0026ldquo;mathematical programming\u0026rdquo; and \u0026ldquo;mathematical program\u0026rdquo; which are respectively synonyms for \u0026ldquo;mathematical optimization\u0026rdquo; and \u0026ldquo;mathematical optimization problem\u0026rdquo; respectively. We can see why in this post: this kind of context where the term \u0026ldquo;program\u0026rdquo; could refer to a computer program or a mathematical problem becomes very confusing. We are in 2019 and the term \u0026ldquo;program\u0026rdquo; is now universally understood as a computer program. Moreover, \u0026ldquo;mathematical programming\u0026rdquo; merely refers to a problem specification, it is very confusing to say that \u0026ldquo;linear/semi-definite/convex programming\u0026rdquo; is merely meant as putting together a bunch of equations, not at all about how to tackle these.\n ","date":1556488800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557403969,"objectID":"43ed916a7a94f76a3d197360f50c5d35","permalink":"https://matbesancon.github.io/post/2019-04-14-optimization-function-evaluation/","publishdate":"2019-04-29T00:00:00+02:00","relpermalink":"/post/2019-04-14-optimization-function-evaluation/","section":"post","summary":"Some digging in representations for optimization modelling\n","tags":["optimization","jump","functional","python","julia"],"title":"Variables are not values: types and expressions in mathematical optimization","type":"post"},{"authors":null,"categories":null,"content":" I must admit I am not always the most talented at social events. One point I am especially bad at is remembering names, and it gets even harder when lots of people have similar or similar-sounding names. What if we could select a list of people with names as different from each other as possible?\nFirst some definitions, different here is meant with respect to the Hamming distance of any two names. This is far from ideal since Ekaterina would be quite far from Katerina, but it will do the trick for now.\nGraph-based mental model This sounds like a problem representable as a complete graph. The names are the vertices, and the weight associated with each edge $(i,j)$ is the distance between the names of the nodes. We want to take a subset of $k$ nodes, such that the sum of edge weights for the induced sub-graph is maximum. This is therefore a particular case of maximum (edge) weight clique problem over a complete graph, which has been investigated in [1, 2] among others.\nA mathematical optimization approach This model can be expressed in a pretty compact way:\n$$ \\max_{x,y} \\sum_{(i,j)\\in E} c_{ij} \\cdot y_{ij} $$ subject to: $$ 2y_{ij} \\leq x_i + x_j ,, \\forall (i,j) \\in E$$ $$ \\sum_{i} x_i \\leq k $$ $$x_i, y_{ij} \\in \\mathbb{B} $$\nThe graph is complete and undirected, so the set of edges is:\n$ E = $ {$ (i,j) | i \\in $ {$ 1..|V| $}$, j \\in ${$ 1..i-1 $}}\nIt\u0026rsquo;s an integer problem with a quadratic number of variables and constraints. Some other formulations have been proposed, and there may be a specific structure to exploit given that we have a complete graph. For the moment though, this generic formulation will do.\nA Julia implementation What we want is a function taking a collection of names and returning which are selected. The first thing to do is build this distance matrix. We will be using the StringDistances.jl package not to have to re-implement the Hamming distance.\nimport StringDistances hamming(s1, s2) = StringDistances.evaluate(StringDistances.Hamming(), s1, s2) function build_dist(vstr, dist = hamming) return [dist(vstr[i], vstr[j]) for i in eachindex(vstr), j in eachindex(vstr)] end We keep the option to change the distance function with something else later. The optimization model can now be built, using the distance function and $k$, the maximum number of nodes to take.\nusing JuMP import SCIP function max_clique(dist, k) m = Model(with_optimizer(SCIP.Optimizer)) n = size(dist)[1] @variable(m, x[1:n], Bin) @variable(m, y[i=1:n,j=1:i-1], Bin) @constraint(m, sum(x) \u0026lt;= k) @constraint(m, [i=1:n,j=1:i-1], 2y[i,j] \u0026lt;= x[i] + x[j]) @objective(m, Max, sum(y[i,j] * dist[i,j] for i=1:n,j=1:i-1)) return (m, x, y) end I\u0026rsquo;m using SCIP as an integer solver to avoid proprietary software, feel free to switch it for your favourite one. Note that we don\u0026rsquo;t optimize the model yet but simply build it. It is a useful pattern when working with JuMP, allowing users to inspect the build model or add constraints to it before starting the resolution. The last steps are straightforward:\ndist = build_dist(vstr) (m, x, y) = max_clique(dist, k) optimize!(m) # solve the problem # get the subset of interest diverse_names = [vstr[i] for i in eachindex(vstr) if JuMP.value(x[i]) ≈ 1.] And voilà.\nTrying out the model I will use 50 real names taken from the list of random names website, which you can find here. The problem becomes large enough to be interesting, but reasonable enough for a decent laptop. If you want to invite 4 of these people and get the most different names, Christian, Elizbeth, Beulah and Wilhelmina are the ones you are looking for.\nBonus and random ideas It is computationally too demanding for now, but it would be interesting to see how the total sum of distances evolves as you add more people.\nAlso, we are using the sum of distances as an objective to maximize. One interesting alternative would be to maximize the smallest distance between any two nodes in the subset. This changes the model, since we need to encode the smallest distance using constraints. We will use an indicator constraint to represent this:\n$$\\max_{x,y} d $$ subject to: $$ y_{ij} \\Rightarrow d \\leq c_{ij} ,, \\forall (i,j) \\in E$$ $$ 2y_{ij} \\leq x_i + x_j \\forall (i,j) \\in E $$ $$ \\sum_{(i,j) \\in E} y_{ij} = k\\cdot (k-1) $$\nDepending on the solver support, the indicator constraint can be modelled directly, with big M or SOS1 constraints. This remains harder than the initial model.\nSpecial thanks to Yuan for bringing out the discussion which led to this post, and to BYP for the feedback.\n Sources [1] Alidaee, Bahram, et al. \u0026ldquo;Solving the maximum edge weight clique problem via unconstrained quadratic programming.\u0026rdquo; European Journal of Operational Research 181.2 (2007): 592-597.\n[2] Park, Kyungchul, Kyungsik Lee, and Sungsoo Park. \u0026ldquo;An extended formulation approach to the edge-weighted maximal clique problem.\u0026rdquo; European Journal of Operational Research 95.3 (1996): 671-682.\n","date":1554588000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557328745,"objectID":"01a2c2b9f10659f8bb42c5548961c487","permalink":"https://matbesancon.github.io/post/2019-04-07-name_distances/","publishdate":"2019-04-07T00:00:00+02:00","relpermalink":"/post/2019-04-07-name_distances/","section":"post","summary":"Making social events easier as a graph problem.\n","tags":["julia","optimization","jump","graph","integer-optimization"],"title":"Picking different names with integer optimization","type":"post"},{"authors":null,"categories":null,"content":" This post explores the possibility to build static lists in Julia, meaning lists for which the size is known at compile-time. This is inspired by a post on a Scala equivalent but will take different roads to see more than a plain port. Of course, this implementation is not that handy nor efficient but is mostly meant to push the limits of the type system, especially a trick of using recursive types as values (replacing a dependent type system). Some other references:\n The list operations are inspired by the implementation in DataStructures.jl StaticArrays.jl is a good inspiration for static data structures in Julia  First thoughts: value type parameter Julia allows developers to define type parameters. In the case of a list, the most obvious one may be the type of data it contains: abstract type MyList{T} end\nSome types are however parametrized on other things, if we look at the definition of AbstractArray for example:\n  AbstractArray{T,N}  Supertype for N-dimensional arrays (or array-like types) with elements of type T.\n The two type parameters are another type T and integer N for the dimensionality (tensor rank). The only constraint for a value to be an acceptable type parameter is to be composed of plain bits, complying with isbitstype.\nThis looks great, we could define our StaticList directly using integers.\n\u0026#34;\u0026#34;\u0026#34; A static list of type `T` and length `L` \u0026#34;\u0026#34;\u0026#34; abstract type StaticList{T,L} end struct Nil{T} \u0026lt;: StaticList{T,0} end StaticList{T}() where T = Nil{T}() StaticList(v::T) where T = Cons(v, Nil{T}()) struct Cons{T,L} \u0026lt;: StaticList{T,L+1} h::T t::StaticList{T,L} function Cons(v::T, t::StaticList{T,L}) where {T,L} new{T,L}(v,t) end end # Usage: # Cons(3, Nil{Int}()) is of type StaticList{Int,1} # Cons(4, Cons(3, Nil{Int}())) is of type StaticList{Int,2} If you try to evaluate this code, you will get an error: ERROR: MethodError: no method matching +(::TypeVar, ::Int64)\nPretty explicit, you cannot perform any computation on values used as type parameters. With more complex operations, this could make the compiler hang, crash or at least perform poorly (we would be forcing the compiler to execute this code at compile-time).\nOne way there might be around this is macros or replacing sub-typing with another mechanism. For the macro-based approach, ComputedFieldTypes.jl does exactly that. More discussion on computed type parameters in [1] and [2].\nEdit: using integer type parameters can be achieved using ComputedFieldTypes.jl as such:\njulia\u0026gt; using ComputedFieldTypes julia\u0026gt; abstract type StaticList{T,L} end julia\u0026gt; struct Nil{T} \u0026lt;: StaticList{T,0} end julia\u0026gt; @computed struct Cons{T,L} \u0026lt;: StaticList{T,L} h::T t::StaticList{T,L-1} function Cons(v::T, t::StaticList{T,L0}) where {T,L0} L = L0+1 new{T,L}(v,t) end end julia\u0026gt; Cons(3, Nil{Int}()) Cons{Int64,1,0}(3, Nil{Int64}()) julia\u0026gt; Cons(4, Cons(3, Nil{Int}())) Cons{Int64,2,1}(4, Cons{Int64,1,0}(3, Nil{Int64}())) This might be the neatest option for building the StaticList.\nRecursive natural numbers We can use the same technique as in the Scala post, representing natural number using recursive types.\n ZeroLength is a special singleton type Next{L} represents the number following the one represented by L  We can modify our previous example: \u0026#34;\u0026#34;\u0026#34; A type parameter for List length, the numerical length can be retrieved using `length(l::Length)` \u0026#34;\u0026#34;\u0026#34; abstract type Length end struct ZeroLength \u0026lt;: Length end struct Next{L\u0026lt;:Length} \u0026lt;: Length end \u0026#34;\u0026#34;\u0026#34; A linked list of size known at compile-time \u0026#34;\u0026#34;\u0026#34; abstract type StaticList{T,L\u0026lt;:Length} end struct Nil{T} \u0026lt;: StaticList{T,ZeroLength} end StaticList{T}() where T = Nil{T}() StaticList(v::T) where T = Cons(v, Nil{T}()) struct Cons{T,L\u0026lt;:Length} \u0026lt;: StaticList{T,Next{L}} h::T t::StaticList{T,L} function Cons(v::T, t::StaticList{T,L}) where {T,L\u0026lt;:Length} new{T,L}(v,t) end end \u0026#34;\u0026#34;\u0026#34; By default, the type of the Nil is ignored if different from the type of first value \u0026#34;\u0026#34;\u0026#34; Cons(v::T,::Type{Nil{T1}}) where {T,T1} = Cons(v, Nil{T}())\nWe can then define basic information for a list, its length:\nBase.length(::Type{ZeroLength}) = 0 Base.length(::Type{Next{L}}) where {L} = 1 + length(L) Base.eltype(::StaticList{T,L}) where {T,L} = T Base.length(l::StaticList{T,L}) where {T,L} = length(L) One thing should catch your attention in this block, we use a recursive definition of length for the Length type, which means we can blow our compiler. However, both of the definitions are static, in the sense that they don\u0026rsquo;t use type information, so the final call should reduce to spitting out the length cached at compile-time. You can confirm this is the case by checking the produced assembly instructions with @code_native. We respected our contract of a list with size known at compile-time.\nImplementing a list-y behaviour This part is heavily inspired by the DataStructures.jl list implementation, as such we will not re-define methods with semantically similar but implement them for our list type. Doing so for your own package allows user to switch implementation for the same generic code.\nThe first operation is being able to join a head with an existing list:\nDataStructures.cons(v::T,l::StaticList{T,L}) where {T,L} = Cons(v,l) \u0026#34;\u0026#34;\u0026#34; Allows for `cons(v,Nil)`. Note that the `Nil` type is ignored. \u0026#34;\u0026#34;\u0026#34; DataStructures.cons(v::T,::Type{Nil}) where {T} = StaticList(v) (::Colon)(v::T,l::StaticList{T,L}) where {T,L} = DataStructures.cons(v, l) (::Colon)(v::T,::Type{Nil}) where {T,L} = DataStructures.cons(v, Nil{T}) Implementing the odd ::Colon methods allows for a very neat syntax:\nl0 = StaticList{Int}() l1 = 1:l0 l2 = 2:l1 Unlike the Scala post, we are not using the :: operator which is reserved for typing expressions in Julia. We can add a basic head and tail methods, which allow querying list elements without touching the inner structure. This will be useful later on.\nDataStructures.head(l::Cons{T,L}) where {T,L} = l.h DataStructures.tail(l::Cons{T,L}) where {T,L} = l.t Testing list equality can be done recursively, dispatching on the three possible cases:\n==(l1::StaticList, l2::StaticList) = false function ==(l1::L1,l2::L2) where {T1,L,T2,L1\u0026lt;:Cons{T1,L},L2\u0026lt;:Cons{T2,L}} l1.h == l2.h \u0026amp;\u0026amp; l1.t == l2.t end \u0026#34;\u0026#34;\u0026#34; Two `Nil` are always considered equal, no matter the type \u0026#34;\u0026#34;\u0026#34; ==(::Nil,::Nil) = true We can now define basic higher-order functions, such as zip below, and implement the iteration interface.\nfunction Base.zip(l1::Nil{T1},l2::StaticList{T2,L2}) where {T1,T2,L2} Nil{Tuple{T1,T2}} end function Base.zip(l1::Cons{T1,L1},l2::Cons{T2,L2}) where {T1,L1,T2,L2} v = (l1.h, l2.h) Cons(v,zip(l1.t,l2.t)) end Base.iterate(l::StaticList, ::Nil) = nothing function Base.iterate(l::StaticList, state::Cons = l) (state.h, state.t) end Iterating over our lists is fairly straight-forward, and will be more efficient than the recursive implementations of the higher-order functions, we still kept it for equality checking, more a matter of keeping a functional style in line with the Scala post.\nThe case of list reversal is fairly straightforward: iterate and accumulate the list in a new one.\nfunction Base.reverse(l::StaticList{T,L}) where {T,L} l2 = Nil{T} for h in l l2 = Cons(h, l2) end l2 end We define the cat operation between multiple lists.\nfunction Base.cat(l1::StaticList{T,L},l2::StaticList{T,L}) where {T,L} l = l2 for e in reverse(l1) l = Cons(e, l) end l end The reverse is necessary to keep the order of the two lists.\nSpecial-valued lists Now that we have a basic static list implementation, we can spice things up. StaticList is just an abstract type in our case, not an algebraic data type as in common functional implementations, meaning we can define other sub-types.\nImagine a numeric list, with a series of zeros or ones somewhere. Instead of storing all of them, we can find a smart way of representing them. Let us define a static list of ones:\nstruct OnesStaticList{T\u0026lt;:Number,L\u0026lt;:Length} end Base.iterate(l::OnesStaticList, ::Type{ZeroLength}) = nothing function Base.iterate(l::OnesStaticList{T,L}, state::Type{Next{L1}} = L) where $ (one(T), L1) end This list corresponds to the 1 value of type T, repeated for all elements. In a similar fashion, one can define a ZeroList:\nstruct ZerosStaticList{T\u0026lt;:Number,L\u0026lt;:Length} end Base.iterate(l::ZerosStaticList, ::Type{ZeroLength}) = nothing function Base.iterate(l::ZerosStaticList{T,L}, state::Type{Next{L1}} = L) where$ (zero(T), L1) end One thing to note is that these lists are terminal, in the sense that they cannot be part of a greater list. To fix this, we can add a tail to these as follows: struct ZerosStaticList{T\u0026lt;:Number,L\u0026lt;:Length,TL\u0026lt;:StaticList{T,\u0026lt;:Length}} t::TL end Base.iterate(l::ZerosStaticList, ::Type{ZeroLength}) = l.t function Base.iterate(l::ZerosStaticList{T,L}, state::Type{Next{L1}} = L) where$ (zero(T), L1) end\nThe t field of the list contains the tail after the series of zeros, we can thus build a much simpler representation in case of long constant series. In a similar fashion, one could define a constant list of N elements, storing the value just once.\nMulti-typed lists There is one last extension we can think of with this data structure. Since we have a recursive length parameter, why not add it a type at each new node?\nabstract type TLength end struct TZeroLength \u0026lt;: TLength end struct TNext{T,L\u0026lt;:TLength} \u0026lt;: TLength end abstract type TStaticList{L\u0026lt;:TLength} end struct TNil \u0026lt;: TStaticList{TZeroLength} end struct TCons{T, L\u0026lt;:TLength} \u0026lt;: TStaticList{TNext{T,L}} h::T t::TStaticList{L} function TCons(v::T, t::TStaticList{L}) where {T,L\u0026lt;:TLength} new{T,L}(v,t) end end With such construct, all nodes can be of a different type T, without removing the type information from the compiler.\njulia\u0026gt; TCons(3,TNil()) TCons{Int64,TZeroLength}(3, TNil()) julia\u0026gt; TCons(\u0026#34;ha\u0026#34;, TCons(3,TNil())) TCons{String,TNext{Int64,TZeroLength}}(\u0026#34;ha\u0026#34;, TCons{Int64,TZeroLength}(3, TNil())) One interesting thing to note here is that the type takes the same structure as the list itself:\nType: either a T and a TLength containing the rest of the type, or TNil\nData: either a value of a given type and the rest of the list, or empty list\nConclusion The Julia type system and compiler allow for sophisticated specifications when designing data structures, which gives it a feel of compiled languages. This however should not be abused, in our little toy example, the type parameter grows in complexity as the list does, which means the compiler has to carry out some computation.\nIf you want some further compile-time tricks, Andy Ferris\u0026rsquo;s workshop at JuliaCon 2018 details how to perform compile-time computations between bits and then bytes.\nIf you have any idea how to implement StaticList using integer parameters instead of custom struct I would be glad to exchange. Porting this to use ComputedFieldTypes.jl might be a fun experiment.\nFeel free to reach out any way you prefer, Twitter, email to exchange or discuss this post.\n Sources Header image source: https://pxhere.com/en/photo/742575\n[1] A proposal on Julia \u0026ldquo;Defer calculation of field types until type parameters are known\u0026rdquo;, julia/issues/18466 [2] Discussion on compile-time computations on Discourse\n","date":1553900400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554670576,"objectID":"d04262380247a1ac96d69d0161a612e5","permalink":"https://matbesancon.github.io/post/2019-03-30-static-list/","publishdate":"2019-03-30T00:00:00+01:00","relpermalink":"/post/2019-03-30-static-list/","section":"post","summary":"Pushing the type system for more compile-time information\n","tags":["julia"],"title":"Static lists in Julia","type":"post"},{"authors":null,"categories":null,"content":" While reading books, lots of thoughts come and go, especially if the subject resonates and is connected to topics of interest. If the book is a novel or other fiction, I try to keep these thoughts away to remain in the universe and story. For non-fiction though, some of these thoughts constitute valuable elements to put on a larger frame, with other publications, slowly building context for the topics at hand. The Entrepreneurial State, by Mariana Mazzucato, definitely has some elements to put on a larger frame of economic policy, economics, on the perceived and actual role of the state and its institutions.\nChanging the narrative The main point and argument of the book is brilliant: re-trace the facts about the development of some technologies, companies, industries to challenge the established, implicit or explicit narrative about the state\u0026rsquo;s role. In that case, the narrative is the sacred effect of the market and individual entrepreneurs for building today\u0026rsquo;s greatest achievements.\nThe unexpected HR argument One point I never thought about before reading the book is the talent pool each side is taking from. While keeping the sexy part of the narrative, the private firms will always attract the best talents. For sure, some people will join public services for the greater good, but some necessary talents might not join because they have major criteria on what to achieve.\nIf the narrative is that public institutions are there simply for controlling and punctually fixing the economy, lots of talents will be driven by private firms able to offer them to actually accomplish things and move forward. If the State is now seen as the voice setting the direction for the coming years and the rules to get there before letting the children out on the playground, people working in the \u0026ldquo;development department\u0026rdquo; as Mazzucato calls it play a part in a strategic role they would not have in the firms themselves.\nIf you think about it, the only public servants glorified and pictured with cool jobs in today\u0026rsquo;s representation are linked to the military or police. Think of recent corporate series you\u0026rsquo;ve seen, public servants are always those envious ones who didn\u0026rsquo;t have the courage to take the risky path.\nOh no, Apple again To add some context, the first edition of the book was out in 2013. If I try to remember the ambient perception, tech was not yet the evil eating the world, building a startup was still freaking your parents out (at least if you lived in France), Bitcoin was still nerds' or drugs money. And Apple was still in the general opinion the cool company building slick products. A chapter of the book is specifically dedicated to the company and how it has been helped by the US federal and state governments at various stages and for various steps of its rise. The narrative the author sets is that even the most innovative, \u0026ldquo;entrepreneurial\u0026rdquo;, garage-born companies got helped by the government all the way through, whatever version of it is told by them, the media or VCs. Still, this is a personal touch, but Apple has never been fascinating, nor have I admired the firm more than others, or had this \u0026ldquo;wow\u0026rdquo; effect to friends getting jobs there. It\u0026rsquo;s still a consumer firm building expensive toys, not solving the world\u0026rsquo;s problem. The problem with this chapter is that I agreed with the author\u0026rsquo;s underlying point before even starting it, so the content I read felt mostly like a bunch of historical facts on a company I am not that interested in.\nChanging energy systems Currently involved in a PhD involving thinking new decision processes for power grids, I naturally got thrilled to see a chapter on renewable generation and green business. The author mentions the parallel and applications of IT to these new challenges, with the nice mention of \u0026ldquo;throwing software at the problem\u0026rdquo; [1], referring to designing algorithms to cope with solar and wind power intermittency. In that case, it is indeed necessary but not sufficient. Software will at most bring information within reach of the agents needing it at the right time. This availability is only a prerequisite for enabling better decision-making in power systems, creating value shared between the different levels contributing to the various improvements. See recent work in journals such as IEEE Transactions on Power Systems / on Smart Grids, the hard problems are not data collection or transmission but making decision under various types of constraints. Nonetheless, it was a nice surprise to read an economist\u0026rsquo;s view, summary and prediction for smart grids, with mentions of programs such as demand response.\nThe danger of the strawman This might be one central critic to the book, from an argument construction perspective. The whole stream of thought is built around a de- and reconstruction of the role of the State for major innovations, past and present. There is however the continuous danger of a strawman argument, the detractors of the role of the states are often described as \u0026ldquo;they\u0026rdquo;, and referred to vaguely compared to other topics for which the author provides numerous references. In comparison, re-using the same article from the Economist for the other side of the argument seems like an unfair trial.\nGoing further, other critical angles If you have one take-away from this post, the book is worth reading in depth and thinking over. It strikes a nice balance between the academic rigour, providing plenty of references to go further on different topics and developing arguments with care, while staying pleasant to read before going to bed, during your commute or with your favourite cup of Earl Grey.\nNot being an economist, I will not go far in comparison to other schools of thought on industrial and innovation policies. Feel free to check those other articles shedding another light on the ideas developed in the book for critical points of view but mostly this excellent summary and analysis by Nicolas Colin, whose book Hedge is next on my reading list.\nFeel free to reach out any way you prefer, Twitter, email to exchange or discuss the book or this post.\n Sources [1] \u0026ldquo;Powering the Dream: The History and Promise of Green Technology\u0026rdquo; Madrigal, 2011\n","date":1552863600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553457257,"objectID":"9ff4ca764329a6e65747f91ea9ec2731","permalink":"https://matbesancon.github.io/post/2019-01-24-entrepreneurial-state-review/","publishdate":"2019-03-18T00:00:00+01:00","relpermalink":"/post/2019-01-24-entrepreneurial-state-review/","section":"post","summary":"Some thoughts and notes on an industrial policy book.\n","tags":["book","economics"],"title":"Book review: the Entrepreneurial State","type":"post"},{"authors":null,"categories":null,"content":"In a recent pull request on a personal project, I spent some time designing an intuitive API for a specific problem. After reaching a satisfying result, I realized this would never have been possible without one of the central mechanisms of the Julia language: multiple dispatch. Feel free to read the Julia docs on the topic or what Wikipedia has to say about it.\nThis post is a walkthrough for multiple dispatch for a case in mathematical optimization. The first part will introduce the problem context and requires some notion in mathematical optimization, if this stuff is scary, feel free to skip to the rest directly.\nRefresher on if-then-else constraints I promised an example oriented towards mathematical optimization, here it is: it is common to model constraints with two variables $(x, y)$, $x$ continuous and $y$ binary stating:\n $y = 0 \\Rightarrow x = 0$ If $y = 1$, there is no specific constraint on $x$  Some examples of models with such constraint:\n Facility location: if a wharehouse is not opened, $y = 0$, then the quantity served by this point has to be $x = 0$, otherwise, the quantity can go up to the wharehouse capacity. Unit commitment (a classic problem for power systems): if a power plant has not been activated for a given hour, then it cannot supply any power, otherwise, it can supply up to its capacity. Complementarity constraints: if a dual variable $\\lambda$ is 0, then the corresponding constraint is not active (in non-degenerate cases, the slack variable is non-zero)  Logical constraints with such if-then-else structure cannot be handled by established optimization solvers, at least not in an efficient way. There are two usual ways to implement this, \u0026ldquo;big-M\u0026rdquo; type constraints and special-ordered sets of type 1 SOS1.\nA SOS1 constraint specifies that out of a set of variables or expressions, at most one of them can be non-zero. In our case, the if-then-else constraint can be modeled as: $$SOS1(x,, 1-y)$$\nMost solvers handling integer variables can use these $SOS1$ constraints within a branch-and-bound procedure.\nThe other formulation is using an upper-bound on the $x$ variable, usually written $M$, hence the name:\n$$x \\leq M \\cdot y $$\nIf $y=0$, $x$ can be at most 0, otherwise it is bounded by $M$. If $M$ is sufficiently big, the constraint becomes inactive. However, smaller $M$ values yield tighter formulations, solved more efficiently. See Paul Rubin\u0026rsquo;s detailed blog post on the subject. If we want bounds as tight as possible, it is always preferable to choose one bound per constraint, instead of one unique $M$ for them all, which means we need a majorant of all individual $M$.\nAs a rule of thumb, big-M constraints are pretty efficient if $M$ is tight, but if we have no idea about it, SOS1 constraints may be more interesting, see [1] for recent numerical experiments applied to bilevel problems.\nModeling if-then-else constraints Now that the context is set, our task is to model if-then-else constraints in the best possible way, in a modeling package for instance. We want the user to specify something as:\nfunction handle_ifthenelse(x, y, method, params) # build the constraint with method using params end Without a dispatch feature baked within the language, we will end up doing it ourselves, for instance in:\nfunction handle_ifthenelse(x, y, method, params) if typeof(method) == SOS1Method # model as SOS1Method elseif typeof(method) == BigMMethod # handle as big M with params else throw(MethodError(\u0026#34;Method unknown\u0026#34;)) end end NB: if you have to do that in Julia, there is a isa(x, T) function verifying if x is a T in a more concise way, this is verifying sub-typing instead of type equality, which is much more flexible.\nThe function is way longer than necessary, and will have to be modified every time. In a more idiomatic way, what we can do is:\nstruct SOS1Method end struct BigMMethod end function handle_ifthenelse(x, y, ::SOS1Method) # model as SOS1Method end function handle_ifthenelse(x, y, ::BigMMethod, params) # handle as big M with params end Much better here, three things to notice:\n This may look similar to pattern matching in function arguments if you are familiar with languages as Elixir. However, the method to use can be determined using static dispatch, i.e. at compile-time. We don\u0026rsquo;t need to carry around params in the case of the SOS1 method, since we don\u0026rsquo;t use them, so we can adapt the method signature to pass only what is needed. This code is much easier to document, each method can be documented on its own type, and the reader can refer to the method directly.  Cherry on top, any user can define their own technique by importing our function and defining a new behavior: import OtherPackage # where the function is defined struct MyNewMethod end function handle_ifthenelse(x, y, ::MyNewMethod) # define a new method for ifthenelse, much more efficient end\nHandling big M in an elegant way We have seen how to dispatch on the technique, but still we are missing one point: handling the params in big-M formulations. If you have pairs of $(x_j,y_j)$, then users may want:\n$$ x_j \\leq M_j \\cdot y_j,, \\forall j $$\nOr: $$ x_j \\leq M \\cdot y_j,, \\forall j $$\nThe first formulation requires a vector of M values, and the second one requires a scalar. One default option would be to adapt to the most general one: if several M values are given, build a vector, if there is only one, repeat it for each $j$. One way to do it using dynamic typing: struct BigMMethod end function handle_ifthenelse(x, y, ::BigMMethod, M::Union{Real,AbstractVector{\u0026lt;:Real}}) if M isa Real # handle with one unique M else # it is a vector # handle with each M[j] end end\nNote that we can constrain the type of M to be either a scalar or a Vector using Union type. Still, this type verification can be done using dispatch, and we can handle the multiple cases:\nstruct BigMMethod end \u0026#34;\u0026#34;\u0026#34; Use one unique big M value \u0026#34;\u0026#34;\u0026#34; function handle_ifthenelse(x, y, ::BigMMethod, M::Real) # handle with one unique M end \u0026#34;\u0026#34;\u0026#34; Use a vector of big M value \u0026#34;\u0026#34;\u0026#34; function handle_ifthenelse(x, y, ::BigMMethod, Mvec::AbstractVector) # handle with each Mvec[j] end This solution is fine, and resolving most things at compile-time. Also, note that we are defining one signature as a convenience way redirecting to another.\nPolishing our design: enriched types The last solution is great, we are dispatching on our algorithm and parameter types. However, in a realistic research or development work, many more decisions are taken such as algorithms options, number types, various parameters. We will likely end up with something similar to:\nfunction do_science(x, y, z, ::Alg1, params_alg_1, ::Alg2, params_alg_2, ::Alg3, # algortithm 3 does not need parameters ::Alg4, params_alg_4) # do something with params_alg_1 for Alg1 # do something with params_alg_2 for Alg2 # ... end Requiring users to pass all arguments and types in the correct order. A long chain of positional arguments like this end makes for error-prone and cumbersome interfaces. Can we change this? We created all our types as empty structures struct A end and use it just to dispatch. Instead, we could store adapted parameters within the corresponding type:\nstruct Alg1 coefficient::Float64 direction::Vector{Float64} end # define other types function do_science(x, y, z, a1::Alg1, a2::Alg2, ::Alg3, a4::Alg4) # do something with params_alg_1 for Alg1 # a1.coefficient, a1.direction... # do something with Alg2 # ... end Getting back to our initial use case of BigMMethod, we need to store the $M$ value(s) in the structure: struct BigMMethod M::Union{Float64, Vector{Float64}} end\nThis seems fine, however, the Julia compiler cannot know the type of the M field at compile-time, instead, we can use a type parameter here: struct BigMMethod{MT\u0026lt;:Union{Real, AbstractVector{\u0026lt;:Real}}} M::MT BigMMethod(M::MT) where {MT} = new{MT}(M) end\nWhen constructing the BigMMethod with this definition, it can be specialized on MT, the type of M, two examples of valid definitions are: BigMMethod(3.0) # result: BigMMethod{Float64}(3.0) BigMMethod(3) # result: BigMMethod{Int}(3) BigMMethod([3.0, 5.0]) # result BigMMethod{Vector{Float64}}([3.0, 5.0])\nThe advantage is we can now specialize the handle_ifthenelse signature on the type parameter of M, as below:\n\u0026#34;\u0026#34;\u0026#34; Use one unique big M value \u0026#34;\u0026#34;\u0026#34; function handle_ifthenelse(x, y, bm::BigMMethod{\u0026lt;:Real}) # handle with one unique M bm.M end \u0026#34;\u0026#34;\u0026#34; Use a vector of big M value \u0026#34;\u0026#34;\u0026#34; function handle_ifthenelse(x, y, bm::BigMMethod{\u0026lt;:AbstractVector}) # handle with each bm.M[j] end The advantage is a strictly identical signature, whatever the method and its parameters, users will always call it with: handle_ifthenelse(x, y, bm::BigMMethod{\u0026lt;:AbstractVector})\nConclusion: avoiding a clarity-flexibility trade-off In this simple but commonly encountered example, we leveraged multiple dispatch, the ability to choose a function implementation depending on the type of its arguments. This helped us define a homogeneous interface for specifying a type of constraint, specializing on the method (SOS1 or big M) and on the data available (one M or a vector of M values).\nPerformance bonus, this design is providing the Julia compiler with strong type information while remaining flexible for the user. In Julia terminology, this property is called type stability. We would not have benefitted from this property if we had used reflection-based design (with typeof() and isa).\nThis idea of using big-M as an example did not come up in the abstract but is a simplification of the design used in the BilevelOptimization.jl package. Remember I mentioned complementarity constraints, it is exactly this use case.\nIf you are interested in more examples of multiple dispatch and hands-on use cases for the Julia type system, check out these two articles. Feel free to reach out any way you prefer, Twitter, email.\n Edit 1: thanks BYP for sharp proofreading and constructive critics.\nEdit 2: Thanks Mathieu Tanneau for pointing out the alternative solution of indicator constraints instead of big M, as documented in Gurobi, CPLEX.\nEdit 3: For more info on big M constraints and underlying issues, you can read Thiago Serra\u0026rsquo;s post, which includes nice visualizations of the problem space.\n Sources:\n[1] Henrik Carøe Bylling\u0026rsquo;s thesis, KU, http://web.math.ku.dk/noter/filer/phd19hb.pdf\n","date":1550962800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551464545,"objectID":"a89225f4619c744c2d52fcb80cecae6c","permalink":"https://matbesancon.github.io/post/2019-02-24-multiple-dispatch-optimizers/","publishdate":"2019-02-24T00:00:00+01:00","relpermalink":"/post/2019-02-24-multiple-dispatch-optimizers/","section":"post","summary":"Leveraging one of Julia central features for clearer formulation of an optimization problem.\n","tags":["optimization","julia"],"title":"Multiple dispatch - an example for mathematical optimizers","type":"post"},{"authors":null,"categories":null,"content":" After the first submissions to journals, most researchers will be contacted by editors for reviewing articles others have written. It may seem like a daunting task, evaluating the work someone else put several months to prepare, code, write, correct and submit.\nDisclaimer: to preserve the anonymity of the reviews I made and am making, all examples I give below are made up.\nThe main phases of my reviewing process are:\n What is this about? Can I review it? Is the paper in the scope of the journal? Are there some topics I might struggle to understand? Diving in, a first pass to get the story right Thematic passes \u0026amp; writing the recommendations  What is this about? Can I review it? After receiving the invitation and getting the manuscript, my screening phase consists in reading only these three elements:\n Title Abstract Keywords  At that point, I roughly know if it is relevant for both the journal and me that I review it. If I feel way out of scope, I\u0026rsquo;ll reach out to the editor. I will also quickly check the name of the authors to make sure I do not have a conflict of interests with any of them, without looking them up on the internet of course, the goal is to avoid bias if I know them at a personal level.\nNote: Since this only took a quick screening, it can be done in a day or two, letting the editor know too late that you will not review increases the time to publication which is bad for the author, the journal and scientific publication in general.\nIs the paper in the scope of the journal? At that point, I re-read the journal\u0026rsquo;s aim and scope and keep in mind the main ideas. If I am not that familiar with it, I will also check titles and abstracts of random papers in the last issues. This will help during the review if there are some doubts on the manuscript being at the right spot.\nAre there some topics I might struggle to understand? If I have doubts on some parts of the method or context and can identify them, I\u0026rsquo;ll search for foundational articles and reference text books on the subject.\nIn any case, it is predictable that not all reviewers of the paper cover the same area of expertise, especially for multi-disciplinary journals. Still, it is always better to be comfortable with all components. Take a case in mathematical optimization, for instance a manuscript tackling a problem in power systems, with a game theoretical aspect and formulating a Semi-Definite Positive model solved using a bundle method. I might be familiar with the application (power systems) and game-theoretical considerations in such domain, but without being an expert in SDP and even less bundle methods. This is not a reason to refuse the role of reviewer.\nHowever, not being proficient on a component can introduce a bias in the review by putting the reviewer on the defensive:\n \u0026ldquo;why do the authors need all this fuss with this thing I\u0026rsquo;ve never heard of, why not the good all techniques like what I do\u0026rdquo;.\n I\u0026rsquo;ve seen read different comments in reviews which looked a lot like this. This is why it can be valuable to take some time to get more familiar with shadow areas. Plus this makes reviewing a challenge and an excuse to learn something new and connected to my area.\nDiving in, a first pass to get the story right At that point, I book at least two hours for a first read of the paper, with a pen, a printed version and a notebook. I should eventually get a tablet to take notes on the PDF instead of print-outs but for the moment, the number of papers I am asked to review remains reasonable. I read it through without interruptions (no phone, no open browser, no music or music without lyrics), taking notes on the side on all things that cross my mind. Notes are of different types: small mistakes, remarkable points, key information and the \u0026ldquo;interrogation queue\u0026rdquo;. This queue is inspired by developers' code review and the most advanced metric found for it: An element is added in the queue when something is missing for my understanding here and has not been introduced upwards in the article. An element is removed from the queue when an explanation for it appears (so later in the article). Of course, any element remaining in the queue at the end of the manuscript is a problem: it is never explained, introduced properly. Two considerations play a role for the quality of the paper for its ease of understanding:\n How long is the queue at any point in the paper? Does it introduce too much cognitive load? How long is the distance between the appearance of an element in the queue? (the interrogation moment) and its removal (the aha moment)  The second point is easy to solve, just recommend introducing the concept before the place in the text where the interrogation appeared. The first point will require more work on the authors' side to displace all explanations before the introduction of the concept/symbol, reducing the overall cognitive load at any moment for the reader.\nThematic read \u0026amp; writing the recommendations After the first reading round, I usually have some ideas about what are the key axes of the review, I can start writing it up with all the small details (typos, clumsy or vague phrasing, etc), all that is not on the structure nor on the content. A good rule of thumb is that those minor corrections are limited to few words in just one sentence. After that, I write down different main axes, as for instance: \u0026ldquo;this step of the methodology section is not detailed enough\u0026rdquo; and quote either precise points in the text where the problem arises from and/or recommendations for fixing it: \u0026ldquo;this or that would make the article to be reproducible\u0026rdquo;. The deeper a problem is, the more discussion it brings, the goal is not to let the authors stuck with a blind comment, see the following examples nobody likes reading:\n \u0026ldquo;Some steps in Section III seem incorrect\u0026rdquo;\n How much does it cost to the reviewer to point out where and why exactly?\n \u0026ldquo;The authors did not manage to highlight a significant part of the literature\u0026rdquo;\n On which topic? What is not covered? Do you mean the authors did not cite your article?\nOnly after these last points am I 100% certain of the final recommendation I will give for the manuscript, the usual options are:\n With the minor modifications recommended, the paper is good to be published in my opinion. Some required modifications are major, re-submit for another reviewing round. The issues raised during review are too central to fix during review rounds, the work needs a huge re-write.  After forming this opinion, if I am not too late on the deadline, I will let myself some time off the review (a few days), and then come back to what I wrote to be sure every comment can be understood and used by the authors to improve the paper. Also, I want to be sure not to have written anything too rash. Nobody wants to be that reviewer.\nConclusion Even though peer review is considered a pillar of modern research, it has its history, qualities and flaws, and is fundamentally made by human beings and does not systematically reflect a universal truth; that should be kept in mind at all time. Also, the scientific communities should keep challenging it by making it evolve and experimenting new ways of carrying it out, addressing some key flaws. Note that I do not say the solutions presented in these articles are the ground truth, all I am stating is that it is worth opening the discussion, which academia is not doing much at the moment.\nMaybe you have other tips for reviewing papers, how do you improve your process? Which points were too domain-dependent / idealistic? (I did warn it was a naive view) Reach out any way you prefer, Twitter, email.\n [1] Source for the cover image: Journal des Savants or Journal Des Sçavans in old French, considered the earliest scientific journal. https://jamesgray2.me/2016/09/06/le-journal-des-savants-1681-1699/\n","date":1549234800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549447117,"objectID":"0b3b6c2f96ae5e7f8715532968f1fe97","permalink":"https://matbesancon.github.io/post/2019-02-04-article-review/","publishdate":"2019-02-04T00:00:00+01:00","relpermalink":"/post/2019-02-04-article-review/","section":"post","summary":"Gathering some thoughts on what worked and what did not.\n","tags":["academia"],"title":"A naive and incomplete guide to peer-review","type":"post"},{"authors":null,"categories":null,"content":"Enjoying the calm of the frozen eastern French countryside for the last week of 2018, I was struck by nostalgia while reading a SIAM news article [1] on a near-reversible heat exchange between two flows and decided to dust off my thermodynamics books (especially [2]).\nResearch in mathematical optimization was not the obvious path I was on a couple years ago. The joint bachelor-master\u0026rsquo;s program I followed in France was in process engineering, a discipline crossing transfer phenomena (heat exchange, fluid mechanics, thermodynamics), control, knowledge of the matter transformations at hand (chemical, biochemical, nuclear reactions) and industrial engineering (see note at the end of this page).\nHypotheses Throughout the article, we will use a set of flow hypotheses which build up the core of our model for heat exchange. These can seem odd but are pretty common in process engineering and realistic in many applications.\n The two flows advance in successive \u0026ldquo;layers\u0026rdquo;. Each layer has a homogeneous temperature; we therefore ignore boundary layer effects. Successive layers do not exchange matter nor heat. The rationale behind this is that the temperature difference between fluids is significantly higher than between layers. Pressure losses in the exchanger does not release a significant heat compared to the fluid heat exchange. The fluid and wall properties are constant with temperature.  Starting simple: parallel flow heat exchange In this model, both flows enter the exchanger on the same side, one at a hot temperature, the other at a cold temperature. Heat is exchanged along the exchanger wall, proportional at any point to the difference in temperature between the two fluids. We therefore study the evolution of two variables $u_1(x)$ and $u_2(x)$ in an interval $x \\in [0,L]$ with $L$ the length of the exchanger.\nIn any layer $[x, x + \\delta x]$, the heat exchange is equal to: $$\\delta \\dot{Q} = h \\cdot (u_2(x) - u_1(x)) \\cdot \\delta x$$ with $h$ a coefficient depending on the wall heat exchange properties.\nMoreover, the variation in internal energy of the hot flow is equal to $\\delta \\dot{Q}$ and is also expressed as:\n$$ c_2 \\cdot \\dot{m}_2 \\cdot (u_2(x+\\delta x) - u_2(x)) $$ $c_2$ is the calorific capacity of the hot flow and $\\dot{m}_2$ its mass flow rate. The you can check that the given expression is a power. The same expressions apply to the cold flow. Let us first assume the following:\n$$c_2 \\cdot \\dot{m}_2 = c_1 \\cdot \\dot{m}_1$$\nimport DifferentialEquations const DiffEq = DifferentialEquations using Plots function parallel_exchanger(du,u,p,x) h = p[1] # heat exchange coefficient Q = h * (u[1]-u[2]) du[1] = -Q du[2] = Q end function parallel_solution(L, p) problem = DiffEq.ODEProblem( parallel_exchanger, # function describing the dynamics of the system u₀, # initial conditions u0 (0., L), # region overwhich the solution is built, x ∈ [0,L] p, # parameters, here the aggregated transfer constant h ) return DiffEq.solve(problem, DiffEq.Tsit5()) end plot(parallel_solution([0.0,100.0], 50.0, (0.05))) $$ u_1(x) = T_{eq} \\cdot (1 - e^{-h\\cdot x}) $$ $$ u_2(x) = (100 - T_{eq}) \\cdot e^{-h\\cdot x} + T_{eq} $$\nWith $T_{eq}$ the limit temperature, trivially 50°C with equal flows.\n(Full disclaimer: I\u0026rsquo;m a bit rusty and had to double-check for errors)\nThis model is pretty simple, its performance is however low from a practical perspective. First on the purpose itself, we can compute for two fluids the equilibrium temperature. This temperature can be adjusted by the ratio of two mass flow rates but will remain a weighted average. Suppose the goal of the exchange is to heat the cold fluid, the necessary mass flow $\\dot{m}_2$ tends to $\\infty$ as the targeted temperature tends to $u_2(L)$, and this is independent of the performance of the heat exchanger itself, represented by the coefficient $h$. Here is the extended model using the flow rate ratio to adjust the temperature profiles:\nimport DifferentialEquations const DiffEq = DifferentialEquations function ratio_exchanger(du,u,p,x) h = p[1] # heat exchange coefficient r = p[2] # ratio of mass flow rate 2 / mass flow rate 1 Q = h * (u[1]-u[2]) du[1] = -Q du[2] = Q / r end function ratio_solution(u₀, L, p) problem = DiffEq.ODEProblem( ratio_exchanger, # function describing the dynamics of the system u₀, # initial conditions u0 (0., L), # region overwhich the solution is built, x ∈ [0,L] p, # parameters, here the aggregated transfer constant h ) return DiffEq.solve(problem, DiffEq.Tsit5()) end for (idx,r) in enumerate((1.0, 5.0, 10.0, 500.0)) plot(ratio_solution([0.0,100.0], 50.0, (0.05, r))) xlabel!(\u0026#34;x (m)\u0026#34;) ylabel!(\u0026#34;T °C\u0026#34;) title!(\u0026#34;Parallel flow with ratio $r\u0026#34;) savefig(\u0026#34;parallel_ratio_$(idx).pdf\u0026#34;) end This model has an analytical closed-form solution given by: $$ T_{eq} = \\frac{100\\cdot \\dot{m}_2}{\\dot{m}_1 + \\dot{m}_2} = 100\\cdot\\frac{r}{1+r} $$ $$ u_1(x) = T_{eq} \\cdot (1 - e^{-h\\cdot x}) $$ $$ u_2(x) = (100 - T_{eq}) \\cdot e^{-h\\cdot x \\cdot r} + T_{eq} $$\nOpposite flow model This model is trickier because we don\u0026rsquo;t consider the dynamics of the system along one dimension anymore. The two fluids flowing in opposite directions are two interdependent systems. We won\u0026rsquo;t go through the analytical solution but use a similar discretization as in article [1].\nThis model takes $n$ discrete cells, each considered at a given temperature. Two cells of the cold and hot flows are considered to have exchanged heat after crossing.\nApplying the energy conservation principle, the gain of internal energy between cell $k$ and $k+1$ for the cold flow is equal to the loss of internal energy of the hot flow from cell $k+1$ to cell $k$. These differences come from heat exchanged, expressed as:\n$$\\dot{Q}_k = h \\cdot \\Delta x \\cdot (u_{2,k+1} - u_{1,k}) $$ $$\\dot{Q}_k = \\dot{m}_1 \\cdot c_1 \\cdot (u_{1,k+1} - u_{1,k}) $$ $$\\dot{Q}_k = \\dot{m}_2 \\cdot c_2 \\cdot (u_{2,k+1} - u_{2,k}) $$\nWatch out the sense of the last equation since the heat exchange is a loss for the hot flow. Again we use the simplifying assumption of equality of the quantities: $$ \\dot{m}_i \\cdot c_i $$\nOur model only depends on the number of discretization steps $n$ and transfer coefficient $h$. function discrete_crossing(n, h; itermax = 50000) u1 = Matrix{Float64}(undef, itermax, n) u2 = Matrix{Float64}(undef, itermax, n) u1[:,1] .= 0.0 u1[1,:] .= 0.0 u2[:,n] .= 100.0 u2[1,:] .= 100.0 for iter in 2:itermax for k in 1:n-1 δq = h * (u2[iter-1, k+1] - u1[iter-1, k]) * (50.0/n) u2[iter, k] = u2[iter-1, k+1] - δq u1[iter, k+1] = u1[iter-1, k] + δq end end (u1,u2) end\nconst (a1, a2) = discrete_crossing(500, 0.1) const x0 = range(0.0, length = 500, stop = L) p = plot(x0, a1[end,:], label = \u0026#34;u1 final\u0026#34;, legend = :topleft) plot!(p, x0, a2[end,:], label = \u0026#34;u2 final\u0026#34;) for iter in (100, 500) global p plot!(p, x0, a1[iter,:], label = \u0026#34;u1 $(iter)\u0026#34;) plot!(p, x0, a2[iter,:], label = \u0026#34;u2 $(iter)\u0026#34;) end xlabel!(\u0026#34;x (m)\u0026#34;) We can observe the convergence of the solution at different iterations: After convergence, we observe a parallel temperature profiles along the exchanger, the difference between the two flows at any point being reduced to $\\epsilon$ mentioned in article [1]. The two differences between our model and theirs are:\n The discretization grid is slightly different since we consider the exchange to happen between cell $k$ and cell $k+1$ at the node between them, while they consider an exchange between $k-1$ and $k+1$ at cell $k$. They consider two flow unit which just crossed reach the same temperature, while we consider a heat exchange limited by the temperature difference (the two flows do not reach identical temperatures but tend towards it).  Finally we can change the ratio: $$\\frac{\\dot{m}_1\\cdot c_1}{\\dot{m}_2\\cdot c_2}$$ for the counterflow model as we did in the parallel case.\nfunction discrete_crossing(n, h, ratio; itermax = 50000) u1 = Matrix{Float64}(undef, itermax, n) u2 = Matrix{Float64}(undef, itermax, n) u1[:,1] .= 0.0 u1[1,:] .= 0.0 u2[:,n] .= 100.0 u2[1,:] .= 100.0 for iter in 2:itermax for k in 1:n-1 δq = h * (u2[iter-1, k+1] - u1[iter-1, k]) * 50.0 / n u2[iter, k] = u2[iter-1, k+1] - δq * ratio u1[iter, k+1] = u1[iter-1, k] + δq end end (u1,u2) end Julia tip: note that we do not define a new function for this but create a method for the function discrete_crossing defined above with a new signature (n, h, ratio).\nWe can plot the result: const x0 = range(0.0, length = 500, stop = L) p = plot(x0, a1[end,:], label = \u0026#34;u1 ratio 1.0\u0026#34;, legend = :bottomright) plot!(p, x0, a2[end,:], label = \u0026#34;u2 ratio 1.0\u0026#34;) for ratio in (0.1,0.5) global p (r1, r2) = discrete_crossing(500, 0.1, ratio) plot!(p, x0, r1[end,:], label = \u0026#34;u1 ratio $(ratio)\u0026#34;) plot!(p, x0, r2[end,:], label = \u0026#34;u2 ratio $(ratio)\u0026#34;) end xlabel!(\u0026#34;x (m)\u0026#34;)\nConclusion To keep this post short, we will not show the influence of all parameters. Some key effects to consider:\n Increasing $h$ increases the gap between the flow temperatures Increasing the number of steps does not change the result for a step size small enough Increasing the exchanger length reduces the gap A ratio of 1 minimizes the temperature difference at every point (and thus minimizes the entropy). This very low entropy creation is a positive sign for engineers from a thermodynamics point of view: we are not \u0026ldquo;degrading\u0026rdquo; the \u0026ldquo;quality\u0026rdquo; of available energy to perform this heat exchange or in other terms, we are not destroying exergy.  Feel free to reach out on Twitter or via email if you have comments or questions, I\u0026rsquo;d be glad to take both.\n Note on process engineering The term is gaining more traction in English, and should replace chemical engineering in higher education to acknowledge the diversity of application fields, greater than the chemical industry alone. The German equivalent Verfahrenstechnik has been used for decades and Génie des Procédés is now considered a norm in most French-speaking universities and consortia.\n Edit: thanks BYP for the sharp-as-ever proofreading\n Sources:\n[1] Levi M. A Near-perfect Heat Exchange. SIAM news. 2018 Dec;51(10):4.\n[2] Borel L, Favrat D. Thermodynamique et énergétique. PPUR presses polytechniques; 2nd edition, 2011.\n Image sources: [3] Geogebra\n","date":1545865200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545988704,"objectID":"ca4d982c3fd583c60e36f0709b8f6687","permalink":"https://matbesancon.github.io/post/2018-12-27-heat-exchanger/","publishdate":"2018-12-27T00:00:00+01:00","relpermalink":"/post/2018-12-27-heat-exchanger/","section":"post","summary":"\n","tags":["engineering","julia"],"title":"Winter warm-up: toy models for heat exchangers","type":"post"},{"authors":null,"categories":null,"content":"The pre-print of the presented work can be found on arXiv. The manuscript has also been submitted and should be published in the coming months.\nAn open-source Julia package has been released here for other researchers to model Time-and-Level-of-Use tariffs.\n","date":1545087600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564816314,"objectID":"4087ffdd8cffd2738e697ed162119d1f","permalink":"https://matbesancon.github.io/project/tlou/","publishdate":"2018-12-18T00:00:00+01:00","relpermalink":"/project/tlou/","section":"project","summary":"Formulating the TLOU price-setting as a bilevel optimization problem","tags":["academia","optimization","energy"],"title":"A Bilevel Framework for Optimal Price-Setting of Time-and-Level-of-Use Tariffs","type":"project"},{"authors":null,"categories":null,"content":"Contributions to the JuliaStats ecosystem, especially the Distributions.jl package for modeling probability distributions in Julia using a minimal and flexible interface.\n","date":1545087600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570717459,"objectID":"2c5b5dd19a3e3b8b0ddb2cee302329a5","permalink":"https://matbesancon.github.io/project/distributions/","publishdate":"2018-12-18T00:00:00+01:00","relpermalink":"/project/distributions/","section":"project","summary":"Toolkit for statistical modeling in Julia","tags":["open-source","statistics","julia-package"],"title":"JuliaStats/Distributions.jl","type":"project"},{"authors":null,"categories":null,"content":"","date":1545087600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557156329,"objectID":"20efcb99f7c62b5d9b58ba22d12030c0","permalink":"https://matbesancon.github.io/project/yaspr/","publishdate":"2018-12-18T00:00:00+01:00","relpermalink":"/project/yaspr/","section":"project","summary":"Trying out game development with the Piston framework in Rust","tags":["open-source","game","rust"],"title":"YASPR: Yet Another Snake on Piston \u0026 Rust","type":"project"},{"authors":null,"categories":null,"content":"We gave an overview of the Julia programming language for researchers in optimization theory and practice. The talk was divided in four parts:\n Introduction to the Julia language, key features and central mechanisms. Example use cases with linear algebra. The JuliaSmoothOptimizers ecosystem, organization \u0026amp; usage JuliaGraphs \u0026amp; the LightGraphs package, features and structure A quick tour of JuliaOpt \u0026amp; JuMP for structured, constrained optimization  ","date":1542754800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557161060,"objectID":"1973223efdab128c823d127d1d7410f5","permalink":"https://matbesancon.github.io/talk/julia_opt_workshop/","publishdate":"2018-11-21T00:00:00+01:00","relpermalink":"/talk/julia_opt_workshop/","section":"talk","summary":"We gave an overview of the Julia programming language for researchers in optimization theory and practice. The talk was divided in four parts:\n Introduction to the Julia language, key features and central mechanisms. Example use cases with linear algebra. The JuliaSmoothOptimizers ecosystem, organization \u0026amp; usage JuliaGraphs \u0026amp; the LightGraphs package, features and structure A quick tour of JuliaOpt \u0026amp; JuMP for structured, constrained optimization  ","tags":null,"title":"Introduction to Julia and its ecosystems for optimization and modeling","type":"talk"},{"authors":null,"categories":null,"content":" So, it\u0026rsquo;s been a bit more than a year since I took a flight to Montréal to start a PhD on mathematical optimization \u0026amp; game theory for smart grids.\nAfter the rush of summer conferences, and my return to France for a part of my PhD at INRIA Lille, it is a good time to take a step back and think of what has been going on and what is coming next. I\u0026rsquo;ll also answer some common questions I had in a more thoughtful way than I can in a bar conversation/family dinner. Maybe this can also help other PhD students seeing we are not in the same boat, but they all still look alike.\nTL;DR: a PhD is not studies in the sense you think, and it\u0026rsquo;s not a job either, these mental models will not help much.\nSo, when are you going to finish? I don\u0026rsquo;t know, when are you going to finish your job? It doesn\u0026rsquo;t look like it\u0026rsquo;s been moving that much recently. Or when will this company you\u0026rsquo;re building be \u0026ldquo;finished\u0026rdquo;?\nThese questions are similar, really. A research subject is rarely isolated, don\u0026rsquo;t see this as emptying a 4-year bowl of soup. It\u0026rsquo;s more like picking berries: you grab one, then the next, which is close enough, oh and this one is nice, but a bit further, I\u0026rsquo;ll have to stretch my arm a bit more to reach it.\n[1]\nI had some interesting discussions in Montréal about when and how to know you should bring your PhD to a conclusion. And the answer should always be that it depends what your objectives are, if you want to include this last project in the PhD. So no, I don\u0026rsquo;t know when I will finish, because if every step was predictable in terms of duration and success, it would not be a PhD or even research, what I do know is that I don\u0026rsquo;t want to block interesting projects or leave only half-explored research trails because \u0026ldquo;3 years is plenty\u0026rdquo;.\nIt must feel weird, getting back to university It does, but not how you imagine. I was previously at a startup for a while. What I was used to is a great autonomy in execution. What the PhD is about is adding self-determination of the objectives, expected results, and means. It does not mean I\u0026rsquo;m working alone while I was in a team before, it means the degree of ownership of successes and failures is much higher, try to picture the three following sentences in a conversation:\n \u0026ldquo;I was at a startup before, it failed and I moved on to XYZ.\u0026rdquo; \u0026ldquo;I started a PhD but didn\u0026rsquo;t get through, then moved on to XYZ.\u0026rdquo; \u0026ldquo;I built a company, it failed, now I\u0026rsquo;m working on XYZ.\u0026rdquo;  It depends on the relationship to failure the person has in front of you, but for those I know, (1) is just an external cause, while (2) and (3) are personal failures, that\u0026rsquo;s ownership.\nThe biggest conclusion I made roughly after 6 months in is that a single-founder startup is one of the closest mental models to keep during the PhD, which explains several things, like inability to explain exactly what you do to your family and friends, imposter syndrome or procrastination.\nSo you get paid enough to buy noodles? Yes, I\u0026rsquo;m living quite well thanks, I can even afford fancying my noodles, but let\u0026rsquo;s dig deeper on the matter of €/$/£.\nDisclaimer: my PhD is between applied maths \u0026amp; computer science, I know all majors are not that financially comfortable.\n[2]\nI also know it\u0026rsquo;s considered rude to talk about money in some cultures, including France, especially if you\u0026rsquo;re not complaining; so yes, I\u0026rsquo;ll be rude.\nWhen I\u0026rsquo;m in France, I\u0026rsquo;m paid slightly less than some engineers with the same level of qualification. The difference is higher if I\u0026rsquo;m comparing to what I would have had on Data Science, applied maths and software development positions. The difference between what I would earn and the scholarship is higher in Canada. Still, like I said, I can live without watching my bank account towards the end of the month.\nThe biggest danger of getting money monthly is thinking of it as a salary, meaning you\u0026rsquo;re thinking of the PhD as a job, meaning you\u0026rsquo;re thinking of yourself as an employee. On the paper, the money I get in France is a salary from my research institute, but one should keep in mind this is only on paper, the danger is to get the wrong mindset: think of yourself as a single person carrying a project, not an employee.\nPeople often argue that they have a research director, who is de facto their boss. I don\u0026rsquo;t think this is the case, directors choose project proposals and people to carry them out (the order of this choice varies). They choose to invest time, effort and money from their structure into this person+project pair, without dictating to the letter what the outcomes of the projects are. Their retribution for this exchange is a partial ownership in the outcomes of the project (publications, conferences, software). Sounds familiar? Yes I\u0026rsquo;m looking at the Wikipedia page on Venture Capital. Let\u0026rsquo;s dig deeper: thesis directors invest this time, money and energy in areas they are familiar with, they have worked in and/or have mentored other people on. This sounds like the VC firms' investment theses. Read these two articles to see a more proper definition and examples of investment theses but I hope you\u0026rsquo;ll get my point: PhDs are not R\u0026amp;D employees and directors are not \u0026ldquo;bosses\u0026rdquo;. If you have friends familiar with how startups work, this should be fine to explain. If you\u0026rsquo;re talking to people who have been employees their whole life in traditional structures, I have not yet found a clear and simple way to explain the situation in a casual conversation, let me know if you have something.\nSo, back to being a student heh? This image is much easier to correct. On the paper this is true, a PhD has a student status, even when working close with/in companies like in Germany, Denmark or France CIFRE theses. Some people will ask this genuinely because they still picture their undergraduate years and think you\u0026rsquo;re back to this. So, it\u0026rsquo;s true, I\u0026rsquo;m taking courses, mostly because I find them interesting and keeping learning things is a bit of a raison d\u0026rsquo;être. But I was also doing so while working, using online courses platform like Coursera or France Université Numérique, going to meetups, reading and writing blog posts. So the thing that changed is maybe the part of my time dedicated to learning which got higher than when employed.\nNow about the second category of people asking this question, yeah those one. In general, the points discussed above are enough as an explanation, but if the tone is really about trolling, which can happen, reverse the question: \u0026ldquo;Yeah I\u0026rsquo;m a student, I\u0026rsquo;m learning stuff every day. Wait you\u0026rsquo;re not? Exactly the stagnation I don\u0026rsquo;t want in my life.\u0026quot;\nIs it mean? Maybe, but the point is not to \u0026ldquo;win\u0026rdquo; a conversation, it\u0026rsquo;s about shutting down the perpetration of imposter syndrome, own the uniqueness of your status, both the good and the bad bits. None should be made feel inferior because they didn\u0026rsquo;t take the conventional, safe and socially accepted path of the 9-17 workday.\nRe-thinking my values \u0026amp; priorities I\u0026rsquo;ve written about values two years ago in the context of a company trying to define who they are. This is a complex topic, about discovering and understanding what the group prioritizes collectively.\nAs the owner of your project and of your time and resources, it\u0026rsquo;s up to you to define what is important. This begins with what is measured for success. Coming to academia from another milieu, I was not used to the process of publishing in peer-reviewed journals. First position I\u0026rsquo;ll take and try to maintain: the measures of academic success are broken, or at least imperfect (reach out to future-me if I change my mind). One example of this is research software. Paraphrasing @mgymrek:\nYour paper is cited outside of your field in one semi-related paragraph: *counts towards your career progression*\nYour academic software package has 100 stars on GitHub: *counts for nothing*\nSomething is wrong here 😐 #jsm2018\n\u0026mdash; Sean Kross (@seankross) July 30, 2018  Had my \u0026quot;software is part of the research process\u0026quot; argument with an academic who wanted to use software to generate results but didn\u0026#39;t want to \u0026quot;concentrate on it too much\u0026quot;. I should start counting how many times I go through this and throw a party when I get to a million.\n\u0026mdash; Simon Hettrick (@sjh5000) September 21, 2018  If you can, watch Mike Croucher\u0026rsquo;s excellent talk at JuliaCon 2018 for more depth on the subject.\nThe consequence of ignoring software as a valuable result of research is pretty straight-forward: proprietary software all over. It\u0026rsquo;s changing in scientific computing, statistics and other fields with the rise of Julia, R, Python. My domain, mathematical optimization, is still behind with dominant solvers (the software doing the actual work) and lots of Algebraic Modeling Languages (the front-end to interact with the solver) being proprietary. The last part is changing, the first one is still tough. My point is that people behind software you\u0026rsquo;re using everyday contribute way more to the success of your PhD than this obscure paper you cite because the review committee asked you to. If your university is giving thousands in commercial licenses and millions in access to paper, maybe you should make them donate both time and money to the tools you\u0026rsquo;re using. Yes all of them.\nI have been involved in the Julia community, especially within the JuliaGraphs and JuliaStats ecosystems, mostly because these are subjects I understand (at least a bit) and/or used. Key take-away:\nReporting issues you have and contributing to improve the documentation is as valuable as writing code.\nSo\u0026hellip; it\u0026rsquo;s been a year And I\u0026rsquo;m still learning (understand making mistakes, getting stuck, etc), one of the reasons I had to learn more is not coming from a background in maths, nor from a research-oriented degree.\nReach out any way you prefer, Twitter, email. Of course some things I\u0026rsquo;ve written are related to my situation, I\u0026rsquo;d be interested to know how it relates or not to yours.\n Image sources:\n[1] https://pxhere.com/en/photo/571187\n[2] https://pixabay.com/en/noodles-thailand-food-thai-2693009/\n","date":1537999200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538064695,"objectID":"b38df74c3c3465b7fdaf47773d586230","permalink":"https://matbesancon.github.io/post/2018-09-27-year-in-phd/","publishdate":"2018-09-27T00:00:00+02:00","relpermalink":"/post/2018-09-27-year-in-phd/","section":"post","summary":"\n","tags":["phd","academia"],"title":"A year in PhD","type":"post"},{"authors":null,"categories":null,"content":"Quick overview of the Julia programming language at the LilleFP meetup. Slides are in Franglish but should be understandable. The programming model was presented with a quick overview of parts of the type system and multiple dispatch mechanism.\nIt was really nice to be able to exchange with people coming from very different programming worlds and compare their approach, opinion and programming needs with some design choices of the language.\n","date":1537394400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557161060,"objectID":"20729607beec886695c29b85f80646af","permalink":"https://matbesancon.github.io/talk/lillefp_julia/","publishdate":"2018-09-20T00:00:00+02:00","relpermalink":"/talk/lillefp_julia/","section":"talk","summary":"Quick overview of the Julia programming language at the LilleFP meetup. Slides are in Franglish but should be understandable. The programming model was presented with a quick overview of parts of the type system and multiple dispatch mechanism.\nIt was really nice to be able to exchange with people coming from very different programming worlds and compare their approach, opinion and programming needs with some design choices of the language.","tags":null,"title":"Julia, programming model, type system and use cases","type":"talk"},{"authors":null,"categories":null,"content":"","date":1536012000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557328745,"objectID":"83d1a8dfa221e4e6087810d1b9984d8c","permalink":"https://matbesancon.github.io/project/mixed_distributions/","publishdate":"2018-09-04T00:00:00+02:00","relpermalink":"/project/mixed_distributions/","section":"project","summary":"Modelling, inferring and sampling from continuous-discrete distributions in Julia, on top of Distributions.jl","tags":["open-source","statistics","julia-package","distributions"],"title":"Mixed continuous-discrete distributions","type":"project"},{"authors":null,"categories":null,"content":" This is an adapted post on the talk we gave with James at JuliaCon 2018 in London. You can see the original slides, the video still requires a bit of post-processing.\nLast week JuliaCon in London was a great and very condensed experience. The two talks on LightGraphs.jl received a lot of positive feedback and more than that, we saw how people are using the library for a variety of use cases which is a great signal for the work on the JuliaGraphs ecosystem (see the lightning talk).\nI wanted to re-build the same graph for people who prefer a post version to my clumsy live explanations on a laptop not handling dual-screen well (those who prefer the latter are invited to see the live-stream of the talk).\nWhy abstractions? The LightGraphs library is built to contain as few elements as possible to get anyone going with graphs. This includes:\n The interface a graph type has to comply with to be used Essential algorithms implemented by any graph respecting that interface A simple, battery-included implementation based on adjacency lists  The thing is, if you design an abstraction which in fact has just one implementation, you\u0026rsquo;re doing abstraction wrong. This talks was also a reality-check for LightGraphs, are we as composable, extensible as we promised?\nThe reason for abstraction is also that minimalism has its price. The package was designed as the least amount of complexity required to get graphs working. When people started to use it, obviously they needed more features, some of which they could code themselves, some other required extensions built within LightGraphs. By getting the core abstractions right, you guarantee people will be able to use it and to build on top with minimal friction, while keeping it simple to read and contribute to.\nOur matrix graph type Let\u0026rsquo;s recall that a graph is a collection of nodes and a collection of edges between these nodes. To keep it simple, for a graph of $n$ edges, we will consider they are numbered from 1 to n. An edge connects a node $i$ to a node $j$, therefore all the information of a graph can be kept as an adjacency matrix $M_{ij}$ of size $n \\times n$:\n$$M_{ij} = \\begin{cases} 1, \u0026amp; \\mbox{if edge (i $\\rightarrow$ j) exists} \\\\ 0 \u0026amp; \\mbox{otherwise}\\end{cases}$$\nWe don\u0026rsquo;t know what the use cases for our type will be, and therefore, we will parametrize the graph type over the matrix type:\nimport LightGraphs; const lg = LightGraphs mutable struct MatrixDiGraph{MT \u0026lt;: AbstractMatrix{Bool}} \u0026lt;: lg.AbstractGraph{Int} matrix::MT end The edges are simply mapping an entry (i,j) to a boolean (whether there is an edge from i to j). Even though creating a graph type that can be directed or undirected depending on the situation is possible, we are creating a type that will be directed by default.\nImplementing the core interface We can now implement the core LightGraphs interface for this type, starting with methods defined over the type itself, of the form function(g::MyType)\nI\u0026rsquo;m not going to re-define each function here, their meaning can be found by checking the help in a Julia REPL: ?LightGraphs.vertices or on the documentation page.\nlg.is_directed(::MatrixDiGraph) = true lg.edgetype(::MatrixDiGraph) = lg.SimpleGraphs.SimpleEdge{Int} lg.ne(g::MatrixDiGraph) = sum(g.m) lg.nv(g::MatrixDiGraph) = size(g.m)[1] lg.vertices(g::MatrixDiGraph) = 1:nv(g) function lg.edges(g::MatrixDiGraph) n = lg.nv(g) return (lg.SimpleGraphs.SimpleEdge(i,j) for i in 1:n for j in 1:n if g.m[i,j]) end Note the last function edges, for which the documentation specifies that we need to return an iterator over edges. We don\u0026rsquo;t need to collect the comprehension in a Vector, returning a lazy generator.\nSome operations have to be defined on both the graph and a node, of the form function(g::MyType, node). lg.outneighbors(g::MatrixDiGraph, node) = [v for v in 1:lg.nv(g) if g.m[node, v]] lg.inneighbors(g::MatrixDiGraph, node) = [v for v in 1:lg.nv(g) if g.m[v, node]] lg.has_vertex(g::MatrixDiGraph, v::Integer) = v \u0026lt;= lg.nv(g) \u0026amp;\u0026amp; v \u0026gt; 0\nOut MatrixDiGraph type is pretty straight-forward to work with and all required methods are easy to relate to the way information is stored in the adjacency matrix.\nThe last step is implementing methods on both the graph and an edge of the form function(g::MatrixDiGraph,e). The only one we need here is: lg.has_edge(g::MatrixDiGraph,i,j) = g.m[i,j]\nOptional mutability Mutating methods were removed from the core interace some time ago, as they are not required to describe a graph-like behavior. The general behavior for operations mutating a graph is to return whether the operation succeded. They consist in adding or removing elements from either the edges or nodes.\nimport LightGraphs: rem_edge!, rem_vertex!, add_edge!, add_vertex! function add_edge!(g::MatrixDiGraph, e) has_edge(g,e) \u0026amp;\u0026amp; return false n = nv(g) (src(e) \u0026gt; n || dst(e) \u0026gt; n) \u0026amp;\u0026amp; return false g.m[src(e),dst(e)] = true end function rem_edge!(g::MatrixDiGraph,e) has_edge(g,e) || return false n = nv(g) (src(e) \u0026gt; n || dst(e) \u0026gt; n) \u0026amp;\u0026amp; return false g.m[src(e),dst(e)] = false return true end function add_vertex!(g::MatrixDiGraph) n = nv(g) m = zeros(Bool,n+1,n+1) m[1:n,1:n] .= g.m g.m = m return true end Testing our graph type on real data We will use the graph type to compute the PageRank of\nimport SNAPDatasets data = SNAPDatasets.loadsnap(:ego_twitter_d) twitter_graph = MatrixDiGraph(lg.adjacency_matrix(data)[1:10,1:10].==1); ranks = lg.pagerank(twitter_graph) Note the broadcast check .==1, adjacency_matrix is specified to yield a matrix of Int, so we use this to cast the entries to boolean values.\nI took only the first 10 nodes of the graph, but feel free to do the same with 500, 1000 or more nodes, depending on what your machine can stand 🙈\nOverloading non-mandatory functions Some methods are already implemented for free by implementing the core interface. That does not mean it should be kept as-is in every case. Depending on your graph type, some functions might have smarter implementations, let\u0026rsquo;s see one example. What MatrixDiGraph is already an adjacency_matrix, so we know there should be no computation required to return it (it\u0026rsquo;s almost a no-op).\nusing BenchmarkTools: @btime @btime adjacency_matrix(bigger_twitter) println(\u0026#34;why did that take so long?\u0026#34;) lg.adjacency_matrix(g::MatrixDiGraph) = Int.(g.m) @btime A = lg.adjacency_matrix(bigger_twitter) println(\u0026#34;that\u0026#39;s better.\u0026#34;) This should yield roughly:\n13.077 ms (5222 allocations: 682.03 KiB) why did that take so long? 82.077 μs (6 allocations: 201.77 KiB) that's better. You can fall down to a no-op by storing the matrix entries as Int directly, but the type ends up being a bit heavier in memory, your type, your trade-off.\nConclusion We\u0026rsquo;ve implemented a graph type suited to our need in a couple lines of Julia, guided by the LightGraphs interface specifying how to think about our graph instead of getting in the way of what to store. A lighter version of this post can be read as slides.\nAs usual, ping me on Twitter for any question or comment.\nBonus If you read this and want to try building your own graph type, here are two implementations you can try out, put them out in a public repo and show them off afterwards:\n We created a type just for directed graphs, why bothering so much? You can create your own type which can be directed or not, either by storing the information in the struct or by parametrizing the type and getting the compiler to do the work for you. We store the entries as an AbstractMatrix{Bool}, if your graph is dense enough (how dense? No idea), it might be interesting to store entries as as BitArray.   Image source: GraphPlot.jl\n","date":1534456800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535649092,"objectID":"4ea0bcff6dde362d969de51cdf3b5768","permalink":"https://matbesancon.github.io/post/2018-08-17-abstract_graph/","publishdate":"2018-08-17T00:00:00+02:00","relpermalink":"/post/2018-08-17-abstract_graph/","section":"post","summary":"Who needs libraries when from scratch looks so good\n","tags":["julia","graph","package","interface"],"title":"Building our own graph type in Julia","type":"post"},{"authors":null,"categories":null,"content":"We presented the LightGraphs.jl package with James for anyone in need of a simple \u0026amp; extensible graph library in Julia, the core interface for abstract graphs and essential algorithms included.\nAnyone can come up with their own graph type, and we show it by building the simplest graph type from an adjacency matrix, implementing the LightGraphs interface, and then re-using the whole ecosystem on this type for free.\n [1] Image source: Photo by Fancycrave on Unsplash\n","date":1533765600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557161060,"objectID":"265c4dd7100382a55b33864d0d6e0833","permalink":"https://matbesancon.github.io/talk/juliacon18/","publishdate":"2018-08-09T00:00:00+02:00","relpermalink":"/talk/juliacon18/","section":"talk","summary":"We presented the LightGraphs.jl package with James for anyone in need of a simple \u0026amp; extensible graph library in Julia, the core interface for abstract graphs and essential algorithms included.\nAnyone can come up with their own graph type, and we show it by building the simplest graph type from an adjacency matrix, implementing the LightGraphs interface, and then re-using the whole ecosystem on this type for free.\n [1] Image source: Photo by Fancycrave on Unsplash","tags":null,"title":"Graph interfaces, bespoke graphs for every occasion","type":"talk"},{"authors":null,"categories":null,"content":" \nIn the previous post, we explored a well-known integer optimization situation in manufacturing, the cutting stock problem. After some details on the decisions, constraints and objectives, we implemented a naive model in JuMP.\nOne key thing to notice is the explosion of number of variables and constraints and the fact that relaxed solutions (without constraining variables to be integers) are very far from actual feasible solutions.\nWe will now use an other way of formulating the problem, using a problem decomposition and an associated solution method (column generation).\nRe-stating the cutting stock problem Remember we used two decisions: $Y_i$ stating if the big roll $i$ is used and $X_{ij}$ expressing the number of cuts $j$ made in the roll $i$. To minimize the number of rolls, it makes sense to put as many small cuts as possible on a big roll. We could therefore identify saturating patterns, that is, a combination of small cuts fitting on a big roll, such that no additional cut can be placed, and then find the smallest combination of the pattern satisfying the demand.\nOne problem remains: it is impossible to compute, or even to store in memory all patterns, their number is exponentially big with the number of cuts, so we will try to find the best patterns and re-solve the problem, using the fact that not all possible patterns will be necessary.\nThis is exactly what the Dantzig-Wolfe decomposition does, it splits the problem into a Master Problem MP and a sub-problem SP.\n The Master Problem, provided a set of patterns, will find the best combination satisfying the demand. The sub-problem, given an \u0026ldquo;importance\u0026rdquo; of each cut provided by the master problem, will find the best cuts to put on a new pattern.  This is an iterative process, we can start with some naive patterns we can think of, compute an initial solution for the master problem, which will be feasible but not optimal, move on to the sub-problem to try to find a new pattern (or column in the optimization jargon, hence the term of column generation).\nHow do we define the \u0026ldquo;importance\u0026rdquo; of a cut $j$? The value of the dual variable associated with this constraint will tell us that. This is not a lecture in duality theory, math-eager readers can check out further documentation on the cutting stock problem and duality in linear optimization.\nMoreover, we are going to add one element to our model: excess cuts can be sold at a price $P_j$, so that we can optimize by minimizing the net cost (production cost of the big rolls minus the revenue from excess cuts).\nNew formulation Again, we are going to formulate first possible decisions and then constraints on these decisions for the new version of the problem.\nDecisions At the master problem level, given a pattern $p$, the decision will be $\\theta_p$ (theta, yes Greek letters are awesome), the number of big rolls which will be used with this pattern. $\\theta_p$ is a positive integer.\nThe decision at the sub-problem level will be to find how many of each cut $j$ to fit onto one big roll, $a_j$.\nFor a pattern $p$, the number of times a cut $j$ appears is given by $a_{jp}$.\nConstraints The big roll size constraint is kept in the sub-problem, a pattern built has to respect this constraint: $$ \\sum_j a_{j} \\cdot W_j \\leq L $$\nThe demand $D_j$ is met with all rolls of each pattern so it is kept at the master level. The number of cuts of type $j$ produced is the sum of the number of this cut on each patterns times the number of the pattern in a solution:\n$$ NumCuts_j = \\sum_p a_{jp} \\cdot \\theta_p \\geq D_j$$\nObjective formulation At the master problem, we minimize the number of rolls, which is simply: $$ \\sum_{p} \\theta_p $$\nAt the sub-problem, we are trying to maximize the gain associated with the need for the demand + the residual price of the cuts. If we can find a worth using producing compared to its production cost, it is added.\nImplementation As before, we will formulate the master and sub-problem using Julia with JuMP. Again, we use the Clp and Cbc open-source solvers. We read the problem data (prices, sizes, demand) from a JSON file.\nusing JuMP using Cbc: CbcSolver using Clp: ClpSolver import JSON const res = open(\u0026quot;data0.json\u0026quot;, \u0026quot;r\u0026quot;) do f data = readstring(f) JSON.Parser.parse(data) end const maxwidth = res[\u0026quot;maxwidth\u0026quot;] const cost = res[\u0026quot;cost\u0026quot;] const prices = Float64.(res[\u0026quot;prices\u0026quot;]) const widths = Float64.(res[\u0026quot;widths\u0026quot;]) const demand = Float64.(res[\u0026quot;demand\u0026quot;]) const nwidths = length(prices) cost is the production cost of a big roll.\nSub-problem The subproblem is a function taking reduced costs of each cut and maximizing the utility of the pattern it creates:\n\u0026#34;\u0026#34;\u0026#34; subproblem tries to find the best feasible pattern maximizing reduced cost and respecting max roll width corresponding to a multiple-item knapsack \u0026#34;\u0026#34;\u0026#34; function subproblem(reduced_costs, sizes, maxcapacity) submodel = Model(solver = CbcSolver()) n = length(reduced_costs) xs = @variable(submodel, xs[1:n] \u0026gt;= 0, Int) @constraint(submodel, sum(xs. * sizes) \u0026lt;= maxcapacity) @objective(submodel, Max, sum(xs. * reduced_costs)) solve(submodel) return round.(Int,getvalue(xs)), round(Int,getobjectivevalue(submodel)) end Initial master problem We saw that the master problem finds a solution and then requires a new pattern from the sub-problem. This is therefore preferable to start from an initial feasible, otherwise we fall into a special case we\u0026rsquo;re not discussing here. One initial solution would be to build one pattern per cut, with as many cuts as we can, which is $floor(L/w_j)$.\nfunction init_master(maxwidth, widths, rollcost, demand, prices) n = length(widths) ncols = length(widths) patterns = spzeros(UInt16,n,ncols) for i in 1:n patterns[i,i] = min(floor(Int,maxwidth/widths[i]),round(Int,demand[i])) end m = Model(solver = ClpSolver()) θ = @variable(m, θ[1:ncols] \u0026gt;= 0) @objective(m, Min, sum(θ[p] * (rollcost - sum(patterns[j,p] * prices[j] for j=1:n)) for p in 1:ncols) ) @constraint(m, demand_satisfaction[j=1:n], sum(patterns[j,p] * θ[p] for p in 1:ncols)\u0026gt;=demand[j]) if solve(m) != :Optimal warn(\u0026#34;No optimal\u0026#34;) end return (m, getvalue(θ), demand_satisfaction, patterns) end We can compute the reduced costs from the dual values associated with the demand and the prices of cuts\n# getting the model and values (m, θ, demand_satisfaction, patterns) = init_master(maxwidth, widths, cost, demand, prices); # compute reduced costs reduced_costs = getdual(demand_satisfaction)+prices; # ask sub-problem for new pattern newcol, newobj = subproblem(reduced_costs, widths, maxwidth) Putting it all together We can now build a column generation function putting all elements together and performing the main iteration:\nfunction column_generation(maxwidth, widths, rollcost, demand, prices; maxcols = 5000) (m, θ, demand_satisfaction, patterns) = init_master(maxwidth, widths, rollcost, demand, prices) ncols = nwidths while ncols \u0026lt;= maxcols reduced_costs = getdual(demand_satisfaction) + prices newcol, newobj = subproblem(reduced_costs, widths, maxwidth) netcost = cost - sum(newcol[j] * (getdual(demand_satisfaction)[j]+prices[j]) for j in 1:nwidths) println(\u0026#34;New reduced cost: $netcost\u0026#34;) if netcost \u0026gt;= 0 return (:Optimal, patterns, getvalue(θ)) end patterns = hcat(patterns, newcol) ncols += 1 m = Model(solver = ClpSolver()) θ = @variable(m, θ[1:ncols] \u0026gt;= 0) @objective(m, Min, sum(θ[p] * (rollcost - sum(patterns[j,p] * prices[j] for j=1:nwidths)) for p in 1:ncols) ) @constraint(m, demand_satisfaction[j=1:nwidths], sum(patterns[j,p] * θ[p] for p in 1:ncols)\u0026gt;=demand[j]) if solve(m) != :Optimal warn(\u0026#34;No optimal\u0026#34;) return (status(m), patterns, getvalue(θ)) end end return (:NotFound, patterns, :NoVariable) end We\u0026rsquo;ve printed information along the computation to see what\u0026rsquo;s going on more clearly, now launching it:\nstatus, patterns, θ = column_generation(maxwidth, widths, cost, demand, prices, maxcols = 500); New reduced cost: -443.18181818181824 New reduced cost: -375.0 New reduced cost: -264.0 New reduced cost: -250.0 New reduced cost: -187.5 New reduced cost: -150.0 New reduced cost: -150.0 New reduced cost: -107.14285714285711 New reduced cost: -97.5 New reduced cost: -107.14285714285734 New reduced cost: -72.0 New reduced cost: -53.571428571428555 New reduced cost: -53.125 New reduced cost: -50.0 New reduced cost: -43.40625 New reduced cost: -36.0 New reduced cost: -34.625 New reduced cost: -41.5 New reduced cost: -21.8515625 New reduced cost: -22.159090909090878 New reduced cost: -20.625 New reduced cost: -16.304347826086314 New reduced cost: -16.304347826086996 New reduced cost: -20.310344827586277 New reduced cost: -18.0 New reduced cost: -8.837209302325732 New reduced cost: -6.060606060606119 New reduced cost: 0.0 While the cost of a new pattern is negative, we can add it to the master and keep running. This seems to make sense. Now, one thing to note, we have not yet specified the integrality constraints, meaning that we don\u0026rsquo;t have integer number of patterns. We can see that on the $\\theta$ variable: println(θ) [0.0, 0.0, 0.0, ... 70.0, 0.0, 0.0, 0.0, 12.56, 46.86, 0.0, 0.0, 0.0, 0.0, 3.98, 0.0, 0.0, 21.5, 5.0, 31.12, 61.12, 33.58, 0.0, 0.0, 32.2, 44.0, 46.88, 19.0, 1.88, 16.42] println(sum(θ)) 446.1000000000001\nWe saw in the last post that the problem without integrality constraints is a relaxation and therefore, can only yield a better result. This means that we cannot have an integer solution using 446 big rolls or less, the minimum will be 447 rolls. Let\u0026rsquo;s solve the problem with the same patterns, but adding the integrality:\n# compute initial integer solution: # take worse case from linear solution, round up intial_integer = ceil.(Int,θ); \u0026#34;\u0026#34;\u0026#34; From patterns built in the column generation phase, find an integer solution \u0026#34;\u0026#34;\u0026#34;function branched_model(patterns, demand, rollcost, prices; npatts = size(patterns)[2], initial_point = zeros(Int,npatts)) npatts = size(patterns)[2] m = Model(solver = CbcSolver()) θ = @variable(m, θ[p = 1:npatts] \u0026gt;= 0, Int, start = initial_point[p]) @objective(m, Min, sum(θ[p] * (rollcost - sum(patterns[j,p] * prices[j] for j=1:nwidths)) for p in 1:npatts) ) @constraint(m, demand_satisfaction[j=1:nwidths], sum(θ[p] * patterns[j,p] for p in 1:npatts) \u0026gt;= demand[j]) status = solve(m) return (status, round.(Int,(getvalue(θ)))) end Let\u0026rsquo;s see what the results look like:\nstatus, θ_final = branched_model(patterns, demand, cost, prices; initial_point = intial_integer) println(status) :Optimal println(sum(θ_final)) 447 Given that we cannot do better than 447, we know we have the optimal number of rolls.\nConclusion After seeing what a mess integer problems can be in the first part, we used a powerful technique called Dantzig-Wolfe decomposition, splitting the problem into master and sub-problem, each handling a subset of the constraints.\nColumn generation is a technique making this decomposition usable in practice, by adding only one or few columns (patterns) at each iteration, we avoid an exponentially growing number of variables. The fact that JuMP is built as an embedded Domain Specific Language in Julia makes it a lot easier to specify problems and play around them. Most optimization specific modeling languages are built around declarative features and get messy very quickly when introducing some logic (like column generation iterations). Developers could relate this technique to lazy value computation: we know all values are there, but we just compute them whenever needed.\nHope you enjoyed reading this second post on the cutting stock problem. A Jupyter notebook summing up all code snippets can be found at this repository, feel free to ping me for feedback.\nCode and citation Found this post useful for your work? The corresponding repository is available on GitHub, consider citing it using the following DOI 10.5281/zenodo.3329389, the BibTeX entry is available on Zenodo.\nNote on performance The column generation approach we just saw scales well to huge problems, but this particular implementation can feel a bit slow at first. One recommended thing is to do in such case is \u0026ldquo;warm-starting\u0026rdquo; the solver: give it a good initial solution to start from. Since we built both the master and subproblem as stateless functions, the model is being re-built from scratch each time. The advantage is that any solver can be used, since some of them don\u0026rsquo;t support warm starts.\nThanks to Aristide for his very sharp ideas and views on this article which contributed to its improvement!\n Image source: https://www.flickr.com/photos/30478819@N08/38272827564\n","date":1527631200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581333203,"objectID":"7f6ad8e0dcd8dac56b21e206602010e6","permalink":"https://matbesancon.github.io/post/2018-05-25-colgen2/","publishdate":"2018-05-30T00:00:00+02:00","relpermalink":"/post/2018-05-25-colgen2/","section":"post","summary":"A column generation algorithm for the cutting width problem using Julia and JuMP\n","tags":["julia","optimization","integer-optimization","jump"],"title":"The cutting stock problem: part 2, solving with column generation","type":"post"},{"authors":null,"categories":null,"content":"\nInteger optimization often feels weird (at least to me). Simple reformulations of a (mixed) integer optimization problem (MIP) can make it way easier to solve. We\u0026rsquo;re going to explore one well-known example of such integer problem in two blog posts. This first part introduces the problem and develops a naive solution. We\u0026rsquo;re going to see why it\u0026rsquo;s complex to solve and why this formulation does not scale.\nIn a second post, we will see a reformulation of the problem which makes it easier to solve and scales to bigger instances.\nInteger optimization reminder An optimization problem takes three components: decisions variables $x$, a set of constraints telling you if a decision is feasible or not and a cost function $c(x)$ giving a total cost of a decision. Optimization is a domain of applied mathematics consisting in finding the best feasible decision for a problem. Lots of decision problems come with integrality constraints: if $x$ is the decision, then it can only take integer values 0,1,2\u0026hellip; or even only binary values ${0,1}$. Think of problems involving number of units produced for a good, yes/no decisions, etc\u0026hellip; If a problem has lots of variables, naive enumerations of feasible solutions becomes impossible: even problems with 50 variables can make your average laptop crash.\nThe cutting stock problem The problem is not new and has been given quite some thoughts because of its different industrial applications, it has been one of the first applications of the column generation method we are going to use. The key elements of the problems are: given some large rolls (metal, paper or other), we need to cut smaller portions of given lengths to satisfy a demand for the different small lengths. Find more details here. A small instance might be: given rolls of size $100cm$, we want to cut at least 7 rolls of size $12cm$ and 9 rolls of size $29cm$. The objective is to minimize the number of big rolls to satisfy this demand.\nHow do we formulate this mathematically?\nDecisions $Y_i$ is a binary decision indicating if we use the big roll number $i$. $X_{ij}$ is an integer giving the number of times we cut a small roll $j$ in the big roll $i$.\nConstraints $Y$ are binary variables, $X$ are integer. Now the less trivial constraints:\n Demand satisfaction constraint: the sum over all $i$ big rolls of the cut $j$ has to satisfy the demand for that cut: $$\\sum_{i} X_{ij} \\geq D_j $$  For the two-cut example with the demand of $7 \\times 12cm$ and $9 \\times 29cm$, let\u0026rsquo;s suppose we have 10 big rolls $i \\in {1\u0026hellip;10}$, the demand for the first 12cm cut is 7 cuts, the number of cuts of this size produced is: $$ \\sum_i X_{i1} = X_{1,1} + X_{2,1} + \u0026hellip; + X_{10,1}$$\nThis total must at least match the demand, so: $$ X_{1,1} + X_{2,1} + \u0026hellip; + X_{10,1} \\geq 7 $$\n Roll size constraint: if a roll $i$ is used, we cannot fit more width onto it than its total width: $$\\sum_{j} X_{ij} \\cdot W_j \\leq L \\cdot Y_i $$  For the two-cut example with the demand of $7 \\times 12cm$ and $9 \\times 29cm$, let\u0026rsquo;s suppose we have one roll $i$:\n If $Y_i = 0$, the roll size constraint becomes:  $$ \\sum_{j} X_{ij} \\cdot W_j = 12 \\cdot X_{i1} + 29 \\cdot X_{i2} \\leq 0 $$\nThe only feasible solution for this roll $i$ is ($X_{i1} = 0,X_{i2} = 0$).\n If $Y_i = 1$, the roll size constraint becomes: $$ 12 \\cdot X_{i1} + 29 \\cdot X_{i2} \\leq 100 $$  Which means we can fit as many cuts as the roll size allows for.\nA first naive implementation Let\u0026rsquo;s first import the necessary packages: we\u0026rsquo;re using JuMP as a modeling tool, which is an optimization-specific language embedded in Julia (compare it to AMPL, GAMS, Pyomo, PuLP). As I consider it an embedded language, I\u0026rsquo;ll do a full import into my namespace with using (unlike what I usually do with packages). We also use Cbc, an open-source solver for integer problems from the Coin-OR suite.\nusing JuMP using Cbc: CbcSolver We can define our optimization problem within a function taking the parameters of the cutting stock problem, namely a maxwidth of the big rolls, scalar assuming all of them have the same width, a widths vector, one element for each cut size $j$ and a demand vector, again, one for each cut size.\nfunction cutting_stock_model(maxwidth, widths, demand, N = sum(demand)) # Define the JuMP model m = Model(solver = CbcSolver()) # define the two groups of variables over their respective indices Y = @variable(m, Y[1:N],Bin) X = @variable(m, X[i=1:N,j=1:length(widths)],Int) # define both constraints and objective demand_satisfac = @constraint(m, [j=1:length(widths)], sum(X[i,j] for i in 1:N) \u0026gt;= demand[j] ) roll_size_const = @constraint(m, [i=1:N], sum(X[i,j] * widths[j] for j in 1:length(widths)) \u0026lt;= Y[i] * maxwidth ) @objective(m, Min, sum(Y[i] for i in 1:N)) # return the model formulation to solve later return m end Here $N$ has to be an upper bound on the number of big rolls to use, otherwise the problem will be infeasible (not enough big rolls to find a solution satisfying the demand). An initial naive value for this could be the total demand, after all one small cut per roll can be considered a worst-case solution.\nNote that we don\u0026rsquo;t call solve on the model yet, the function simply builds the model, this will help us see how it evolves with various entry parameters. In Julia REPL, or by using the @show macro, we can have more details on the model. Using println(m) instead of @show will build a mathematical formulation of the model in a LateX-like style, which can be valuable to ensure your implementation matches the initial formulation.\njulia\u0026gt; println(cutting_stock_model(100, [12,10], [3,4])) Min Y[1] + Y[2] + Y[3] + Y[4] + Y[5] + Y[6] + Y[7] Subject to X[1,1] + X[2,1] + X[3,1] + X[4,1] + X[5,1] + X[6,1] + X[7,1] ≥ 3 X[1,2] + X[2,2] + X[3,2] + X[4,2] + X[5,2] + X[6,2] + X[7,2] ≥ 4 12 X[1,1] + 10 X[1,2] - 100 Y[1] ≤ 0 12 X[2,1] + 10 X[2,2] - 100 Y[2] ≤ 0 12 X[3,1] + 10 X[3,2] - 100 Y[3] ≤ 0 12 X[4,1] + 10 X[4,2] - 100 Y[4] ≤ 0 12 X[5,1] + 10 X[5,2] - 100 Y[5] ≤ 0 12 X[6,1] + 10 X[6,2] - 100 Y[6] ≤ 0 12 X[7,1] + 10 X[7,2] - 100 Y[7] ≤ 0 Y[i] ∈ {0,1} ∀ i ∈ {1,2,…,6,7} X[i,j], integer, ∀ i ∈ {1,2,…,6,7}, j ∈ {1,2} Let\u0026rsquo;s see what the model looks like for different instances: julia\u0026gt; cutting_stock_model(100, [12,10], [85,97], 200) (Minimization problem with: * 602 linear constraints * 600 variables: 200 binary, 400 integer Solver is CbcMathProg, X[i,j], integer, ∀ i ∈ {1,2,…,199,200}, j ∈ {1,2}, Y[i] ∈ {0,1} ∀ i ∈ {1,2,…,199,200}) julia\u0026gt; cutting_stock_model(100, [12,10,25], [85,97,52], 300) (Minimization problem with: * 1203 linear constraints * 1200 variables: 300 binary, 900 integer Solver is CbcMathProg, X[i,j], integer,∀ i ∈ {1,2,…,299,300}, j ∈ {1,2,3}, Y[i] ∈ {0,1} ∀ i ∈ {1,2,…,299,300}) julia\u0026gt; cutting_stock_model(100, [12,10,25,40,30,41], [85,97,52,63,77,31], 500) (Minimization problem with: * 3506 linear constraints * 3500 variables: 500 binary, 3000 integer Solver is CbcMathProg, X[i,j], integer, ∀ i ∈ {1,2,…,499,500}, j ∈ {1,2,…,5,6}, Y[i] ∈ {0,1} ∀ i ∈ {1,2,…,499,500})\nWe see the number of variables and constraints explode as we add more possible cut sizes. More precisely:\n Number of variables: $ size(X) + size(Y) = Nrolls \\cdot Ncuts + Nrolls $ Number of constraints: $ size(DemandConstr) + size(WidthConstr) = Ncuts + Nrolls$  Without going into details on the solving process, two things make the problem difficult to solve:\n Symmetry: if we place cuts on a roll $Y_1$ and leave another $Y_2$ unused, the resulting solution is concretely the same as using $Y_2$ and leaving $Y_1$ unused. Bad relaxation: integer solvers mostly work by solving a \u0026ldquo;relaxed\u0026rdquo; version of the problem without the integrality constraint, and then iteratively restricting the problem to find the best integer solution. If the relaxed version of the problem yields solutions far away from an integer one, the solver will have more work to get there.  Difficulty (1) is pretty intuitive, but we could get some insight on (2). Let\u0026rsquo;s define our relaxed problem. We\u0026rsquo;re going to use the Clp solver, which will solve the same problem, but without the Int restriction for $X$ nor the Bin restriction for $Y$: function relaxed_cutting_stock(maxwidth, widths, demand, N = sum(demand)) m = Model(solver = ClpSolver()) Y = @variable(m, 0 \u0026lt;= Y[1:N] \u0026lt;= 1) X = @variable(m, X[1:N,1:length(widths)] \u0026gt;= 0) demand_satisfac = @constraint(m, [j=1:length(widths)], sum(X[i,j] for i in 1:N) \u0026gt;= demand[j]) roll_size_const = @constraint(m, [i=1:N], sum(X[i,j] * widths[j] for j in 1:length(widths)) \u0026lt;= Y[i] * maxwidth) @objective(m, Min, sum(Y[i] for i in 1:N)) return (m,Y,X) end\nLet\u0026rsquo;s see the results:\njulia\u0026gt; res = [(i,getvalue(Y[i])) for i in 1:N if getvalue(Y[i]) ≉ 0] 33-element Array{Tuple{Int64,Float64},1}: (1, 1.0) (2, 1.0) (3, 1.0) (4, 1.0) (5, 1.0) (6, 1.0) (7, 1.0) (8, 1.0) (9, 1.0) (10, 1.0) (11, 1.0) (12, 1.0) (13, 1.0) (14, 1.0) (15, 1.0) (16, 1.0) (17, 1.0) (18, 1.0) (19, 1.0) (20, 1.0) (21, 1.0) (22, 1.0) (23, 1.0) (24, 1.0) (25, 1.0) (26, 1.0) (27, 1.0) (28, 1.0) (29, 1.0) (30, 1.0) (31, 1.0) (32, 0.9) (84, 1.0) idxs = [i for (i,_ ) in res] julia\u0026gt; [getvalue(X)[i,:] for i in idxs] 33-element Array{Array{Float64,1},1}: [0.0, 7.0, 1.2] [0.0, 0.0, 4.0] [0.0, 0.0, 4.0] [0.0, 0.0, 4.0] [0.0, 0.0, 4.0] [0.0, 0.0, 4.0] [0.0, 0.0, 4.0] [0.0, 0.0, 4.0] [0.0, 0.0, 4.0] [0.0, 10.0, 0.0] [0.0, 10.0, 0.0] [0.0, 0.0, 4.0] [0.0, 10.0, 0.0] [0.0, 10.0, 0.0] [0.0, 10.0, 0.0] [0.0, 10.0, 0.0] [0.0, 10.0, 0.0] [0.0, 10.0, 0.0] [0.0, 10.0, 0.0] [0.0, 0.0, 4.0] [0.0, 0.0, 4.0] [0.0, 0.0, 4.0] [8.0, 0.0, 0.16] [8.0, 0.0, 0.16] [8.0, 0.0, 0.16] [8.0, 0.0, 0.16] [8.0, 0.0, 0.16] [8.0, 0.0, 0.16] [8.0, 0.0, 0.16] [8.0, 0.0, 0.16] [5.8, 0.0, 1.216] [7.2, 0.0, 0.144] [8.0, 0.0, 0.16] We notice the $Y$ variables are overall pretty saturated and almost integer, but the $X$ variables are highly fractional: the linear cuts are divided such that they fit perfectly the big rolls. This will make the variable hard to get to an integer solution.\nConclusion This was a quick intro to the cutting stock problem to get a grasp of its structure and difficulty, the goal was not to get too technical and keep a broad target audience.\nHope you enjoyed it, if that\u0026rsquo;s the case, I\u0026rsquo;ll see you on the next article, we\u0026rsquo;ll implement a column generation algorithm from scratch to solve it. If you have any question/remarks, feel free to get in touch.\nCode and citation Found this post useful for your work? The corresponding repository is available on GitHub, consider citing it using the following DOI 10.5281/zenodo.3329389, the BibTeX entry is available on Zenodo.\nThanks Special thanks to Soham and Aristide for their feedback, these helped me a great deal simplify the structure and add details and explanations where needed.\n Image source: https://www.flickr.com/photos/30478819@N08/38272827564\n","date":1527026400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581333203,"objectID":"5d900ecf2db384340871f9103b8562ae","permalink":"https://matbesancon.github.io/post/2018-05-23-colgen/","publishdate":"2018-05-23T00:00:00+02:00","relpermalink":"/post/2018-05-23-colgen/","section":"post","summary":"Solving a cutting stock problem step by step using Julia and JuMP\n","tags":["julia","modeling","optimization","integer-optimization","jump"],"title":"Tackling the cutting stock problem: part 1, problem exploration","type":"post"},{"authors":null,"categories":null,"content":"A quick introduction to the why and how of package development in Julia for scientific computing, with two applications of custom arrays. One of them, MatFuncs.jl was live-coded and available here.\n","date":1520463600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557161060,"objectID":"51365837d3dee98de7dbd9317c442995","permalink":"https://matbesancon.github.io/talk/julia_montreal/","publishdate":"2018-03-08T00:00:00+01:00","relpermalink":"/talk/julia_montreal/","section":"talk","summary":"A quick introduction to the why and how of package development in Julia for scientific computing, with two applications of custom arrays. One of them, MatFuncs.jl was live-coded and available here.","tags":null,"title":"Intro to package development in Julia","type":"talk"},{"authors":null,"categories":null,"content":"With the end-of-year celebrations, we all had some expenses to manage, some of them shared with friends, and we all have this eternal problem of splitting them fairly.\n Les bons comptes font les bons amis. French wisdom\n Applications like Tricount or Splitwise became famous precisely by solving this problem for you: just enter the expenses one by one, with who owes whom and you\u0026rsquo;ll get the simplest transactions to balance the amounts at the end.\nIn this post, we\u0026rsquo;ll model the expense balancing problem from a graph perspective and see how to come up with a solution using Julia and the JuliaGraphs ecosystem [1].\nThe expenses model Say that we have $n$ users involved in the expenses. An expense $\\delta$ is defined by an amount spent $\\sigma$, the user who paid the expense $p$ and a non-empty set of users who are accountable for this expense $a$.\n $\\delta = (\\sigma, p, a)$\n The total of all expenses $\\Sigma$ can be though of as: for any two users $u_i$ and $u_j$, the total amount that $u_i$ spent for $u_j$. So the expenses are a vector of triplets (paid by, paid for, amount).\nAs an example, if I went out for pizza with Joe and paid 8GPHC for the two of us, the expense is modeled as:\n $\\delta = (\\sigma: 8GPHC, p: Mathieu, a: [Mathieu, Joe])$.\n Now considering I don\u0026rsquo;t keep track of money I owe myself, the sum of all expenses is the vector composed of one triplet:\n $\\Sigma = [(Mathieu, Joe, \\frac{8}{2} = 4)]$\n In Julia, the expense information can be translated to a structure: const User = Int const GraphCoin = Float16 struct Expense payer::User amount::GraphCoin users::Set{User} end\nReducing expenses Now that we have a full representation of the expenses, the purpose of balancing is to find a vector of transactions which cancels out the expenses. A naive approach would be to use the transposed expense matrix as a transaction matrix. If $u_i$ paid $\\Sigma_{i,j}$ for $u_j$, then $u_j$ paying back that exact amount to $u_i$ will solve the problem. So we need in the worst case as many transactions after the trip as $|u| \\cdot (|u| - 1)$. For 5 users, that\u0026rsquo;s already 20 transactions, how can we improve it?\nBreaking strongly connected components Suppose that I paid the pizza slice to Joe for 4GPHC, but he bought me an ice cream for 2GPHC the day after. In the naive models, we would have two transactions after the trip: he give me 4GPHC and I would give him 2GPHC. That does not make any sense, he should simply pay the difference between what he owes me and what I owe him. For any pair of users, there should only be at most one transaction from the most in debt to the other, this result in the worst case of $\\frac{|u| \\cdot (|u| - 1)}{2}$ transactions, so 10 transactions for 5 people.\nNow imagine I still paid 4GPHC for Joe, who paid 2GPHC for Marie, who paid 4GPHC for me. In graph terminology, this is called a strongly connected component. The point here is that transactions will flow from one user to the next one, and back to the first.\nIf there is a cycle, we can find the minimal due sum within it. In our 3-people case, it is 2GPHC. That\u0026rsquo;s the amount which is just moving from hand to hand and back at the origin: it can be forgotten. This yields a new net debt: I paid 2GPHC for Joe, Marie paid 2GPHC for me. We reduced the number of transactions and the amount due thanks to this cycle reduction.\nExpenses as a flow problem To simplify the problem, we can notice we don\u0026rsquo;t actually care about who paid whom for what, a fair reimbursement plan only requires two conditions:\n All people who are owed some money are given at least that amount People who owe money don\u0026rsquo;t pay more than the net amount they ought to pay  We can define a directed flow network with users split in two sets of vertices, depending on whether they owe or are owed money. We call these two sets $V_1$ and $V_2$ respectively.\n There is an edge from any node of $V_1$ to any node of $V_2$. We define a source noted $s$ connected to all vertices in $V_1$, the edge from $s$ to any node of $V_1$ has a capacity equal to what they owe. We define a sink noted $t$ to which all vertices in $V_2$ connect, with infinite capacity and a demand (the minimal flow that has to pass through) equal to what they are owed.  With this model, GraphCoins will flow from user owing money to users who are owed money, see Wikipedia description of the flow problem.\nComputing net owed amount per user Given a vector of expenses, we should be able to build the matrix holding what is owed in net from a user to another:\n\u0026#34;\u0026#34;\u0026#34; Builds the matrix of net owed GraphCoins \u0026#34;\u0026#34;\u0026#34; function compute_net_owing(expenses::Vector{Expense}, nusers::Int) owing_matrix = zeros(GraphCoin, nusers, nusers) # row owes to column for expense in expenses for user in expense.users if user != expense.payer owing_matrix[user,expense.payer] += expense.amount / length(expense.users) end end end # compute net owed amount net_owing = zeros(GraphCoin, nusers, nusers) for i in 1:nusers-1 for j in i+1:nusers if owing_matrix[i,j] \u0026gt; owing_matrix[j,i] net_owing[i,j] = owing_matrix[i,j] - owing_matrix[j,i] elseif owing_matrix[i,j] \u0026lt; owing_matrix[j,i] net_owing[j,i] = owing_matrix[j,i] - owing_matrix[i,j] end end end return net_owing end From that matrix, we should determine the net amount any user owes or is owed: \u0026#34;\u0026#34;\u0026#34; What is owed to a given user (negative if user owes money) \u0026#34;\u0026#34;\u0026#34; function net_owed_user(net_owing::Matrix{GraphCoin}) return (sum(net_owing,1)\u0026#39; - sum(net_owing,2))[:,1] end\nThe sum function used with 1 or 2 sums a matrix over its rows, columns respectively. This computes a difference between what a user is owed and what they owe.\nBuilding the graph and the corresponding flow problem A flow problem is determined by the directed graph (nodes and directed edges), the minimal flow for any edge, a maximal flow or capacity for any edge and a cost of having a certain flow going through each edge.\nFirst, we need to import LightGraphs, the core package of the JuliaGraph ecosystem containing essential types.\nimport LightGraphs; const lg = LightGraphs  Note that I use explicit package import (not using), an habit I kept from using Python and that I consider more readable than importing the whole package into the namespace. lg has become my usual name for the LightGraphs package.\n function build_graph(net_owing::Matrix{GraphCoin}) nusers = size(net_owing,1) g = lg.DiGraph(nusers + 2) source = nusers + 1 sink = nusers + 2 net_user = net_owed_user(net_owing) v1 = [idx for idx in 1:nusers if net_user[idx] \u0026lt; 0] v2 = [idx for idx in 1:nusers if net_user[idx] \u0026gt;= 0] capacity = zeros(GraphCoin, nusers+2,nusers+2) demand = zeros(GraphCoin, nusers+2,nusers+2) maxcap = sum(net_owing) for u1 in v1 lg.add_edge!(g,source,u1) capacity[source,u1] = -net_user[u1] for u2 in v2 lg.add_edge!(g,u1,u2) capacity[u1,u2] = maxcap end end for u2 in v2 lg.add_edge!(g,u2,sink) capacity[u2,sink] = maxcap demand[u2,sink] = net_user[u2] end (g, capacity, demand) end This function builds our graph structure and all data we need attached.\nSolving the flow problem Now that the components are set, we can solve the problem using another component of the JuliaGraphs ecosystem specialized for flow problems:\nusing LightGraphsFlows: mincost_flow using Clp: ClpSolver We also need a Linear Programming solver to pass to the flow solver, all we have to do is bundle the pieces together:\nfunction solve_expense(expenses::Vector{Expense}, nusers::Int) (g, capacity, demand) = build_graph(compute_net_owing(expenses, nusers)) flow = mincost_flow(g, capacity, demand, ones(nusers+2,nusers+2), ClpSolver(), nusers+1, nusers+2) return flow[1:end-2,1:end-2] end We truncate the flow matrix because we are only interested in what users are paying each other, not in the flows from and to the source and sink.\nTrying out our solution Now that all functions are set, we can use it on any expense problem:\nexpenses = [ Expense(1, 10, Set([1,2])), Expense(1, 24, Set([1,2,3])), Expense(3, 10, Set([2,3])) ] solve_expense(expenses, 3) 3×3 Array{Float64,2}: 0.0 0.0 0.0 18.0 0.0 0.0 3.0 0.0 0.0 In the result, each row pays to each column and voilà! Our three users don\u0026rsquo;t have to feel the tension of unpaid debts anymore.\nConclusion, perspective and note on GPHC We managed to model our specific problem using LightGraphs.jl and the associated flow package pretty easily. I have to admit being biased since I contributed to the JuliaGraphs ecosystem, if your impression is different or if you have some feedback, don\u0026rsquo;t hesitate to file an issue on the corresponding package, some awesome people will help you figure things out as they helped me.\nThere is one thing we ignored in our model, it\u0026rsquo;s the number of transactions realized. Using this as an objective turns the problem into a Mixed-Integer Linear Programming one, which are much harder to solve and cannot use simple flow techniques. However, I still haven\u0026rsquo;t found a case where our simple approach does not yield the smallest number of transactions.\nFinal word: I started the idea of this article long before the crypto-madness (September actually), when currencies where still considered as boring, nerdy or both, sorry about following the (late) hype. I even changed GraphCoin symbol to GPHC because I found another one with which my initial name conflicted.\nIf you have questions or remarks on LightGraphs, LightGraphsFlows, the article or anything related, don\u0026rsquo;t hesitate to ping me!\nEdits:\nSpecial thanks to Seth Bromberger for the review.\n The cover image was created using GraphPlot.jl.\n[1] James Fairbanks Seth Bromberger and other contributors. Juliagraphs/LightGraphs.jl: Lightgraphs, 2017, https://doi.org/10.5281/zenodo.889971. DOI: 10.5281/zenodo.889971\n","date":1515970800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557151933,"objectID":"5dd7446f6cc4ddd5c173d6d1f089ef04","permalink":"https://matbesancon.github.io/post/2017-09-11-graph-theory-expenses-management/","publishdate":"2018-01-15T00:00:00+01:00","relpermalink":"/post/2017-09-11-graph-theory-expenses-management/","section":"post","summary":"Graph theory and Julia to solve the boring aspect of having friends\n","tags":["graph","julia"],"title":"Solving the group expenses headache with graphs","type":"post"},{"authors":null,"categories":null,"content":"Starting from a weird Kaggle side-project during the Chrismas holidays, I gradually got involved in the JuliaGraphs ecosystem. After some discussion on the Julia Slack #graphs channel, I went from reporting a simple feature I needed to helping with the re-organization by splitting out two packages:\n LightGraphsMatching.jl LightGraphsFlows.jl  I also implemented the min-cost flow problem formulated as a linear optimization problem formulated using MathProgBase.jl, using any user-provided solver.\nMany thanks to the whole JuliaGraphs team for their trust, support and advice.\n","date":1515538800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557328745,"objectID":"ab7f7eac66e9649ddaee5ffc49b4d30d","permalink":"https://matbesancon.github.io/project/juliagraphs/","publishdate":"2018-01-10T00:00:00+01:00","relpermalink":"/project/juliagraphs/","section":"project","summary":"A graph modeling and analysis ecosystem for Julia","tags":["open-source","graph","julia-package"],"title":"JuliaGraphs contributions","type":"project"},{"authors":null,"categories":null,"content":"WebFuncs.jl is a project testing the Julia language out of its natural scope. Having played quite a bit with Go and Python, I wanted to see if the Julia ecosystem had tools for HTTP handling.\nThe inspiration of a simple-to-use function server came from the fx project. Define your function, the package throws it as a server for you.\nThe package has been accepted on the Julia package repository and can be fetched using Pkg.add(\u0026quot;WebFuncs\u0026quot;).\n","date":1515538800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557328745,"objectID":"17dc9c3f360fd25b4bb5bcc079859ee5","permalink":"https://matbesancon.github.io/project/webfuncs/","publishdate":"2018-01-10T00:00:00+01:00","relpermalink":"/project/webfuncs/","section":"project","summary":"Serve Julia functions with HTTP","tags":["open-source","julia-package"],"title":"WebFuncs","type":"project"},{"authors":null,"categories":null,"content":"In the last article, we explored different modeling options for a three-component systems which could represent the dynamics of a chemical reaction or a disease propagation in a population. Building on top of this model, we will formulate a desirable outcome and find a decision which maximizes this outcome.\n In addition to the packages imported in the last post, we will also use BlackBoxOptim.jl:\n import DifferentialEquations const DiffEq = DifferentialEquations import Plots import Optim The model The same chemical system with three components, A, B and R will be used: $$A + B → 2B$$ $$B → R$$\nThe reactor where the reaction occurs must remain active for one minute. Let\u0026rsquo;s imagine that $B$ is our valuable component while $R$ is a waste. We want to maximize the quantity of $B$ present within the system after one minute, that\u0026rsquo;s the objective function. For that purpose, we can choose to add a certain quantity of new $A$ within the reactor at any point. $$t_{inject} ∈ [0,t_{final}]$$.\nImplementing the injection There is one major feature of DifferentialEquations.jl we haven\u0026rsquo;t explored yet: the event handling system. This allows for the system state to change at a particular point in time, depending on conditions on the time, state, etc\u0026hellip;\n# defining the problem const α = 0.8 const β = 3.0 diffeq = function(du, u, p, t) du[1] = - α * u[1] * u[2] du[2] = α * u[1] * u[2] - β * u[2] du[3] = β * u[2] end u0 = [49.0;1.0;0.0] tspan = (0.0, 1.0) prob = DiffEq.ODEProblem(diffeq, u0, tspan) const A_inj = 30 inject_new = function(t0) condition(u, t, integrator) = t0 - t affect! = function(integrator) integrator.u[1] = integrator.u[1] + A_inj end callback = DiffEq.ContinuousCallback(condition, affect!) sol = DiffEq.solve(prob, callback=callback) sol end # trying it out with an injection at t=0.4 sol = inject_new(0.4) Plots.plot(sol) The ContinuousCallback construct is the central element here, it takes as information:\n When to trigger the event, implemented as the condition function. It triggers when this function reaches 0, which is here the case when $t = t_0$. What to do with the state at that moment. The state is encapsulated within the integrator variable. In our case, we add 30 units to the concentration in A.  As we can see on the plot, a discontinuity appears on the concentration in A at the injection time, the concentration in B restarts increasing.\nFinding the optimal injection time: visual approach From the previously built function, we can get the whole solution with a given injection time, and from that the final state of the system.\ntinj_span = 0.05:0.005:0.95 final_b = [inject_new(tinj).u[end][2] for tinj in tinj_span] Plots.plot(tinj_span, final_b) Using a plain for comprehension, we fetch the solution of the simulation for the callback built with each $t_{inject}$.\nInjecting $A$ too soon lets too much time for the created $B$ to turn into $R$, but injecting it too late does not let enough time for $B$ to be produced from the injected $A$. The optimum seems to be around ≈ 0.82,\nFinding the optimum using Optim.jl The package requires an objective function which takes a vector as input. In our case, the decision is modeled as a single variable (the injection time), it\u0026rsquo;s crucial to make the objective use a vector nonetheless, otherwise calling the solver will just explode with cryptic errors.\ncompute_finalb = tinj -\u0026gt; -1 * inject_new(tinj[1]).u[end][2] Optim.optimize(compute_finalb, 0.1, 0.9) We get a detailed result of the optimization including the method and iterations:\n* Algorithm: Brent's Method * Search Interval: [0.100000, 0.900000] * Minimizer: 8.355578e-01 * Minimum: -2.403937e+01 * Iterations: 13 * Convergence: max(|x - x_upper|, |x - x_lower|) \u0026lt;= 2*(1.5e-08*|x|+2.2e-16): true * Objective Function Calls: 14 The function inject_new we defined above returns the complete solution of the simulation, we get the state matrix u, from which we extract the final state u[end], and then the second component, the concentration in B: u[end][2]. The optimization algorithm minimizes the objective, while we want to maximize the final concentration of B, hence the -1 multiplier used for\ncompute_finalb.\n We can use the Optim.jl package because our function is twice differentiable, the best improvement direction is easy to compute.\n Extending the model The decision over one variable was pretty straightforward. We are going to extend it by changing how the $A$ component is added at $t_{inject}$. Instead of being completely dissolved, a part of the component will keep being poured in after $t_{inject}$. So the decision will be composed of two variables:\n The time of the beginning of the injection The part of $A$ to inject directly and the part to inject in a continuous fashion. We will note the fraction injected directly $\\delta$.  Given a fixed available quantity $A₀$ and a fraction to inject directly $\\delta$, the concentration in A is increased of $\\delta \\cdot A₀$ at time $t_{inject}$, after which the rate of change of the concentration in A is increased by a constant amount, until the total amount of A injected (directly and over time) is equal to the planned quantity.\nWe need a new variable in the state of the system, $u_4(t)$, which stands for the input flow of A being active or not.\n $u(t) = 0$ if $t \u0026lt; t_{inject}$ $u(t) = 0$ if the total flow of A which has been injected is equal to the planned quantity $u(t) = \\dot{A}\\ $ otherwise, with $\\dot{A}\\ $ the rate at which A is being poured.  New Julia equations We already built the key components in the previous sections. This time we need two events:\n A is directly injected at $t_{inject}$, and then starts being poured at constant rate A stops being poured when the total quantity has been used  const inj_quantity = 30.0; const inj_rate = 40.0; diffeq_extended = function(du, u, p, t) du[1] = - α * u[1] * u[2] + u[4] du[2] = α * u[1] * u[2] - β * u[2] du[3] = β * u[2] du[4] = 0.0 end u0 = [49.0;1.0;0.0;0.0] tspan = (0.0, 1.0) prob = DiffEq.ODEProblem(diffeq_extended, u0, tspan) We wrap the solution building process into a function taking the starting time and the fraction being directly injected as parameters:\ninject_progressive = function(t0, direct_frac) condition_start(u, t, integrator) = t0 - t affect_start! = function(integrator) integrator.u[1] = integrator.u[1] + inj_quantity * direct_frac integrator.u[4] = inj_rate end callback_start = DiffEq.ContinuousCallback( condition_start, affect_start!, save_positions=(true, true) ) condition_end(u, t, integrator) = (t - t0) * inj_rate - inj_quantity * (1 - direct_frac) affect_end! = function(integrator) integrator.u[4] = 0.0 end callback_end = DiffEq.ContinuousCallback(condition_end, affect_end!, save_positions=(true, true)) sol = DiffEq.solve(prob, callback=DiffEq.CallbackSet(callback_start, callback_end), dtmax=0.005) end Plots.plot(inject_progressive(0.6,0.6)) We can notice callback_start being identical to the model we previously built, while condition_end corresponds to the time when the total injected quantity reaches inj_quantity. The first events activates $u_4$ and sets it to the nominal flow, while the second callback resets it to 0.\nOptim.jl can be re-used to determine the optimal decision:\nobjective = function(x) sol = inject_progressive(x[1], x[2]) -sol.u[end][2] end # wrapped objective function and starting point x0 = 0.5*ones(2) wrapped_obj = Optim.OnceDifferentiable(objective, x0) # call optimize with box algorithm Optim.optimize(wrapped_obj, x0, [0.1,0.0], [1.0,1.0], Optim.Fminbox()) The result details are:\n* Algorithm: Fminbox with Conjugate Gradient * Starting Point: [0.5,0.5] * Minimizer: [0.8355419400368459,0.9999654432422779] * Minimum: -2.404040e+01 * Iterations: 4 * Convergence: true * |x - x'| ≤ 1.0e-32: false |x - x'| = 3.43e-04 * |f(x) - f(x')| ≤ 1.0e-32 |f(x)|: true |f(x) - f(x')| = -6.85e-11 |f(x)| * |g(x)| ≤ 1.0e-08: false |g(x)| = 9.05e-08 * Stopped by an increasing objective: true * Reached Maximum Number of Iterations: false * Objective Calls: 125 * Gradient Calls: 79 We wrap our function in a Optim.OnceDifferentiable to provide Optim with the information that the function is differentiable, even though we don\u0026rsquo;t provide a gradient, it can be computed by automatic differentiation or finite differences.\nThe optimal solution corresponds to a complete direct injection ($\\delta \\approx 1$) with $t_{inject}^{opt}$ identical to the previous model. This means pouring the A component in a continuous fashion does not allow to produce more $B$ at the end of the minute.\nConclusion We could still built on top of this model to keep refining it, taking more phenomena into account (what if the reactions produce heat and are sensitive to temperature?). The structures describing models built with DifferentialEquations.jl are transparent and easy to use for further manipulations.\nOne point on which I place expectations is some additional interoperability between DifferentialEquations.jl and JuMP, a Julia meta-package for optimization. Some great work was already performed to combine the two systems, one use case that has been described is the parameter identification problem (given the evolution of concentration in the system, identify the α and β parameters).\nBut given that the function I built from a parameter was a black box (without an explicit formula, not a gradient), I had to use BlackBoxOptim, which is amazingly straightforward, but feels a bit overkill for smooth functions as presented here. Maybe there is a different way to build the objective function, using parametrized functions for instance, which could make it transparent to optimization solvers.\nIf somebody has info on that last point or feedback, additional info you\u0026rsquo;d like to share regarding this post, hit me on Twitter. Thanks for reading!\n Edits and improvements 2018-01-31:\nI updated this post to adapt to the new DifferentialEquations.jl interface. I also used Optim.jl for the two cases without BlackBoxOptim.jl, which is very nice but not necessary for differentiable functions.\nSpecial thanks to Patrick for his quick response and help with Optim.jl.\n 2017-12-20:\nOf course, BlackBoxOptim.jl was not the most appropriate algorithm as predicted. Patrick and Chris gave me some hints in this thread and I gave Optim.jl a try.\nThis package has a range of algorithms to choose from depending on the structure of the function and the knowledge of its gradient and Hessian. The goal is continuous optimization, (as opposed to BlackBoxOptim.jl which supports more exotic search spaces).\nFinding the optimum $t_{inject}$ of the first problem is pretty simple: import Optim Optim.optimize(compute_finalb, 0.1, 0.9)\nThis yields the following information:\nResults of Optimization Algorithm * Algorithm: Brent's Method * Search Interval: [0.100000, 0.900000] * Minimizer: 8.355891e-01 * Minimum: -2.403824e+01 * Iterations: 13 * Convergence: max(|x - x_upper|, |x - x_lower|) \u0026lt;= 2*(1.5e-08*|x|+2.2e-16): true * Objective Function Calls: 14 14 calls to the objective function, pretty neat compared to the hundreds of BlackBoxOptim. We also confirm the optimum of 0.8355891. Not yet sure we could use Optim.jl for the second case (boxed multivariate optimization without explicit gradient).\n ","date":1513724400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557151933,"objectID":"0bb6cb3812eac858d8ee997b6b289fc4","permalink":"https://matbesancon.github.io/post/2017-12-20-diffeq-julia2/","publishdate":"2017-12-20T00:00:00+01:00","relpermalink":"/post/2017-12-20-diffeq-julia2/","section":"post","summary":"Now that we've built a model, let's use it to make the best decision\n","tags":["julia","modeling","numerical-techniques","applied-math","optimization"],"title":"DifferentialEquations.jl - part 2: decision from the model","type":"post"},{"authors":null,"categories":null,"content":"DifferentialEquations.jl came to be a key component of Julia\u0026rsquo;s scientific ecosystem. After checking the JuliaCon talk of its creator, I couldn\u0026rsquo;t wait to start building stuff with it, so I created and developed a simple example detailed in this blog post. Starting from a basic ordinary differential equation (ODE), we add noise, making it stochastic, and finally turn it into a discrete version.\n Before running the code below, two imports will be used:\n import DifferentialEquations const DiffEq = DifferentialEquations import Plots I tend to prefer explicit imports in Julia code, it helps to see from which part each function and type comes. As DifferentialEquations is longuish to write, we use an alias in the rest of the code.\nThe model We use a simple 3-element state in a differential equation. Depending on your background, pick the interpretation you prefer:\n  An SIR model, standing for susceptible, infected, and recovered, directly inspired by the talk and by the Gillespie.jl package. We have a total population with healthy people, infected people (after they catch the disease) and recovered (after they heal from the disease).\n  A chemical system with three components, A, B and R. $$A + B → 2B$$ $$B → R$$\n  After searching my memory for chemical engineering courses and the universal source of knowledge, I could confirm the first reaction is an autocatalysis, while the second is a simple reaction. An autocatalysis means that B molecules turn A molecules into B, without being consumed.\nThe first example is easier to represent as a discrete problem: finite populations make more sense when talking about people. However, it can be seen as getting closer to a continuous differential equation as the number of people get higher. The second model makes more sense in a continuous version as we are dealing with concentrations of chemical components.\nA first continuous model Following the tutorials from the official package website, we can build our system from:\n A system of differential equations: how does the system behave (dynamically) Initial conditions: where does the system start A time span: how long do we want to observe the system  The system state can be written as: $$u(t) = \\begin{bmatrix} u₁(t) \\ u₂(t) \\ u₃(t)\n\\end{bmatrix}^T $$\nWith the behavior described as: $$ \\dot{u}(t) = f(u,t) $$ And the initial conditions $u(0) = u₀$.\nIn Julia with DifferentialEquations, this becomes: α = 0.8 β = 3.0 function diffeq(du, u, p, t) du[1] = - α * u[1] * u[2] du[2] = α * u[1] * u[2] - β * u[2] du[3] = β * u[2] end u₀ = [49.0;1.0;0.0] tspan = (0.0, 1.0)\ndiffeq models the dynamic behavior, u₀ the starting conditions and tspan the time range over which we observe the system evolution. Note that the diffeq function also take a p argument for parameters, in which we could have stored $\\alpha$ and $\\beta$.\nWe know that our equation is smooth, so we\u0026rsquo;ll let DifferentialEquations.jl figure out the solver. The general API of the package is built around two steps:\n Building a problem/model from behavior and initial conditions Solving the problem using a solver of our choice and providing additional information on how to solve it, yielding a solution.  prob = DiffEq.ODEProblem(diffeq, u₀, tspan) sol = DiffEq.solve(prob) One very nice property of solutions produced by the package is that they contain a direct way to produce plots. This is fairly common in Julia to implement methods from other packages, here the ODESolution type implements Plots.plot:\nPlots.plot(sol) If we use the disease propagation example, $u₁(t)$ is the number of healthy people who haven\u0026rsquo;t been infected. It starts high, which makes the rate of infection by the diseased population moderate. As the number of sick people increases, the rate of infection increases: there are more and more possible contacts between healthy and sick people.\nAs the number of sick people increases, the recovery rate also increases, absorbing more sick people. So the \u0026ldquo;physics\u0026rdquo; behind the problem makes sense with what we observe on the curve.\nA key property to notice is the mass conservation: the sum of the three elements of the vector is constant (the total population in the health case). This makes sense from the point of view of the equations: $$\\frac{du₁}{dt} + \\frac{du₂}{dt} + \\frac{du_3}{dt} = 0$$\nAdding randomness: first attempt with a simple SDE The previous model works successfully, but remains naive. On small populations, the rate of contamination and recovery cannot be so smooth. What if some sick people isolate themselves from others for an hour or so, what there is a meeting organized, with higher chances of contacts? All these plausible events create different scenarios that are more or less likely to happen.\nTo represent this, the rate of change of the three variables of the system can be considered as composed of a deterministic part and of a random variation. One standard representation for this, as laid out in the package documentation is the following: $$ du = f(u,t) dt + ∑ gᵢ(u,t) dWᵢ $$\nIn our case, we could consider two points of randomness at the two interactions (one for the transition from healthy to sick, and one from sick to recovered).\nStochastic version σ1 = 0.07 σ2 = 0.4 noise_func = function(du, u, p, t) du[1] = σ1 * u[1] * u[2] du[3] = σ2 * u[2] du[2] = - du[1] - du[3] end stoch_prob = DiffEq.SDEProblem(diffeq, noise_func, u₀, tspan) sol_stoch = DiffEq.solve(stoch_prob, DiffEq.SRIW1()) Note that we also change the solver provided to the solve function to adapt to stochastic equations. The last variation is set to the opposite of the sum of the two others to compensate the two other variations (we said we had only one randomness phenomenon per state transition).\nWoops, something went wrong. This time the mass conservation doesn\u0026rsquo;t hold, we finish with a population below the initial condition. What is wrong is that we don\u0026rsquo;t define the variation but the gᵢ(u,t) function, which is then multiplied by dWᵢ. Since we used the function signature corresponding to the diagonal noise, there is a random component per $uᵢ$ variable.\nAdding randomness: second attempt with non-diagonal noise As explained above, we need one source of randomness for each transition. This results in a $G(u,t)$ matrix of $3 × 2$. We can then make sure that the the sum of variations for the three variables cancel out to keep a constant total population.\nnoise_func_cons = function(du, u, p, t) du[1, 1] = σ1 * u[1] * u[2] du[1, 2] = 0.0 du[2, 1] = - σ1 * u[1] * u[2] du[2, 2] = - σ2 * u[2] du[3,1] = 0.0 du[3,2] = σ2 * u[2] end sde_cons = DiffEq.SDEProblem( diffeq, noise_func_cons, u₀, tspan, noise_rate_prototype=zeros(3,2) ) cons_solution = DiffEq.solve(sde_cons, DiffEq.EM(), dt=1/500) We also provide a noise_rate_prototype parameter to the problem builder to indicate we don\u0026rsquo;t want to use a diagonal noise.\nThis time the population conservation holds, at any point in time the sum of the $uᵢ(t)$ remains 50.\nDiscretizing: Gillespie model The models we produced so far represent well the chemical reaction problem, but a bit less the disease propagation. We are using continuous quantities to represent discrete populations, how do we interpret 0.6 people sick at a time?\nOne major strength of the package is its effortless integration of discrete phenomena in a model, alone or combined with continuous dynamics. Our model follows exactly the package tutorial on discrete stochastic problems, so building it should be straightforward.\ninfect_rate = DiffEq.Reaction(α, [1,2],[(1,-1),(2,1)]) recover_rate = DiffEq.Reaction(β, [2],[(2,-1),(3,1)]) disc_prob = DiffEq.GillespieProblem( DiffEq.DiscreteProblem(round.(Int,u₀), tspan), DiffEq.Direct(), infect_rate, recover_rate, ) disc_sol = DiffEq.solve(disc_prob, DiffEq.Discrete()); We define the infection and recovery rate and the variables $uᵢ$ that are affected, and call the Discrete solver. The Plots.jl integration once again yields a direct representation of the solution over the time span.\nAgain, the conservation of the total population is guaranteed by the effect of the jumps deleting one unit from a population to add it to the other.\nConclusion The DifferentialEquations.jl package went from a good surprise to a key tool in my scientific computing toolbox. It does not require learning another embedded language but makes use of real idiomatic Julia. The interface is clean and working on edge cases does not feel hacky. I\u0026rsquo;ll be looking forward to using it in my PhD or side-hacks, especially combined to the JuMP.jl package: DifferentialEquations used to build simulations and JuMP to optimize a cost function on top of the created model.\nThanks for reading, get on touch on Twitter for feedback or questions ;)\n Edits:\nI updated this post to fit the new DifferentialEquations.jl 4.0 syntax. Some changes are breaking the previous API, it can be worth it to check it out in detail.\nChris, the creator and main developer of DifferentialEquations.jl, gave me valuable tips on two points which have been edited in the article. You can find the thread here.\n Import aliases should use const PackageAlias = PackageName for type stability. This allows the compiler to generate efficient code. Some further mentions of type-stability can be found in the official doc The second attempts uses non-diagonal noise, the \u0026ldquo;:additive\u0026rdquo; hint I passed to the solve function does not hold. Furthermore, the appropriate algorithm in that case is the Euler-Maruyama method.  Many thanks to him for these tips, having such devoted and friendly developers is also what makes an open-source project successful.\n ","date":1513206000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1578325251,"objectID":"c5d2541b8ec153f68e77d373b80d0e1d","permalink":"https://matbesancon.github.io/post/2017-12-14-diffeq-julia/","publishdate":"2017-12-14T00:00:00+01:00","relpermalink":"/post/2017-12-14-diffeq-julia/","section":"post","summary":"Playing around with the differential equation solver turned simulation engine\n","tags":["julia","modeling","numerical-techniques","applied-math"],"title":"Getting started with DifferentialEquations.jl","type":"post"},{"authors":null,"categories":null,"content":"The start of my journey as a PhD student last September was a big step, but also an opportunity to review and improve my working habits. My day time had to be used properly, both for results' sake and to be able to keep a balanced life.\nI had been introduced to the Pomodoro technique at Equisense (thanks Camille!) but remained skeptical as for its potential value within my work flow at the time.\nTo make it short, the technique consists in the following steps:\n Decide what task should be worked on. Allocate a given time to work (around 25 minutes) Set a timer and get to work When the time is up, make a short pause (~5 minutes), then repeat After 4 work sprints, take a longer break (~15-30 minutes)  What was wrong with that? The development, test and operation phases were generally self-determining and lead to sprints from 20 to 120 minutes (that length isn\u0026rsquo;t surprising for some tasks and when highly focused). These were also often interrupted by team interactions (required concertation with members of the tech and product team, backend-specific collaborative problem-solving, \u0026hellip;). The main point was that there are enough spontaneous interruptions of the work flow, no need to introduce an additional artificial one. As I look back, I still think this was a valid reason not to use this technique.\nWhat has changed? Time management as a grad student has to be un- and re-learned: rules are different, criteria for success change and so on.\n Time management seen by PhD comics [2]\n Problem structure: programming at a startup vs. applied math In my case, the major part of the workload switched from an implementation-heavy to a modeling-heavy context. As such, the work phases tend to be longer and with an heavier cognitive load. I am not saying that programming is easier, but I\u0026rsquo;m pretty sure mathematics almost always requires to keep more information in mind while working on a problem. Another opinion is that the part of instinct to find a path towards a solution is higher in mathematics.\nWhile programming, there are some key techniques that reduce the number of possible sources to a problem:\n Getting information on the state of the program at a given point (logging, debugging, printing to stdout) Testing the behavior of an isolated piece of the program with given input  These techniques also work for scientific computing of course, but are harder to apply to both modeling and symbolic calculus, the different pieces of the problem have to be combined to find special structures which allow for a resolution. More solutions also tend to come while NOT looking at mathematical problem than for programming problems, where solutions come either in front of the code or when voluntarily thinking of the problem.\nTeam-dependent work vs. figure it out for yourself Most startups obviously value team work, it is one of the group skills that differentiate companies building great things from the ones stuck in an eternal early stage. This was even more true at Equisense where collaboration and product development were both very synchronous by modern standards. It had cons but ease two things:\n Speed of product development. Lots of team under-estimate post-development coordination, the last meters of the sprint to have a feature ready Programming by constraints. Because of fast interactions between the people responsible for the different components, constraints from each one is quickly communicated and the modeling process is defined accounting for them right away.  Now in research, especially in applied mathematics, the work is mostly independent, synchronization happens when working on a joined project for instance. This means that all the interruptions that were happening throughout the day are now gone! Nothing would stop you from working day and night without a break.\nConclusion Two key results of this change of work style are:\n Work sprints are not naturally bound anymore, obviously with decreasing efficiency Few to no interactions interrupt the sprints either  My conclusion was the necessity of a time management technique and associated tools, with a low cognitive overhead and bringing as little distraction as possible.\nFrom these criteria, I rejected a mobile app, smartphones are great to bring different sources of information and communication channels together, not for remaining focused for hours, mobile apps are designed to catch and retain attention, that\u0026rsquo;s simply part of their business model. I also rejected web-based solutions for the constraint of firing up a browser, amongst the heaviest pieces of software on our modern desktops, just to start a working session.\nSo desktop GUI or CLI it is. Even though there is the gnomepomodoro project, it did not seem compatible with all Linux desktops. At that point, I realized the amount of work to build a Pomodoro was low, the requirements and constraints well known, I throw ideas together and start coding.\nI\u0026rsquo;ll explain the initial development and iterations of the app in Go in a second article, if you liked this one, let me know!\n Sources and images:\n1\n2\n","date":1508364000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508527327,"objectID":"f7564da8cfdbdb8403a8b8800b323b74","permalink":"https://matbesancon.github.io/post/2017-10-19-tomate-cli/","publishdate":"2017-10-19T00:00:00+02:00","relpermalink":"/post/2017-10-19-tomate-cli/","section":"post","summary":"Switching from data scientist to graduate student is not\nonly a variation in tasks, but also in success criteria and work flow\n","tags":["golang","phd","productivity"],"title":"Switching my work flow to Pomodoro for grad studies - part I: motivation  ","type":"post"},{"authors":null,"categories":null,"content":"Last weeks have been pretty intense. I officially left Equisense and started a joined PhD project between INRIA Lille and École Polytechnique Montreal. I had been preparing for this fresh start for several months and also wanted to evolve in my content creation process.\nA journey from plain markdown to Hugo I started writing articles to keep track of my learning paths on various topics, including numerical techniques, data analysis and programming. My first articles were either hand-written or RMarkdown-generated Markdown files on a GitHub repository.\nAs I was slowly moving from R to Python, Jupyter notebook became pretty handy to mix paragraphs, code snippets, results and charts. It also forced me to quit declaring and modifying variables, an annoying habit got from always having a REPL and text editor bundled in most scientific computing IDEs (Matlab, Scilab, RStudio, Jupyter).\nGreat, the articles were not centralized though but split into their GitHub repositories, you have to admit this is not the most user-friendly browsing experience. I found several blogs running on Jekyll and I decided to give it a try. For someone who is not fond of struggles with front-end side layout issues, this was a true gift, I could easily reuse templates from front-end developers and designers (special thanks for the awesome Gravity project) without much struggle and focus on what I liked: building projects and writing content.\nSwitching to THE writing platform I kept maintaining the Jekyll blog until almost exactly one year ago. During that time, I was mostly writing in the context of a side-project or thinking on our journey at Equisense. This raised new requirements for the writing process such as collaborative writing, review from friends, seeing the overall picture we were sending as a team from the sum of our articles.\nFor these reasons, my articles gradually switched to Medium, first published as an individual, then on the Equisense page. This was a very productive time for writing as we encouraged one another and had a direct impact on the way we presented the team, how we work and our learning path: an invaluable tool to help candidates decide whether the company was a fit for them and to ease the onboading.\nIf Medium works, why would anyone go back to writing everything from scratch? I really enjoy the writing experience on Medium, with some drawbacks. Medium\u0026rsquo;s design is very opinionated, that\u0026rsquo;s a part of what makes it a experience. However, leaving some choices on key topics is essential (at least to me) on the content-creation side. I believe this should be the case on any two-sided platform: be opinionated on the user-side, leave flexibility on the creator side.\nThe perfect example is the bright screen. It ensures the Medium experience is consistent with the unique font, background etc\u0026hellip; But writing on a dark screen is a lot more comfortable, especially when you\u0026rsquo;re used to it or when your eyes are more light-sensitive: writing late in the evening or early in the morning was not conceivable to me on the Medium interface. The hack I used was to write everything on Atom, then paste everything to Medium once the first draft was ready, still a bit of a pain.\nThis might seem minor as a reason to switch, but the root behind it is more essential: Medium is a platform, you\u0026rsquo;re therefore a user, not an owner. Despite its global success, the company is still young and looking for the right model. Nothing tells me the model they choose tomorrow will be one I want to contribute to (how paid content will be managed for instance). Switching platforms for written content is a lot more tedious than choosing well at the beginning. This new step in my professional and personal life is the perfect occasion to rethink that commitment, I will still be re-publishing content to Medium, but not as the primary source.\n","date":1504562400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557151933,"objectID":"995a003b8692a04fd7cb9fc1e8fac62f","permalink":"https://matbesancon.github.io/post/2017-09-05-moving-content-hugo/","publishdate":"2017-09-05T00:00:00+02:00","relpermalink":"/post/2017-09-05-moving-content-hugo/","section":"post","summary":"New steps, new platform.\n","tags":["jekyll","blog","hugo","writing","medium"],"title":"Moving my content creation to a home-made Hugo site","type":"post"},{"authors":null,"categories":null,"content":"This talk was part of a second meetup introducing Golang use cases to Lille tech community. The slides (in French) can be found here.\n","date":1499292000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557161060,"objectID":"350a461f5ef7bda55bd85e73a501f413","permalink":"https://matbesancon.github.io/talk/golang_talk_lille/","publishdate":"2017-07-06T00:00:00+02:00","relpermalink":"/talk/golang_talk_lille/","section":"talk","summary":"This talk was part of a second meetup introducing Golang use cases to Lille tech community. The slides (in French) can be found here.","tags":["golang"],"title":"Golang in a multi-project, multi-platform team","type":"talk"},{"authors":null,"categories":null,"content":"Two weeks ago, the Equisense team spent a couple days together near the ocean in northern France. The goal was to get to know each other better and sit down to (re)think on the way we work, where we are heading and try to put some words on who we are and how we plan on moving forward.\nYou named it, we tried to define one of the obsessions in the startup culture: company values. There are many pitfalls to avoid while doing so and any of them can make the company look as a cliché, under-ambitious or reject some of the stakeholders. Keep in mind that these values are publicly displayed or at least talked about, which means your employees, investors and clients could all feel disconnected from them. At best, their reaction would be \u0026ldquo;whatever, I guess everybody says so\u0026rdquo; and see you as another cliché.\nAt worst, they can reject the way you define yourself and consider the advantages of working with you are not worth it. But is the second scenario really worse? The scope of such problem is a lot wider than your external communication and the \u0026ldquo;values\u0026rdquo; tab of your website.\nUsing Paul Graham\u0026rsquo;s definition, a startup is all about growth, hence moving fast. Quick decisions and executions cannot come without breaking things and building tension on the way. Trying to define values because they make you sound confident while being agreeable by everyone cannot yield any outcome. No great result comes out of willing to please everyone, and the corollary is that every successful person and organization has haters. Given this statement, the best any entity can do is to choose who is likely not to stick with them and why.\nWhy values anyway? This question is totally legit, especially in countries like France where the startup culture is still not familiar to a significant part of the population or like Germany where pragmatism is king in both what you do and how you communicate it. Traditional organizations have always had a simple deal on the recruitment side: lend me your skills and I\u0026rsquo;ll pay you decently. On the clients' side, the \u0026ldquo;values\u0026rdquo; displayed were traditionally associated with product differentiation (\u0026ldquo;at XYZ, our obsession is to bring the best product to [insert target] at unbeatable prices\u0026rdquo;). The shareholders' side did not even need big words, a couple KPIs from the last quarter would do. As Nicolas Colin phrases in several Medium posts, keeping what is being said to each of these stakeholders completely separated is not possible anymore in the digital age. That\u0026rsquo;s partly why company\u0026rsquo;s culture and values became central topics.\nI\u0026rsquo;ve seen two cases at traditional companies. The first situation is ignorance or non-existence of company values, maybe some of these will sound familiar: \u0026ldquo;Values? No this is the communication staff\u0026rsquo;s business\u0026rdquo; \u0026ldquo;We\u0026rsquo;re not here to dream, we\u0026rsquo;re paid to get the job done\u0026rdquo;\nThe second attitude is picking up \u0026ldquo;values\u0026rdquo; corresponding to trends but completely disconnected from the organization\u0026rsquo;s reality. Just visit the Corporate bullshit generator and you will know what I\u0026rsquo;m referring to: We\u0026rsquo;ve all seen extremely conservative companies call themselves \u0026ldquo;innovators\u0026rdquo; or some historical monopolists call themselves \u0026ldquo;disruptive\u0026rdquo;.\nSo what changed with startups? Simple, you can redefine the way your market works (and sometimes create it in the process) and become the central element for it. That\u0026rsquo;s an idea you can genuinely believe in, work for and something you can promise employees, shareholders and clients. Now where are your values in this? Simply where you want the market to go and the path you\u0026rsquo;re ready to take to go there.\nThere are obviously other factors at stake here, the fact that millennials need to define themselves through what they do for instance and cannot just work for a decent paycheck in the same polite colleague relation for 40+ years. More than ever, our generation needs some sense in what we do at the moment and not in a 40-year projection.\nWriting down values is about choosing a path and sticking to it I\u0026rsquo;d say this is the main highlight I got from hours of thoughts about the topic of company values. Choosing values is not about sounding cool, not about the image you want for the organization\u0026rsquo;s recruitments.\nSomething concrete? Don\u0026rsquo;t define yourself as hackers if you spend at least as much time planning as actually trying and building stuff. Don\u0026rsquo;t pretend to disrupt anything if you\u0026rsquo;re playing the old rules within a known and stable market. Don\u0026rsquo;t define yourself as transparent if you\u0026rsquo;re not obsessed with everyone knowing both how you think and operate.\nDefining yourself through the most trendy terms of the year has lead to a feeling of emptiness in the messages carried in the startup ecosystems and has even become one of its clichés or even jokes.\nHow to define your company in a non-cliché way I won\u0026rsquo;t have the pretension to set the rules on this point, simply to match some great frameworks from people smarter than me who gave this point years of thoughts (conference in French by Oussama Ammar) with the annoying points we discussed.\n  Start with the hard way: define the cool things you are not. This goes with a conclusion drawn earlier, every successful organization has haters, but don’t get the cause-effect relation wrong: your company is not going to reach its goals once it has haters. It should have haters because it defined a clear path to success which induced not satisfying every stakeholder on the way. The corollary is even a stronger conclusion: trying to please every potential target and stakeholder is the safest way to getting stuck and unable to make any decision. This is a luxury startups cannot afford by definition. Immobility can only be explainable in traditional and established businesses.\n  Define your values on the fly: just like you don’t decide as a child that you are a nice person, you don’t decide as a company that you are disrupters before living it. Discover your organization as you are working together and reaching the first painful milestones, these key steps in your development when you have to decide where priorities are being set and who is not going to remain supportive afterwards. These tough experiences and the retrospective understanding of your reaction as a team will make you more confident in what you are doing and help cut the fluff on things you are not meant to do. This is the focus everyone needs to move faster and sharper than the competition, the market and the context.\n  ","date":1475791200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505181809,"objectID":"79f7d2b1346de2e5935d516b80f443e1","permalink":"https://matbesancon.github.io/post/2016-10-7-company-values/","publishdate":"2016-10-07T00:00:00+02:00","relpermalink":"/post/2016-10-7-company-values/","section":"post","summary":"And how to avoid becoming one of the biggest clichés of startup culture\n","tags":["startup"],"title":"Company values: stop trying to dictate who you are","type":"post"},{"authors":null,"categories":null,"content":"When I came back to Equisense, I was surprised and intrigued by many things. But there was one element of the job in particular I had not planned: coming back to low level and embedded programming from higher abstractions I was used to. No OS, no libraries, no smooth write-and-test work-flow, just brutal and bare metal. I clearly needed to blow some steam off with something closer to what I usually do (or did), a data-driven and functional project using nice techs.\nWhy yet another PageRank? The time came to find a new side project and I was just finishing the lectures of Parallel Programming, which I recommend if you\u0026rsquo;re already at ease with Scala and its environment (IDEs, SBT). I wanted to apply the concepts on a project built from scratch. One day, while neglectfully scrolling through another blog post showing the basic concepts of the PageRank computation, I thought this would make a \u0026ldquo;okay\u0026rdquo; project. But wait, interesting elements here:\n The model behind the PageRank computation is a Markov Chain, with which I have been working a lot with at Siemens. Iterating until stability of the ranks is basically a linear flow, easily performed by tail call recursion which is optimized to avoid stack-overflowing the JVM by behaving like a while loop. Computing the rank of each site is independent of the other computations, parallelizing the tasks is a piece of cake  So we\u0026rsquo;re all set up for a purely functional and parallel PageRank.\nThe PageRank model We\u0026rsquo;re gonna go through the basic implementation of the algorithm. What fascinates me is the two-sided view of the algorithm: the intuitive version can be explained to a 5-year-old (or to your boss) while the maths behind it relies on the interpretation of matrix eigenvalues and on a computation of the stationary distribution of the Markov model.\nThe intuitive version Imagine you\u0026rsquo;re surfing on the web like any productive Sunday evening. On a given page, there is an equal probability to click on any link present on the page. There is also a probability that you get tired of the current series of pages and randomly go back to any page of the network.\nLet\u0026rsquo;s try to visualize the two extremes of this \u0026ldquo;random switch\u0026rdquo; usually called damping factor d. If we set d=0, the transition to any page is equally probable, since the surfer will always switch to choosing a page at random. This means that the links going out of the page they\u0026rsquo;re currently on don\u0026rsquo;t influence the probability distribution of the next page.\nOn the other end of the spectrum if the damping factor d=1, the surfer will always look for its next page in the outgoing links of her current page (this raises an issue for pages without any links). An usual value for the factor is d=0.85which keeps the probability of long sequences of related pages likely to happen, but allows for random switch.\nKey elements of the algorithm The algorithm uses the matrix of links: an entry (i,j) is 1 if there is a link on the page j to the page i and 0 otherwise (note that this notation is opposite to the common convention for Markov transition matrices, where the line is the origin state and the column the destination). The other element is a rank vector which is updated until a convergence criterion is met.\nTypes of the different structures Since we want to be able to perform some computations in parallel, most functions will manipulate Scala\u0026rsquo;s Generic data structures. Let\u0026rsquo;s start with the link matrix. It is a sparse structure: instead of representing all entries of the matrix in a vector of vectors, just non-empty elements and there corresponding column and line indexes are stored.\n// defining a dense matrix of Ints as a sequence of sequence type DenseMatrix = GenSeq[GenSeq[Int]] // SparseMatrix: tuple (line, column, value) type SparseMatrix = GenSeq[(Int,Int,Int)] However, the values of our link matrix only contains zeros and ones, so the entries present in the structure all have one as value, so we just need to keep rows and columns:\ntype LinkMat = GenSeq[(Int,Int)] The ranks are stored in a simple generic float sequence:\nR: GenSeq[Float] We also need a few utility functions. sumElements takes the matrix, the rank vector and an integer to find all links for which the outgoing page is j.\ndef sumElements(R: GenSeq[Float], A: LinkMat, j: Int): Float = { // sums all PageRanks / number of links for a column j  val totalLinks = A.filter{tup =\u0026gt; tup._2 == j} if (totalLinks.isEmpty) sys.error(\u0026#34;No link in the page \u0026#34; + j + \u0026#34; at sumElements\u0026#34;) else R(j)/totalLinks.size } Note This implementation of the function is not purely functional since an imperative system error is raised if no index i is found. A better solution here would have been to wrap the value in an Option[Float], return None if no index has been found and Some(x) in case of success.\nWe also need to find all pages pointing to a given page i. This might be a bit compact, but keep in mind that the matrix is simply a pair of page indexes. So we find all pages where the first element is i (the page the link is going to), that\u0026rsquo;s the filter part. We then take the second element of the tuple, so all indexes pointing to i, thanks to a map.\ndef findConnected(i: Int, A: LinkMat): GenSeq[Int] = A.filter(_._1==i).map(_._2).toSeq Note that the result is returned as a normal sequence (not the generic version allowing for parallel computation). It\u0026rsquo;s not a big deal since the resulting sequence is always manageable compared to the whole graph we are manipulating.\nNow, we stated that the algorithm recurses on the rank of all pages until stability, which is something we define through a converged function. We simply use a squared difference between two different versions of the rank to determine if they are acceptably close and yield a boolean.\ndef converged(r1: GenSeq[Float], r2: GenSeq[Float], eps: Float): Boolean = { val totSquare: Float = r1.zip(r2).map(p=\u0026gt;(p._1-p._2)*(p._1-p._2)).sum sqrt(totSquare/r1.size)\u0026lt;=eps } Now that everything is set, the master piece becomes a piece of cake.\n@tailrec def compRank(R: GenSeq[Float], A: LinkMat, damp: Float, eps: Float, niter: Int = 0, niterMax: Int = 10000): GenSeq[Float] = { val rankIndex: GenSeq[Int] = 0 until R.size val rightRank: GenSeq[Float] = rankIndex map{i:Int =\u0026gt; val connected = findConnected(i,A) connected.map{j:Int =\u0026gt; sumElements(R, A, j)}.sum } val newRank = rightRank map {damp*_ + (1-damp)/R.size} if(converged(newRank,R,eps)) newRank else if(niter\u0026gt;=niterMax) { println(\u0026#34;Max iteration reached\u0026#34;) newRank } else compRank(newRank,A,damp,eps,niter+1,niterMax) } We first compute the right term of the new rank formula rightRank and plug it in newRank. The two vectors can be passed to compare to determine if newRank can be returned as a final result or if further recursion is needed. A recursion counter also avoids waiting too long for a result and warns in case of maximum recursion reached by printing to the standard output. Once again, a more functional way would have been to wrap the result in a Try monad (no panic, we\u0026rsquo;re NOT going to go through monads, we\u0026rsquo;ve lost enough people with this).\nYou\u0026rsquo;ve surely noticed the @tailrec tag highlighting that this function is not going to blow the stack up.\nResult on a study case The Enron email dataset While surfing in a semi-random way to find a cool dataset for the application, I found the SNAP project from Stanford on which the Enron emails data are presented and to be downloaded. If you look at the Github repo for this project, I simply removed the header from the txt file to make the parsing tasks easier.\nResults As many phenomena dealing with concentration of resources, the distribution of ranks follows a Pareto distribution, which can be visualized on a log-log scale. I used Python with numpy and matplotlib, finding the current Scala libraries still to cumbersome for this simple task. Here is the result: A conclusion on the functional/imperative debate If some of you clone and try to run the project (you\u0026rsquo;ll just need sbt for that). Some people could argue that the runtime is too long for what it does (whatever too long means), and that an imperative solution with a mutable rank on which we loop until convergence. And I suppose they are right, but parallel imperative is objectively a pain to work with. Tell the architecture what you want, not what to do and it will compute it for you, whatever its configuration is, from your laptop to several clusters. That\u0026rsquo;s a key reason why Spark is functional for instance.\n ","date":1473717600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532551968,"objectID":"e712cb4b7772f47874f38482b57d6fb0","permalink":"https://matbesancon.github.io/post/2016-09-13-page-rank/","publishdate":"2016-09-13T00:00:00+02:00","relpermalink":"/post/2016-09-13-page-rank/","section":"post","summary":"The logic and implementation of one of the first algorithms to power the modern web\n","tags":["data-science","algorithm","functional"],"title":"Functional and parallel PageRank implementation in Scala","type":"post"},{"authors":null,"categories":null,"content":"In politics, a government\u0026rsquo;s first decisions and actions are often reviewed and assessed after the famous first 100 days. According to Wikipedia, the term was coined by F. Roosevelt himself. I wanted to throw the first thoughts on my comeback at Equisense, on culture and operations and the difference between the two stages.\nStartups are in a continuous headlong rush I\u0026rsquo;ll not wait the 100 days to write this post, because in a startup things move faster, so why wait another month? At the same time you have to remain focused for a lot longer than three months or the consequences to expect are worse than skeptical articles or plunging opinion polls. Nobody could judge actions or decisions drawn after a year in business based on one or even three months.\nAnd this adrenalined marathon does not (or should not) stop with a first product release, or worse with a nice fund-raising round. This stops with the company running out of business or the market saying \u0026ldquo;I love you, let\u0026rsquo;s stay forever until death do us apart\u0026rdquo;.\nAn early insight before the long break I had already worked with the team in June, July and August 2015 during their three-founders-and-laptops stage. The focus was on first studies of acceleration signals and feasibility of some features given technological and product choices. Those first graphs and explanations thrown on a small Tex reports were later improved and re-written by the team as it designed Motion. After these few months, I left the startup for Montréal, where I spent my last semester as a student, after which I carried out my Master project in Germany. When came the time to think about what came next, we were still in contact with Camille, Idriss and Benoit and the conversation shifted to how the project had evolved and the thousand cool things coming in the next months and could become a \u0026ldquo;real job\u0026rdquo; this time. After a couple more one-to-one, a few visits in Lille and a hackathon, I was officially back on the adventure.\nGetting back and the baby is all grown up! In the meantime, Equisense launched a successful Kickstarter, reinforcing the feeling that horse-riders value what the product can bring to their experience. The company moved from its first office in Compiègne Innovation Center to the impressive Euratechnologies center in Lille.\n[1]\nMore than this, the team also got bigger to face the challenges of this new stage. The goal is no longer to hack horses acceleration signals until something comes out of it, but to build a reliable and intuitive product from the scientific findings and technological pieces brought together.\nReally getting on the market requires a deeper bond with horse-riders and as much feedback as possible. The new team embodies these changes: a diversity of mindsets, experiences and backgrounds to handle all upcoming challenges with the same care for clients. The hacker spirit isn\u0026rsquo;t gone in this new version of the company, but it isn\u0026rsquo;t the major pillar of the culture anymore. A culture is hard to put into words, but I\u0026rsquo;d say this second face of our Janus startup is a combination of a genuine care for horses wellness and of a passion for horse-riding.\n[2]\nThe fact is that while I was admiring their external successes from my Canadian home, (the Kickstarter campaign, new partnerships, features of the product getting out of the ground one by one\u0026hellip;), the most impressive achievement was being joined by so many diverse profiles while building a working environment at the image of their horse-riders' mindset.\nThe founders already had this care and passion in their DNA, they just succeeded in transforming it into a full culture and transmitting it into an obsession within the team.\n[2]\nWhere are we in the lifetime? From a clumsy foal to the great stallion Other than the culture, the operations changed from the clumsy foal learning to stay up on its hoofs to the stallion swiftly jumping and anticipating all obstacles. [3]\nThe seed stage is about using all assets that are or can easily be at your disposal to run tests and confirm hypotheses. Unlike lots of web startups, uncertainty does not come only from the market, but also from the technological bricks: hardware is today where the web was about ten years ago.\nMoving forwards meant iterating while building knowledge on both fields of uncertainty. This meant at the same time assessing if some measured signals could detect a jump during a training session, and if the customers actually had an interest in the feature. Working for nothing can be frustrating, but ignoring something horse-riders want would have been much worse!\n[5]\nIn the new phase, uncertainty radically changed. In the first stage, we saw how it was caused by a lack of knowledge on both the technology and the market. Of course the knowledge the team has on these topics is still not complete, but is enough to make intelligent decisions and move on. However, a new source of uncertainty has replaced the two previous:\nOrganization and processes are obvious when 4 people are working together on several issues. They become fuzzy and chaotic when several teams are working at high speed without being able to check on each other all day long.\nThe key issue is the company\u0026rsquo;s speed to deliver without letting any randomness in the result. Equisense\u0026rsquo;s customers are horse-riders willing to improve their experience, care and efficiency, not hackers accepting a buggy beta with promising features as long as the product has an API in their favorite language!\nEquisense changed a lot during my absence to evolve into one of the new major phenomena in its industry. If I had to describe how it operates now, I guess I\u0026rsquo;d highlight the focus, the acceleration and the deterministic, well-defined outcome of a still random and flexible organization. (hope my data science buddies will tolerate the paradox of the last one).\nThe coming months promise to be thrilling with the shipping of the first Motion sensors, the R\u0026amp;D on improved features, new products and whatever else comes out of the blue. Even though I\u0026rsquo;m still getting used to working with horses (photos to come), I\u0026rsquo;m without a doubt excited to have rejoined these crazy riders, so stay tuned!\n Image sources: [1] Les Echos: Nord - Pas-de-Calais : A Lille naît la « Silicon Valley » du numérique [2] Equisense website [3] http://www.eco121.fr/equisense-ouvre-la-voie-du-cheval-connecte/ [4] [5] Wikimedia\n","date":1470866400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505181809,"objectID":"c02032f6b34d7f7c4cc2a8c514b44a99","permalink":"https://matbesancon.github.io/post/2016-08-11-back-to-startup/","publishdate":"2016-08-11T00:00:00+02:00","relpermalink":"/post/2016-08-11-back-to-startup/","section":"post","summary":"100 days after a come-back.\n","tags":["startup"],"title":"Back to startup life: thoughts after the first days","type":"post"},{"authors":null,"categories":null,"content":"It\u0026rsquo;s monday morning and I\u0026rsquo;m waking up with a hangover sensation, not from partying in the streets of Lille as one could think at the beginning of the week, but from the last intense 48 hours. I took part in the so-called \u0026ldquo;creathon\u0026rdquo; organized by the Switch up challenge and MakeSense. The special touch on this event was the social impact the projects were meant to have. The result could even not be a company but a non-profit organization.\nI\u0026rsquo;m going to generalize my thoughts as much as possible, but to give a concrete view of what is going on, I\u0026rsquo;m going to use the example of Quare, the project we worked on. It is a device quantifying your stress and the quality of your current working environment thanks to different sensors and individually adjusted algorithms.\nBuilding a company from the ground up: just let me finish this Creating the whole concept for a scalable, repeatable and profitable business based on an issue you want to tackle takes time, focus and creativity. The goal is not to come up with the most spectacular way to solve the problem and build your product, but to find the simplest way allowing your business to grow without limits. You\u0026rsquo;re not building the Empire State, you\u0026rsquo;re planting an acorn to grow an oak.\nStop organizing everything, mess is a bless People coming from a business and management background tend to think of activities in terms of processes, so a structured way in which things are handled and operated. When designing the concept for a startup, just don\u0026rsquo;t. The reason is, your team is going through several critical phases where any constraint in the reasoning would hinder the ability to rephrase the problem you\u0026rsquo;re focused on, or come up with a radical new way to address it. Just let the mess happen and collectively feel when it is time to move on to a next step. If a team member feels like you missed something, simply let them gather their thoughts and arguments, then try to build on them and see how they change the concept. However, not everything must be kept if you don\u0026rsquo;t want an over-generalized problem.\nFocus is key to deliver This part is a bit tricky and you won\u0026rsquo;t find any silver bullet, even less in this blog post. By focused, understand both being focus as state-of-mind and keeping your business idea focused on what matters the most to the issue you address: this is about making real choices which will never please everyone. Keeping focused and moving fast during the week-end has two effects. If you play well, you\u0026rsquo;ll deliver a lot more by the time of the final pitch, and that\u0026rsquo;s an awesome point if you have some of the following objectives:\n Convince and impress specific people in the room: potential partners, investors, accelerators Check how comfortable team members are with each other, if you align on your ambition, your definition and perception of the problem, the way you work and react under pressure  To relate things to our situation this weekend, we were an initial team of two engineers working for a middle-stage startup and two designers at ease with both product and graphical design. A highly motivated business school student joined the team a bit later in the weekend. We had both a creative and chaotic enthusiasm to explore the problems related to stress and lack of focus at work (the issue we decided to tackle) and some ability to focus and to move fast based on our diverse experiences and skills.\nWe addressed the issue of focus at work which is our direct concern while working in an open-space and dealing with creative work requiring long, uninterrupted sessions to make the best out of a day. Even though we spent a great deal of time defining the scope of the problem and primary targets, we all had this get things done attitude and were eager to start realizing something concrete from the beginning. So not only did we all have a strong link to the problem, we also had a common view on it, it allowed the team to have a sharp vision and homogeneous of work and focus.\nBut there are also several not-so-good reasons to move fast during a startup weekend:\n Validate technical choices (Should my device communicate through Wifi or Bluetooth? What information do we need to store from our clients? Any back-end related question) Precise quantitative estimates are pointless. Yup, business plans don\u0026rsquo;t have their place at a startup weekend, if they have a place at all for early stage of uncertain and radically new businesses. Try to simply get some rough ideas about the size of the problem, how much would the device cost in production.  Again, to relate this to our situation, we could make a pretty good estimate of the Bill of Materials based on the sensors we wanted to use and on our experience with Equisense (what components were needed, the type of micro-controller, etc\u0026hellip;). We could come out with different shapes for the device and test it thanks to different people giving feedback which allowed us to iterate, but that was is. We did not go any further on the economic projections, nor did we try to build the whole product in two days. Okay maybe we prototyped the product with an Arduino and the appropriate sensors. That was clearly unnecessary for the weekend, but still fun to play around with hardware and show what anyone can do with a board, two sensors and some cables.\nNonetheless, one of the team\u0026rsquo;s designers bought an Arduino kit right after the weekend, a business student decided to go further with one of his personal projects after seeing how much we had got done after two days. Even if we don\u0026rsquo;t build the next unicorn, discovering each other\u0026rsquo;s fields and building a common culture in so little time was in itself a success and a learning experience.\n","date":1468188000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505181809,"objectID":"18e5ce04e0e549ce3d11ee554ca428f1","permalink":"https://matbesancon.github.io/post/2016-07-11-hackathon/","publishdate":"2016-07-11T00:00:00+02:00","relpermalink":"/post/2016-07-11-hackathon/","section":"post","summary":"Feedback after a weekend re-discovering the early stage feelings.\n","tags":["startup"],"title":"On startup weekends and getting things done","type":"post"},{"authors":null,"categories":null,"content":"The goal of this article is to present couple challenges waiting the industrial data scientist or industrial data science teams, the deep reasons I believe are the root of this inertia, based on my experience (in both data science and engineering projects) and exchanges with engineers and data scientists. The last part introduces some suggestions to make the collaboration richer for both sides.\nWhy isn\u0026rsquo;t data science already everywhere in engineering? It is surprising that this transition hasn\u0026rsquo;t been so spontaneous. Indeed, one could think that engineers, belonging to the \u0026ldquo;STEM family\u0026rdquo; (people studying or working in fields related to Science, Technology, Engineering and Mathematics) would easily embrace the concepts and methods of data science and moreover be able to identify the potential gains, savings and improvements to carry out complex projects in a more effective manner.\nSilo thinking in STEM That\u0026rsquo;s not the case, most engineers I\u0026rsquo;ve been discussing and working with never considered these techniques as relevant to their current tasks. So why so little enthusiasm? A recurrent problem I noticed is the silo thinking of disciplines created by strong and early specializations, along with natural distaste and reduction of unknown fields.\nWe\u0026rsquo;re not Google, deal with it So when someone will first pitch machine learning to an engineer, I would often observe reactions of \u0026ldquo;it\u0026rsquo;s not relevant to my field/work/issues\u0026rdquo; because they don\u0026rsquo;t consider being in a \u0026ldquo;tech\u0026rdquo; industry. This is the same reaction type observed in companies facing digital disruption (see the excellent article of Nicolas Colin here).\nAs a personal example, as I was talking to a production manager about the impact advanced predictive analytics could have on machine reliability and availability, she advanced the \u0026ldquo;non-tech\u0026rdquo; argument, to which I answered with examples of traditional manufacturing companies already using these techniques, including General Electric for turbine monitoring (what they refer to as the Industrial Internet). His last point was \u0026ldquo;Well sure but\u0026hellip; we\u0026rsquo;re not GE\u0026rdquo;, which I understood as \u0026ldquo;I\u0026rsquo;m not able to learn from nor to work in that field totally out of my comfort zone\u0026rdquo;. Although, her discomfort with the methods involved is easily understandable since it requires key concepts in mathematics, statistics and algorithm thinking which would often be considered as theory unusable in their \u0026ldquo;real life\u0026rdquo;.\nMy subject is so complex The other reaction one would observe is linked to an interesting thinking process: People always tend to reduce the breadth of subjects they don\u0026rsquo;t know, and to emphasize (not to say oversize) the width and complexity of their own domain. I recently read a \u0026ldquo;conversation hack\u0026rdquo; to make a conversation pleasant to someone, in three steps:\n Ask them what they do for a living Ask them some more details about how they manage things Look impressed, add \u0026ldquo;Wow, that sounds very complex\u0026rdquo;  People don\u0026rsquo;t feel at ease with the introduction of quantitative, rational methods and analytics for decision-making in their daily work because this implies that a rather \u0026ldquo;simple\u0026rdquo; model can generate better decisions than them. It revives this old phobia of losing their job to a machine.\nBut still\u0026hellip; why particularly engineers? We didn\u0026rsquo;t address this question yet, and it still sounds counter-intuitive, given our first statements. From my personal experience studying and working with both junior and senior engineers, and relatively to business or social science background, there is a stronger will to \u0026ldquo;master the model\u0026rdquo; and understand most key aspects of the system they work on.\nBank managers, marketing leaders or finance analysts totally feel comfortable with the use of data base systems and business intelligence tools, even statistical analyses or predictive modeling tools they can perfectly leverage, but not often understand on the technical parts. They would just need to be able to read, use and trust the results. Engineers, on the other hand don\u0026rsquo;t feel legitimate when using tools they don\u0026rsquo;t master they feel the need of understanding and controlling what\u0026rsquo;s going on under the hood.\nThere is a common vision of the engineers in several cultures, they are the handy people, able to answer most of your questions, master all techniques from nuclear power generation to bio-technologies. They are all supposed to be Tony Stark (or Elon Musk in a more realistic way). So their secret fear is not about being afraid of getting their job \u0026ldquo;automated\u0026rdquo; but more about a situation where they cannot handle their system anymore because a part of the decisions taken is not under their control anymore.\nWhat to do about it? What data science can bring to their organization Proving the utility of data science is the easy part, the process is actually almost identical to bringing data science to any other industry. The potential users should be shown what pain points this new field would address in their business, how similar businesses have already applied machine learning to their issues, and how the processes should be adapted to these projects.\nHow it actually works Empowering the engineers through explanations of the key concepts might be seemingly pointless and time-consuming, but helps them accepting the techniques involved as a part of the \u0026ldquo;internal model\u0026rdquo; secretly hidden in each engineer\u0026rsquo;s mind and used to think about their system and make decisions upon it.\nMost engineers are usually used to (at least) basic algorithm structures. So using it to make them understand the thinking pattern behind machine learning may help them to understand the mechanisms and feel at ease with reapplying it. Once you\u0026rsquo;ve covered the fundamentals, a modeling skill should be developed. Indeed, being able to model a problem as a data science project will give a pretty straightforward beginning (especially on variable selections or feature engineering).\nBasic linear regression (and in general other curve fitting methods) have already been seen for experimental purposes in most engineering fields. If one has only time to explain key concepts, I would give the following order:\n Classification principles, example of classification trees. Regression techniques (if not already known). Simple and multivariate linear regression, polynomial regression. Unsupervised learning, example of k-means clustering. Overfitting, cross-validation concept and techniques. Ensemble learning, example of random forests.  With clear but complete explanations of regression, classification and unsupervised learning, along with a previous knowledge of regression techniques, most engineers will be able to identify opportunities to get deeper insights into the phenomena they investigate or to build robust predictions through machine learning, which is the basic goal to break the barriers we discussed. The 4th and 5th topics are a bonus allowing them to understand what techniques data scientists would use, they would not need them for opportunity identification but to extend their \u0026ldquo;internal model\u0026rdquo;, which can only be beneficial.\nKey examples These examples are taken from diverse projects, challenges and data sets including some personal ones. Each case study is addressed to specific targets.\n Process, Energy and Chemical Engineers  I studied once the Combined Cycle Power Plant dataset which can be found on the UCI dataset repository here. Using machine learning allowed the research group not to work on the basis of restrictive hypotheses on the thermodynamic behavior of the gas or steam, nor on the heat exchange and fluid mechanics phenomena involved (e.g. pressure drop in the pipes due to phase change). The predictions based on data are a totally new way to combine formal model-based approaches (including process optimization) and operational realities (the good old \u0026ldquo;gut feeling\u0026rdquo; experienced staff will tell you about).\n Biomedical Engineers  This also includes all high-level medical professions. Well-known applications were found in several fields, including pattern recognition from medical images and data, disease risk estimations from patient background information.\nPredictive modeling systems will be a decisive disruption in physicist work, they replace the human decision-making process, based on few variables and on a biased and relative experience with the risk-based optimal decision backed by millions of data points.\n Industrial, Manufacturing and Quality Engineers  Those case studies are inspired by my personal experience and the solutions offered by several software development companies.\nThe first one is the application of classification trees to replace rules defining the quality of a product (first, second class or discarded for instance). Using proper data mining tools allows the production manager to define the relative \u0026ldquo;cost\u0026rdquo; of false positives (good products declared as not salable, which induces all the manufacturing costs without the revenue) and false negatives (non-conform products sent to be sold, which induces a risk of complaint, on operation product default, image issues or recall campaigns).\nThe second example is combining time-series analysis and multi-variable regression techniques to give risk estimations on the process stability and trends. I observed several software solution providers to whom the transition from statistics to predictive modeling was a simple and obvious evolution.\nBringing machine learning to engineers is a challenge and must be considered as a promising step for both data science and engineering. Formal modeling approaches and experimental considerations will eventually be able to be conciliated. Data science will gain a significant support and become an accelerator for the development of new techniques.\nYou\u0026rsquo;re an engineer, a data scientist? Have you ever experienced collaborating with engineers on data science applications? Did you encounter some difficulties specific to working with engineers? Please get in touch for further discussion on these topics.\nNow that we have discussed what data science could bring to engineers, a second article may come to explain how to build a predictive model from scratch in an industrial context.\nSpecial thanks to Robert, Benoit and Florian for their feedback on the article.\n","date":1463781600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557403969,"objectID":"3ad58ffddbed1f414f5b67f43a86ec22","permalink":"https://matbesancon.github.io/post/2016-05-21-bringing-data-science-engineers/","publishdate":"2016-05-21T00:00:00+02:00","relpermalink":"/post/2016-05-21-bringing-data-science-engineers/","section":"post","summary":"Thoughts as an engineer-by-training evolving towards data skills in a\nmanufacturing context.\n","tags":["data-science","engineering"],"title":"Bringing data science to engineers","type":"post"},{"authors":null,"categories":null,"content":"[1]\nPart III: Model development\n To follow the following article without any trouble, I would recommend to start with the beginning.\nHow does predictive modeling work Keep the terminology in mind This is important to understand the principles and sub-disciplines of machine learning. We are trying to predict a specific output, our information of interest, which is the category of bank note we observe (genuine or forged). This task is therefore labeled as supervised learning, as opposed to unsupervised learning which consists of finding patterns or groups from data without a priori identification of those groups.\nSupervised learning can further be labeled as classification or regression, depending on the nature of the outcome, respectively categorical or numerical. It is essential to know because the two disciplines don\u0026rsquo;t involve the same models. Some models work in both cases but their expected behavior and performance would be different. In our case, the outcome is categorical with two levels.\nHow does classification work? Based on a subset of the data, we train a model, so we tune it to minimize its error on these data. To make a parallel with Object-Oriented Programming, the model is an instance of the class which defines how it works. The attributes would be its parameters and it would always have two methods (functions usable only from the object):\n train the model from a set of observations (composed of predictive variables and of the outcome) predict the outcome given some new observations Another optional method would be adapt which takes new training data and adjusts/corrects the parameters. A brute-force way to perform this is to call the train method on both the old and new data, but for some models a more efficient technique exists.  Independent evaluation A last significant element: we mentioned using only a subset of the data to train the model. The reason is that the performance of the model has to be evaluated, but if we compute the error on the training data, the result will be biased because the model was precisely trained to minimize the error on this training set. So the evaluation has to be done on a separated subset of the data, this is called cross validation.\nOur model: logistic regression This model was chosen mostly because it is visually and intuitively easy to understand and simple to implement from scratch. Plus, it covers a central topic in data science, optimization. The underlying reasoning is the following: The logit function of the probability of a level of the classes is linearly dependent on the predictors. This can be written as:\nnp.log(p/(1-p)) = beta0 + beta[0] * x[0] + beta[1] * x[1] + ... Why do we need the logit function here? Well technically, a linear regression could be fitted with the class as output (encoded as 0/1) and the features as predictive variables. However, for some values of the predictors, the model would yield outputs below 0 or above 1. The logistic function equation yields an output between 0 and 1 and is therefore well suited to model a probability.\nYou can noticed a decision boundary, which is the limit between the region where the model yields a prediction \u0026ldquo;0\u0026rdquo; and a prediction \u0026ldquo;1\u0026rdquo;. The output of the model is a probability of the class \u0026ldquo;1\u0026rdquo;, the forged bank notes, so the decision boundary can be put at p=0.5, which would be our \u0026ldquo;best guess\u0026rdquo; for the transition between the two regions.\nRequired parameters As you noticed in the previous explanation, the model takes a vector of parameters which correspond to the weights of the different variables. The intercept \\beta_0 places the location of the point at which p=0.5, it shifts the curve to the right or the left. The coefficients of the variables correspond to the sharpness of the transition.\nLearning process Parameters identification issue Unlike linear regression, the learning process for logistic regression is not a straight-forward computation of the parameters through simple linear algebra operations. The criterion to optimize is the likelihood, or equivalently, the log-likelihood of the parameters:\nL(beta|(X,z)) = f(X,z) Parameters update The best parameters in the sense of the log-likelihood are therefore found where this function reaches its maximum. For the logistic regression problem, there is only one critical point, which is also the only maximum of the log-likelihood. So the overall process is to start from a random set of parameters and to update it in the direction that increases the log-likelihood the most. This precise direction is given by the gradient of the log-likelihood. The updated weights at each iteration can be written as:\nbeta = beta + gamma* gradient_log_likelihood(beta) Several criteria can be used to determine if a given set of parameters is an acceptable solution. A solution will be considered acceptable when the difference between two iterations is low enough.\nOptimal learning rate The coefficient gamma is called the learning rate. Higher values lead to quicker variations of the parameters, but also to stability and convergence issues. Too small values on the other increase the number of steps required to reach an acceptable maximum. The best solution is often a varying learning rate, adapting the rate of variations. The rate at step n is chosen as follows:\ngamma_n = alpha*min(c0,3/(np.sqrt(n)+1)) Which means that the learning rate is constant for all first steps until the following condition is reached:\nn \u0026gt; (3-c0)/c0 After this iteration, the learning rate slowly decreases because we assume the parameters are getting closer to the right value, which we don\u0026rsquo;t want to overshoot.\nDecision boundaries and 2D-representation A decision region is the subset of the features space within which the decision taken by the model is identical. A decision boundary is the subset of the space where the decision \u0026ldquo;switches\u0026rdquo;. For most algorithms, the decision taken on the boundary is arbitrary. The possible boundary shapes are a key characteristic of machine learning algorithms.\nIn our case, logistic regression models the logit of the probability, which is strictly monotonous with the probability as linearly proportional to the predictors. It can be deduced that the decision boundary will be a straight line separating the two classes. This can be visualized using two features of the data, \u0026ldquo;vari\u0026rdquo; and \u0026ldquo;k_resid\u0026rdquo;:\nw = learn_weights(data1.iloc[:,(0,1,3)]) # building the mesh xmesh, ymesh = np.meshgrid(np.arange(data1[\u0026#34;vari\u0026#34;].min()-.5,data1[\u0026#34;vari\u0026#34;].max()+.5,.01),\\ np.arange(data1[\u0026#34;k_resid\u0026#34;].min()-.5,data1[\u0026#34;k_resid\u0026#34;].max()+.5,.01)) pmap = pd.DataFrame(np.c_[np.ones((len(xmesh.ravel()),)),xmesh.ravel(),ymesh.ravel()]) p = np.array([]) for line in pmap.values: p = np.append(p,(prob_log(line,w))) p = p.reshape(xmesh.shape) plt.contourf(xmesh, ymesh, np.power(p,8), cmap= \u0026#39;RdBu\u0026#39;,alpha=.5) plt.plot(data1[data1[\u0026#34;class\u0026#34;]==1][\u0026#34;vari\u0026#34;],data1[data1[\u0026#34;class\u0026#34;]==1][\u0026#34;k_resid\u0026#34;],\u0026#39;+\u0026#39;,label=\u0026#39;Class 0\u0026#39;) plt.plot(data1[data1[\u0026#34;class\u0026#34;]==0][\u0026#34;vari\u0026#34;],data1[data1[\u0026#34;class\u0026#34;]==0][\u0026#34;k_resid\u0026#34;],\u0026#39;r+\u0026#39;,label=\u0026#39;Class 1\u0026#39;) plt.legend(loc=\u0026#34;upper right\u0026#34;) plt.title(\u0026#39;2-dimension logistic regression result\u0026#39;) plt.xlabel(\u0026#39;vari\u0026#39;) plt.ylabel(\u0026#39;k_resid\u0026#39;) plt.grid() plt.show() Implementation Elementary functions Modularizing the code increases the readability, we define the implementations of two mathematical functions: def prob_log(x,w): \u0026#34;\u0026#34;\u0026#34; probability of an observation belonging to the class \u0026#34;one\u0026#34; given the predictors x and weights w \u0026#34;\u0026#34;\u0026#34; return np.exp(np.dot(x,w))/(np.exp(np.dot(x,w))+1) def grad_log_like(X, y, w): \u0026#34;\u0026#34;\u0026#34; computes the gradient of the log-likelihood from predictors X, output y and weights w \u0026#34;\u0026#34;\u0026#34; return np.dot(X.T,y- np.apply_along_axis(lambda x: prob_log(x,w),1,X)).reshape((len(w),))\nLearning algorithm A function computes the optimal weights from iterations to find the maximal log-likelihood of the parameters, using the two previous functions.\ndef learn_weights(df): \u0026#34;\u0026#34;\u0026#34; computes and updates the weights until convergence given the features and outcome in a data frame \u0026#34;\u0026#34;\u0026#34; X = np.c_[np.ones(len(df)),np.array(df.iloc[:,:df.shape[1]-1])] y = np.array(df[\u0026#34;class\u0026#34;]) niter = 0 error = .0001 w = np.zeros((df.shape[1],)) w0 = w+5 alpha = .3 while sum(abs(w0-w))\u0026gt;error and niter \u0026lt; 10000: niter+=1 w0 = w w = w + alpha*min(.1,(3/(niter**.5+1))) * (grad_log_like(X,y,w)) if niter==10000: print(\u0026#34;Maximum iterations reached\u0026#34;) return w Prediction Once the weights have been learnt, new probabilities can be predicted from explanatory variables.\ndef predict_outcome(df,w): \u0026#34;\u0026#34;\u0026#34; takes in a test data set and computed weights returns a vector of predicted output, the confusion matrix and the number of misclassifications \u0026#34;\u0026#34;\u0026#34; confusion_matrix = np.zeros((2,2)) p = [] for line in df.values: x = np.append(1,line[0:3]) p.append(prob_log(x,w)) if (prob_log(x,w)\u0026gt;.5) and line[3]: confusion_matrix[1,1]+=1 elif (prob_log(x,w)\u0026lt;.5) and line[3]: confusion_matrix[1,0]+=1 elif (prob_log(x,w)\u0026lt;.5) and not line[3]: confusion_matrix[0,0]+=1 else: confusion_matrix[0,1]+=1 return p, confusion_matrix, len(df)-sum(np.diag(confusion_matrix)) Cross-validated evaluation Learning weights on a training subset and getting the error on an other subset will allow us to estimate the real error rate of our prediction. 100 cross validations are performed and for each of them, we add the error to a list.\nerror = [] weights = [] for test in range(100): trainIndex = np.random.rand(len(data0)) \u0026lt; 0.85 data_train = data1[trainIndex] data_test = data1[~trainIndex] weights.append(learn_weights(data_train)) error.append(predict_outcome(data_test,weights[-1])[2]) The following results were obtained: The model produces on average 2.66 mis-classifications for 100 evaluated banknotes. Note that on each test, 85% of the observations went into the training set, which is arbitrary. However, too few training points would yield inaccurate models and higher error rates.\nImprovement perspectives and conclusion On this data set, we managed to build independent and reliable features and model the probability of belonging to the forged banknotes class thanks to a logistic regression model. This appeared to be quite successful from the error estimation on the test set. However, few further progresses could be made.\nTesting other models We only implemented the logistic regression from scratch, given that several models would have increased the length of this article. But some other algorithms would have been interesting, such as:\n K nearest neighbors Support Vector Machine Model-based predictions such as naive Bayes or Quadratic Discriminant Analysis Classification Tree  Fact of interest: the two first algorithms also build linear decision boundaries, but based on other criteria.\nAdjusting the costs We assumed that misclassifying a true banknote was just as bad as doing so for a forged one. This is why using a limit at p=0.5 was the optimal choice. But suppose that taking a forged banknote for a genuine one costs twice more than the opposite error. Then the limit probability will be set at p = 0.25 to minimize the overall cost. More generally, a cost matrix can be built to minimize the sum of the element-wise product of the cost matrix with the confusion matrix. Here is an interesting Stack Overflow topic topic on the matter.\nOnline classification The analysis carried on in this article is still far from the objective of some data projects, which would be to build a reusable on-line classifier. In our case, this could be used by bank to instantaneously verify bank notes received. This raises some new issues like the update of different parameters and the detection of new patterns.\nSpecial thanks to Rémi for reading the first awful drafts and giving me some valuable feedback.\n ","date":1452639600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505181809,"objectID":"3606db920cd652843023a1d68df3e5ec","permalink":"https://matbesancon.github.io/post/2016-01-13-fraud-detection3/","publishdate":"2016-01-13T00:00:00+01:00","relpermalink":"/post/2016-01-13-fraud-detection3/","section":"post","summary":"Learning by doing: predicting the outcome.\n","tags":["data-science","python","classification"],"title":"A Pythonic data science project: Part III","type":"post"},{"authors":null,"categories":null,"content":"[1]\nPart II: Feature engineering\n What is feature engineering? It could be describe as the transformation of raw data to produce a model input which will have better performance. The features are the new variables created in the process. It is often described as based on domain knowledge and more of an art than of a science. Therefore, it requires a great attention and a more \u0026ldquo;manual\u0026rdquo; process than the rest of data science projects.\nFeature engineering tends to be heavier when raw data are far from the expected input format of our learning models (images or text for instance). It can be noticed that some feature engineering was already performed on our data, since banknotes were registered as images taken from a digital camera, and we only received 5 features for each image.\nCorrelated variables Simple linear and polynomial regression We noticed some strong dependencies between variables thanks to the scatter plot. Those can deter the performance and robustness of several machine learning models. Skewness and kurtosis seem to be somehow related. A regression line can be fitted with the skewness as explanatory variable:\na, b = stats.linregress(data0[\u0026#34;skew\u0026#34;],data0[\u0026#34;kurtosis\u0026#34;])[:2] plt.plot(data0[\u0026#34;skew\u0026#34;],data0[\u0026#34;kurtosis\u0026#34;],\u0026#39;g+\u0026#39;) plt.plot(np.arange(-2.5,2.5,0.05) ,b+a*np.arange(-2.5,2.5,0.05),\u0026#39;r\u0026#39;) plt.title(\u0026#39;Simple linear regression\u0026#39;) plt.xlabel(\u0026#39;Skewness\u0026#39;) plt.ylabel(\u0026#39;Kurtosis\u0026#39;) plt.show() The following result highlights a lack in the model. The slope and intercept seem to be biased by a dense cluster of points with the skewness between 1 and 2. The points with a low skewness are under-represented in the model and do not follow the trend of the regression line. A robust regression technique could correct this bias, but a polynomial regression is the most straight-forward method to capture a higher part of the variance here. The second-degree polynomial model can be written as:\ny_hat = a*np.square(x) + b*x + c and its coefficients can be determined through the minimization of least-square error in numpy:\na, b, c = np.polyfit(data0[\u0026#34;skew\u0026#34;],data0[\u0026#34;kurtosis\u0026#34;],deg=2) plt.plot(data0[\u0026#34;skew\u0026#34;],data0[\u0026#34;kurtosis\u0026#34;],\u0026#39;+\u0026#39;) plt.plot(np.arange(-15,15,.5),a*np.arange(-15,15,.5) * np.arange(-15,15,.5)+b*np.arange(-15,15,.5)+c,\u0026#39;r\u0026#39;) plt.title(\u0026#39;2nd degree polynomial regression\u0026#39;) plt.xlabel(\u0026#39;Skewness\u0026#39;) plt.ylabel(\u0026#39;Kurtosis\u0026#39;) A polynomial regression yields a much better output with balanced residuals. The p-value for all coefficients is below the 1% confidence criterion. One strong drawback can however be noticed: the polynomial model predicts an increase in the kurtosis for skewness superior to 2, but there is no evidence for this statement in our data, so the model could lead to stronger errors.\nThe regression does not capture all the variance (and does not explain all underlying phenomena) of the Kurtosis, so a transformed variable has to be kept, which should be independent from the skewness. The most obvious value is the residual of the polynomial regression we performed.\nWe can can represent this residual versus the explanatory variable to be assured that:\n The residuals are centered around 0 The variance of the residuals is approximately constant with the skewness There are still patterns in the Kurtosis: the residuals are not just noise  p0 = plt.scatter(d0[\u0026#39;skew\u0026#39;],c+b*d0[\u0026#34;skew\u0026#34;] +a*d0[\u0026#34;skew\u0026#34;]* d0[\u0026#34;skew\u0026#34;]-d0[\u0026#34;kurtosis\u0026#34;],c=\u0026#39;b\u0026#39;,marker=\u0026#39;+\u0026#39;,label=\u0026#34;0\u0026#34;) p0 = plt.scatter(d1[\u0026#39;skew\u0026#39;],c+b*d1[\u0026#34;skew\u0026#34;] +a*d1[\u0026#34;skew\u0026#34;]* d1[\u0026#34;skew\u0026#34;]-d1[\u0026#34;kurtosis\u0026#34;],c=\u0026#39;r\u0026#39;,marker=\u0026#39;+\u0026#39;,label=\u0026#34;1\u0026#34;) plt.title(\u0026#39;Explanatory variable vs Regression residuals\u0026#39;) plt.xlabel(\u0026#39;Skewness\u0026#39;) plt.ylabel(\u0026#39;Residuals\u0026#39;) plt.legend([\u0026#34;0\u0026#34;,\u0026#34;1\u0026#34;]) plt.show() The data is now much more uncorrelated, so the feature of interest is the residual of the regression which will replace the kurtosis in the data.\nClass-dependent regression We can try and repeat the same process for the entropy and skewness, which also seem to be related to each other. p0 = plt.scatter(d0[\u0026#39;skew\u0026#39;],c+b*d0[\u0026#34;skew\u0026#34;] +a*d0[\u0026#34;skew\u0026#34;]* d0[\u0026#34;skew\u0026#34;]-d0[\u0026#34;kurtosis\u0026#34;],c=\u0026#39;b\u0026#39;,marker=\u0026#39;+\u0026#39;,label=\u0026#34;0\u0026#34;) p0 = plt.scatter(d1[\u0026#39;skew\u0026#39;],c+b*d1[\u0026#34;skew\u0026#34;] +a*d1[\u0026#34;skew\u0026#34;]* d1[\u0026#34;skew\u0026#34;]-d1[\u0026#34;kurtosis\u0026#34;],c=\u0026#39;r\u0026#39;,marker=\u0026#39;+\u0026#39;,label=\u0026#34;1\u0026#34;) plt.title(\u0026#39;Explanatory variable vs Regression residuals\u0026#39;) plt.xlabel(\u0026#39;Skewness\u0026#39;) plt.ylabel(\u0026#39;Residuals\u0026#39;) plt.legend([\u0026#34;0\u0026#34;,\u0026#34;1\u0026#34;]) plt.show() plt.plot(d0[\u0026#34;skew\u0026#34;],d0[\u0026#34;entropy\u0026#34;],\u0026#39;+\u0026#39;,label=\u0026#34;Class 0\u0026#34;) plt.plot(d1[\u0026#34;skew\u0026#34;],d1[\u0026#34;entropy\u0026#34;],\u0026#39;r+\u0026#39;,label=\u0026#34;Class 1\u0026#34;) plt.xlabel(\u0026#34;Skewness\u0026#34;) plt.ylabel(\u0026#34;Entropy\u0026#34;) plt.grid() plt.legend() plt.show()\nWe can try can fit a 2nd-degree polynomial function:\nft = np.polyfit(data0[\u0026#34;skew\u0026#34;],data0[\u0026#34;entropy\u0026#34;],deg=2) plt.plot(d0[\u0026#34;skew\u0026#34;],d0[\u0026#34;entropy\u0026#34;],\u0026#39;+\u0026#39;,label=\u0026#34;Class 0\u0026#34;) plt.plot(d1[\u0026#34;skew\u0026#34;],d1[\u0026#34;entropy\u0026#34;],\u0026#39;r+\u0026#39;,label=\u0026#34;Class 1\u0026#34;) plt.plot(np.arange(-15,14.5,.5), ft[0]*np.arange(-15,14.5,.5)*np.arange(-15,14.5,.5)+ft[1]* np.arange(-15,14.5,.5)+ft[2],\u0026#39;-\u0026#39;,linewidth=2 , label=\u0026#34;Fitted polynom\u0026#34;) plt.xlabel(\u0026#34;Skewness\u0026#34;) plt.ylabel(\u0026#34;Entropy\u0026#34;) plt.grid() plt.legend(loc=\u0026#34;bottom center\u0026#34;) plt.show() However, it seems that the model does not fit well our data and that the points are not equally distributed on both side of the curve. There is another pattern, which is class-dependent, so two polynomial curves should be fitted, one for each class:\nf0 = np.polyfit(d0[\u0026#34;skew\u0026#34;],d0[\u0026#34;entropy\u0026#34;],deg=2) x = np.arange(-15,14,.5) f1 = np.polyfit(d1[\u0026#34;skew\u0026#34;],d1[\u0026#34;entropy\u0026#34;],deg=2) plt.plot(x,f0[0]* x*x+f0[1]* x+f0[2],\u0026#39;-\u0026#39;,label=\u0026#34;Fitted 0\u0026#34;) plt.plot(d0[\u0026#34;skew\u0026#34;],d0[\u0026#34;entropy\u0026#34;],\u0026#39;+\u0026#39;,alpha=.7,label=\u0026#34;Class 0\u0026#34;) plt.plot(x,f1[0] * x*x+f1[1]* x+f1[2],\u0026#39;-\u0026#39;,label=\u0026#34;Fitted 1\u0026#34;) plt.plot(d1[\u0026#34;skew\u0026#34;],d1[\u0026#34;entropy\u0026#34;],\u0026#39;m+\u0026#39;,alpha=.7,label=\u0026#34;Class 1\u0026#34;) plt.title(\u0026#34;Class dependent fit\u0026#34;) plt.xlabel(\u0026#34;Skewness\u0026#34;) plt.ylabel(\u0026#34;Entropy\u0026#34;) plt.grid() plt.legend(loc=\u0026#39;bottom center\u0026#39;) plt.savefig(\u0026#34;class_depend.png\u0026#34;) plt.show() The model seems to capture more of the variance in our data, which we can confirm by plotting the residuals of the class-dependent regression.\nplt.plot(d0[\u0026#34;skew\u0026#34;],f0[0]* d0[\u0026#34;skew\u0026#34;]* d0[\u0026#34;skew\u0026#34;]+f0[1]* d0[\u0026#34;skew\u0026#34;]+ f0[2]-d0[\u0026#34;entropy\u0026#34;],\u0026#39;b+\u0026#39;,label=\u0026#34;Class 0\u0026#34;) plt.plot(d1[\u0026#34;skew\u0026#34;],f1[0]* d1[\u0026#34;skew\u0026#34;]* d1[\u0026#34;skew\u0026#34;]+f1[1]* d1[\u0026#34;skew\u0026#34;]+ f1[2]-d1[\u0026#34;entropy\u0026#34;],\u0026#39;r+\u0026#39;,label=\u0026#34;Class 1\u0026#34;) plt.legend() plt.grid() plt.xlabel(\u0026#34;Skewness\u0026#34;) plt.ylabel(\u0026#34;Residuals\u0026#34;) plt.savefig(\u0026#34;res_class_dep.png\u0026#34;) plt.show() We have a proper working model, with just one problem: we used the class to predict the entropy whereas our classification objective is to proceed the other way around. Since we noticed that each class follows a different curve, a difference between the distance to the first model and the distance to the second model, which will be noted \u0026ldquo;d\u0026rdquo;, can be computed as:\nd = np.abs(y - x.apply(f0)) - np.abs(y-x.apply(f1)) A positive \u0026ldquo;d\u0026rdquo; value indicates that the entropy of the observation is closer to the model fitted on the class 1, this seems to be a rather relevant indicator to use to build our models. However, this variable seems correlated to the skewness. The latter could have become unnecessary for our prediction, so we choose to eliminate it from the features and take the risk of an information loss.\nd = abs(data0[\u0026#34;entropy\u0026#34;]-f0[0]* data0[\u0026#34;skew\u0026#34;]* data0[\u0026#34;skew\u0026#34;]-f0[1]* data0[\u0026#34;skew\u0026#34;]-f0[2])-\\ abs(data0[\u0026#34;entropy\u0026#34;]-f1[0]* data0[\u0026#34;skew\u0026#34;]* data0[\u0026#34;skew\u0026#34;]-f1[1]* data0[\u0026#34;skew\u0026#34;]-f1[2]) d0[\u0026#34;d\u0026#34;] = d[data0[\u0026#34;class\u0026#34;]==0] d1[\u0026#34;d\u0026#34;] = d[data0[\u0026#34;class\u0026#34;]==1] plt.grid() plt.plot(d0[\u0026#34;skew\u0026#34;],d0[\u0026#34;d\u0026#34;],\u0026#39;b+\u0026#39;,label=\u0026#34;Class 0\u0026#34;) plt.plot(d1[\u0026#34;skew\u0026#34;],d1[\u0026#34;d\u0026#34;],\u0026#39;r+\u0026#39;,label=\u0026#34;Class 1\u0026#34;) plt.legend() plt.title(\u0026#34;d vs skewness for each class\u0026#34;) plt.xlabel(\u0026#34;Skewness\u0026#34;) plt.ylabel(\u0026#34;d\u0026#34;) plt.show() Variable scaling Common scaling techniques Very different spreads could be noticed among variables during the exploratory part. This can lead to a bias in the distance between two points. A possible solution to this is scaling or standardization.\n  Variance scaling of a variable is the division of each value by the variable standard deviation. The output is a variable with variance 1.\n  Min-Max standardization of a variable is the division of each value by the difference between the maximum and minimum values. The outcome values are all contained in the interval [0,1].\n  x_stand = x/(x.max()-x.min()) Other standardization operations exist, but those are the most common because of the properties highlighted.\nAdvantages and risks Scaling variables may avoid the distance between data points to be over-influenced by high-variance variables, because the ability to classify the data points from a variable is usually not proportional to the variable variance.\nFurthermore, all people with notions in physics and calculus would find it awkward to compute a distance from heterogeneous variables (which would have different units and meaning).\nHowever, scaling might increase the weight of variables carrying mostly or only noise, to which the model would fit, increasing the error on new data.\nFor this case, the second risk seems very low: all variables seem to carry information, which we could observe because of the low number of variables.\nFeature engineering pipeline a, b, c = np.polyfit(data0[\u0026#34;skew\u0026#34;],data0[\u0026#34;kurtosis\u0026#34;],deg=2) data1 = data0.copy() # copying the data data1.columns = [\u0026#39;vari\u0026#39;, \u0026#39;skew\u0026#39;, \u0026#39;k_resid\u0026#39;, \u0026#39;entropy\u0026#39;, \u0026#39;class\u0026#39;] data1[\u0026#34;k_resid\u0026#34;] = data0[\u0026#34;kurtosis\u0026#34;] - np.square(a*(data0[\u0026#34;skew\u0026#34;]) + b*data0[\u0026#34;skew\u0026#34;] + c) data1.columns = [\u0026#39;vari\u0026#39;, \u0026#39;skew\u0026#39;, \u0026#39;k_resid\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;class\u0026#39;] # computing the feature from the entropy regression f0 = np.polyfit(d0[\u0026#34;skew\u0026#34;],d0[\u0026#34;entropy\u0026#34;],deg=2) f1 = np.polyfit(d1[\u0026#34;skew\u0026#34;],d1[\u0026#34;entropy\u0026#34;],deg=2) data1[\u0026#34;d\u0026#34;] = abs(data0[\u0026#34;entropy\u0026#34;]-f0[0]* data0[\u0026#34;skew\u0026#34;]* data0[\u0026#34;skew\u0026#34;]-f0[1]* data0[\u0026#34;skew\u0026#34;]-f0[2])-\\ abs(data0[\u0026#34;entropy\u0026#34;]-f1[0]* data0[\u0026#34;skew\u0026#34;]* data0[\u0026#34;skew\u0026#34;]-f1[1]* data0[\u0026#34;skew\u0026#34;]-f1[2]) data1 = data1.drop(\u0026#34;skew\u0026#34;,1) # removing skew data1.iloc[:,:4] = data1.iloc[:,:4]/np.sqrt(np.var(data1.iloc[:,:4])) # data normalization data1 can now be used in the next step which will consist in the implementation of a basic machine learning algorithm. This is the key part in an analysis-oriented data science project, and I hope to see you there.\n ","date":1452553200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505181809,"objectID":"f5eee2f82ae9dc6d372cabbc1bff550c","permalink":"https://matbesancon.github.io/post/2016-01-12-fraud-detection2/","publishdate":"2016-01-12T00:00:00+01:00","relpermalink":"/post/2016-01-12-fraud-detection2/","section":"post","summary":"Learning by doing: the feature engineering step.\n","tags":["data-science","python","classification"],"title":"A Pythonic data science project: Part II","type":"post"},{"authors":null,"categories":null,"content":"A complete predictive modeling project in Python Part I: Preprocessing and exploratory analysis\nOne of the amazing things with data science is the ability to tackle complex problems involving hidden parallel phenomena interacting with each other, just from the data they produce.\nAs an example, we will use data extracted from images of forged and genuine banknotes. The distinction between the two categories would be thought to require a deep domain expertise, which limits the ability to check more than a few banknotes at a time. An automated and trustable test would be of interest for many businesses, governments and organizations.\nStarting from the data provided by H. Dörsken and Volker Lohweg, from the University of Applied Science of Ostwestfalen-Lippe, Germany on the UCI Machine Learning Repository, we will follow key steps of a data science project to build a performant, yet scalable classifier.\nThe dataset was built by applying a wavelet transform on images of banknotes to extract 4 features:\n  Variance, skewness, kurtosis of the wavelet transform (respectively second, third and fourth moment of the distribution).\n  Entropy of the image, which can be interpreted as the amount of information or randomness (which is represented by how different adjacent pixels are).\n  You can find further information on Wavelet on Wikipedia or ask Quora. An explanation of entropy as meant in the image processing context can be found here.\nTo get a better understanding of the way the algorithms works, the full model will be built from scratch or almost (not using a machine learning library like scikit-learn on Python or caret on R).\nBasic statistic notions (variance, linear regression) and some basic python knowledge is recommended to follow through the three articles.\nProgramming choices and libraries Language and environment Python, which is a great compromise between practicality (with handy data format and manipulation) and scalability (much easier to implement for large scale, automated computation than R, Octave or Matlab). More precisely, Python 3.5.1 with the Anaconda distribution 2.4.0, I personally use the Spyder environment but feel free to keep your favorite tools.\nLibraries  Collections (built-in) for occurrence counting numpy 1.10.1, providing key data format, mathematical manipulation techniques. scipy 0.16.0, imported here for the distance matrix computation and the stat submodule for Quantile-Quantile plots. pandas 0.17.1 for advanced data format, high-level manipulation and visualization pyplot from matplotlib 1.5.0 for basic visualization ggplot 0.6.8, which I think is a much improved way to visualize data urllib3 to parse the data directly from the repository (no manual download)  So our first lines of code (once you placed your data in the proper repository) should look like this:\nimport numpy as np import pandas as pd import ggplot from matplotlib import pyplot as plt import scipy.stats as stats import scipy.spatial.distance from collections import Counter import urllib3 Source files The source files will be available on the corresponding Github repository. These include:\n preprocess.py to load the data and libraries exploratory.py for preliminary visualization feature_eng.py where the data will be transformed to boost the model performance model_GLM.py where we define key functions and build our model model.py where we will visualize characteristics of the model  Dataset overview and exploratory analysis Understanding intuitive phenomena in the data and test its underlying structure are the objectives for this first (usually long) phase of a data science project, especially if you were not involved in the data collection process.\nData parsing Instead of manually downloading the data and placing it in our project repository, we will download using the urllib3 library.\nurl = \u0026#34;https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\u0026#34; http = urllib3.PoolManager() r = http.request(\u0026#39;GET\u0026#39;,url) with open(\u0026#34;data_banknote_authentication.txt\u0026#34;,\u0026#39;wb\u0026#39;) as f: f.write(r.data) r.release_conn() data0 = pd.read_csv(\u0026#34;data_banknote_authentication.txt\u0026#34;, names=[\u0026#34;vari\u0026#34;,\u0026#34;skew\u0026#34;,\u0026#34;kurtosis\u0026#34;,\u0026#34;entropy\u0026#34;,\u0026#34;class\u0026#34;]) Key statistics and overview Since the data were loaded using pandas, key methods of the DataFrame object can be used to find some key information in the data.\ndata0.describe()     vari skew kurtosis entropy class     count 1372.000000 1372.000000 1372.000000 1372.000000 1372.000000   mean 0.433735 1.922353 1.397627 -1.191657 0.444606   std 2.842763 5.869047 4.310030 2.101013 0.497103   min -7.042100 -13.773100 -5.286100 -8.548200 0.000000   25% -1.773000 -1.708200 -1.574975 -2.413450 0.000000   50% 0.496180 2.319650 0.616630 -0.586650 0.000000   75% 2.821475 6.814625 3.179250 0.394810 1.000000   max 6.824800 12.951600 17.927400 2.449500 1.000000    Negative values can be noticed in the variance and entropy, whereas it is theoretically impossible, so it can be deduced that some preprocessing operations were already performed.\nWe are trying to detect forged banknotes thanks to the extracted features. The dataset contains 1372 observations, including 610 forged banknotes, so roughly 45%. The two classes are balanced in the data, which might be relevant for some algorithms. Indeed, a higher proportion of a category in the characteristic of interest (here whether the banknote is genuine or not) yields a higher prior probability for that outcome in Bayesian reasoning.\nKernel Density Estimation for each variable by class KDE are powerful tools to understand how 1-dimensional data are distributed. The estimate can also be split by class to find differences in the distributions. Using ggplot and the pandas groupby method, the plots can be generated and saved as such:\nfor v in data0.columns[:4]: ggplot.ggsave( ggplot.ggplot(ggplot.aes(x=v, color=\u0026#39;class\u0026#39;),data=data0)+ ggplot.geom_density()+ ggplot.geom_point(ggplot.aes(y=0),alpha=0.2)+ ggplot.labs(title=\u0026#39;KDE \u0026#39;+v,x=v,y=\u0026#34;KDE\u0026#34;), \u0026#39;KDE_\u0026#39;+v+\u0026#39;.png\u0026#39;,width=18,height=12) Using this first simple visualization technique, we can deduce that the variance may be much more efficient to separate the two banknotes categories than the Kurtosis.\nVisualizing variable combinations with scatter plots We generate a color list using for-comprehension:\ncol = list(\u0026#39;r\u0026#39; if i==1 else \u0026#39;b\u0026#39; for i in data0[\u0026#34;class\u0026#34;]) pd.tools.plotting.scatter_matrix(data0.ix[:,:4],figsize=(6,3), color=col,diagonal=\u0026#39;kde\u0026#39;) A scatter plot is the most straight-forward way to understand intuitive and obvious patterns in the data. It is especially efficient when the number of variables and classes is limited, such as our data set. It allows us to understand class-dependent, non-linear relationships between variables.\nThis is much more efficient than a simple statistic, such as the correlation coefficient which would not have found the skewness and entropy to be related. From these rather strong relationships between variables, we now know that some techniques based on independent features might not be efficient here.\nTesting a distribution with Quantile-Quantile plots # Subsetting the data by class d0 = data0[data0[\u0026#34;class\u0026#34;]==0] d1 = data0[data0[\u0026#34;class\u0026#34;]==1] # For each variable for v in data0.columns[:4]: #set the figure size plt.figure(figsize=(9,4)) # define two subplots ax1 = plt.subplot(121) # compute the quantile-quantile plot with normal distribution stats.probplot(d0[v],dist=\u0026#39;norm\u0026#39;,plot=plt) # add title plt.title(\u0026#34;Normal QQ-plot \u0026#34;+v + \u0026#34; - Class 0\u0026#34;) ax2 = plt.subplot(122) stats.probplot(d1[v],dist=\u0026#39;norm\u0026#39;,plot=plt) plt.title(\u0026#34;Normal QQ-plot \u0026#34;+v + \u0026#34; - Class 1\u0026#34;) plt.savefig(\u0026#34;qqplot_\u0026#34;+v+\u0026#34;.png\u0026#34;,width=700,height=250) plt.show() Even though some variables are quite far from normally distributed, the hypothesis would be acceptable for some model-based learning algorithms using properties of Gaussian variables.\nNon-parametric distribution with boxplots Boxplots represent the data using 25th, 50th and 75th percentiles which can be more robust than mean and variance. The pandas library offers a quick method and plotting tool to represent boxplots for each class and variable. It highlights the differences in the spread of the data.\ndata0.groupby(\u0026#34;class\u0026#34;).boxplot(figsize=(9,5)) This will be useful in the next part, when the data will be transformed to enhance the performance and robustness of predictive models.\nSo see you in the next part for feature engineering!\n ","date":1452466800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505181809,"objectID":"0b5db556eb4114109debcb050cd6f379","permalink":"https://matbesancon.github.io/post/2016-01-11-fraud-detection/","publishdate":"2016-01-11T00:00:00+01:00","relpermalink":"/post/2016-01-11-fraud-detection/","section":"post","summary":"\r\nLearning by doing: detecting fraud on bank notes using Python in 3 steps.\r\n","tags":["data-science","python","classification"],"title":"A Pythonic data science project: Part I","type":"post"}]