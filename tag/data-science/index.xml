<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>data-science | μβ</title>
    <link>https://matbesancon.xyz/tag/data-science/</link>
      <atom:link href="https://matbesancon.xyz/tag/data-science/index.xml" rel="self" type="application/rss+xml" />
    <description>data-science</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 13 Sep 2016 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://matbesancon.xyz/media/icon_hu7565e292f0a230f950fabd03a1d7dda9_12642_512x512_fill_lanczos_center_3.png</url>
      <title>data-science</title>
      <link>https://matbesancon.xyz/tag/data-science/</link>
    </image>
    
    <item>
      <title>Functional and parallel PageRank implementation in Scala</title>
      <link>https://matbesancon.xyz/post/2016-09-13-page-rank/</link>
      <pubDate>Tue, 13 Sep 2016 00:00:00 +0000</pubDate>
      <guid>https://matbesancon.xyz/post/2016-09-13-page-rank/</guid>
      <description>&lt;p&gt;When I &lt;a href=&#34;https://matbesancon.xyz/posts/2016-08-11-back-to-startup/&#34;&gt;came back to Equisense&lt;/a&gt;,
I was surprised and intrigued by many things. But there was one element of the
job in particular I had not planned: coming back to low level and embedded
programming from higher abstractions I was used to. No OS, no
libraries, no smooth write-and-test work-flow, just brutal and bare metal.
I clearly needed to blow some steam off with something closer to what I
usually do (or did), a data-driven and functional project using nice techs.&lt;/p&gt;
&lt;h2 id=&#34;why-yet-another-pagerank&#34;&gt;Why yet another PageRank?&lt;/h2&gt;
&lt;p&gt;The time came to find a new side project and I was just finishing the lectures
of &lt;a href=&#34;https://www.coursera.org/learn/parprog1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parallel Programming&lt;/a&gt;, which I
recommend if you&amp;rsquo;re already at ease with Scala and its environment (IDEs, SBT).
I wanted to apply the concepts on a project built from scratch. One day,
while neglectfully scrolling through another blog post showing the basic
concepts of the PageRank computation, I thought this would make a &amp;ldquo;okay&amp;rdquo; project.
But wait, interesting elements here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The model behind the PageRank computation is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Markov_chain&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Markov Chain&lt;/a&gt;,
with which I have been working a lot with at Siemens.&lt;/li&gt;
&lt;li&gt;Iterating until stability of the ranks is basically a linear flow, easily
performed by &lt;a href=&#34;https://en.wikipedia.org/wiki/Tail_call&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tail call recursion&lt;/a&gt;
which is optimized to avoid stack-overflowing the JVM by behaving like a &lt;code&gt;while&lt;/code&gt; loop.&lt;/li&gt;
&lt;li&gt;Computing the rank of each site is independent of the other computations,
parallelizing the tasks is a piece of cake&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So we&amp;rsquo;re all set up for a purely functional and parallel PageRank.&lt;/p&gt;
&lt;h2 id=&#34;the-pagerank-model&#34;&gt;The PageRank model&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;re gonna go through the basic implementation of the algorithm. What
fascinates me is the two-sided view of the algorithm: the intuitive version can
be explained to a 5-year-old (or to your boss) while the maths behind it
relies on the interpretation of matrix eigenvalues and on a computation of the
stationary distribution of the Markov model.&lt;/p&gt;
&lt;h3 id=&#34;the-intuitive-version&#34;&gt;The intuitive version&lt;/h3&gt;
&lt;p&gt;Imagine you&amp;rsquo;re surfing on the web like any productive Sunday evening. On a
given page, there is an equal probability to click on any link present on the
page. There is also a probability that you get tired of the current series of
pages and randomly go back to any page of the network.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s try to visualize the two extremes of this &amp;ldquo;random switch&amp;rdquo; usually called
&lt;em&gt;damping factor&lt;/em&gt; &lt;code&gt;d&lt;/code&gt;. If we set &lt;code&gt;d=0&lt;/code&gt;, the transition to any page is equally
probable, since the surfer will always switch to choosing a page at random.
This means that the links going out of the page they&amp;rsquo;re currently on don&amp;rsquo;t
influence the probability distribution of the next page.&lt;/p&gt;
&lt;p&gt;On the other end of the spectrum if the damping factor &lt;code&gt;d=1&lt;/code&gt;, the surfer will
always look for its next page in the outgoing links of her current page
(this raises an issue for pages without any links). An usual value for the
factor is &lt;code&gt;d=0.85&lt;/code&gt;which keeps the probability of long sequences of related pages
likely to happen, but allows for random switch.&lt;/p&gt;
&lt;h3 id=&#34;key-elements-of-the-algorithm&#34;&gt;Key elements of the algorithm&lt;/h3&gt;
&lt;p&gt;The algorithm uses the matrix of links: an entry &lt;code&gt;(i,j)&lt;/code&gt; is 1 if there is a
link on the page &lt;code&gt;j&lt;/code&gt; to the page &lt;code&gt;i&lt;/code&gt; and 0 otherwise (note that this notation
is opposite to the common convention for Markov transition matrices, where the
line is the origin state and the column the destination). The other element is
a rank vector which is updated until a convergence criterion is met.&lt;/p&gt;
&lt;h3 id=&#34;types-of-the-different-structures&#34;&gt;Types of the different structures&lt;/h3&gt;
&lt;p&gt;Since we want to be able to perform some computations in parallel, most
functions will manipulate Scala&amp;rsquo;s &lt;em&gt;Generic&lt;/em&gt; data structures. Let&amp;rsquo;s start with
the link matrix. It is a sparse structure: instead of representing all
entries of the matrix in a vector of vectors, just non-empty elements and
there corresponding column and line indexes are stored.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// defining a dense matrix of Ints as a sequence of sequence
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;DenseMatrix&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// SparseMatrix: tuple (line, column, value)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;SparseMatrix&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[(&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;,&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;,&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, the values of our link matrix only contains zeros and ones, so the
entries present in the structure all have one as value, so we just need to keep
rows and columns:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinkMat&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[(&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;,&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The ranks are stored in a simple generic float sequence:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;R&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We also need a few utility functions. &lt;code&gt;sumElements&lt;/code&gt; takes the matrix, the rank
vector and an integer to find all links for which the outgoing page is &lt;code&gt;j&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; sumElements&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;R&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;],&lt;/span&gt; A&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinkMat&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; j&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// sums all PageRanks / number of links for a column j
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; totalLinks &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt; A&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;tup &lt;span style=&#34;color:#66d9ef&#34;&gt;=&amp;gt;&lt;/span&gt; tup&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_2 &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; j&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;totalLinks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;isEmpty&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;error&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;No link in the page &amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; j &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; at sumElements&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    R&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;j&lt;span style=&#34;color:#f92672&#34;&gt;)/&lt;/span&gt;totalLinks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; This implementation of the function is not purely functional since
an imperative system error is raised if no index i is found. A better solution
here would have been to wrap the value in an &lt;code&gt;Option[Float]&lt;/code&gt;, return &lt;code&gt;None&lt;/code&gt; if no
index has been found and &lt;code&gt;Some(x)&lt;/code&gt; in case of success.&lt;/p&gt;
&lt;p&gt;We also need to find all pages pointing to a given page i. This might be a
bit compact, but keep in mind that the matrix is simply a pair of page indexes.
So we find all pages where the first element is i (the page the link is going
to), that&amp;rsquo;s the filter part. We then take the second element of the tuple, so
all indexes pointing to i, thanks to a map.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; findConnected&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;i&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; A&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinkMat&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  A&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;filter&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_1&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;i&lt;span style=&#34;color:#f92672&#34;&gt;).&lt;/span&gt;map&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_2&lt;span style=&#34;color:#f92672&#34;&gt;).&lt;/span&gt;toSeq&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that the result is returned as a normal sequence (not the generic version
allowing for parallel computation). It&amp;rsquo;s not a big deal since the resulting
sequence is always manageable compared to the whole graph we are manipulating.&lt;/p&gt;
&lt;p&gt;Now, we stated that the algorithm recurses on the rank of all pages until
stability, which is something we define through a &lt;code&gt;converged&lt;/code&gt; function. We
simply use a squared difference between two different versions of the rank to
determine if they are acceptably close and yield a boolean.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; converged&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;r1&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;],&lt;/span&gt; r2&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;],&lt;/span&gt; eps&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Boolean&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; totSquare&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; r1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zip&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;r2&lt;span style=&#34;color:#f92672&#34;&gt;).&lt;/span&gt;map&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;(&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_1&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_2&lt;span style=&#34;color:#f92672&#34;&gt;)*(&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_1&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;_2&lt;span style=&#34;color:#f92672&#34;&gt;)).&lt;/span&gt;sum
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  sqrt&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;totSquare&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;r1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size&lt;span style=&#34;color:#f92672&#34;&gt;)&amp;lt;=&lt;/span&gt;eps
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now that everything is set, the master piece becomes a piece of cake.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-scala&#34; data-lang=&#34;scala&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@tailrec&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; compRank&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;R&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;],&lt;/span&gt; A&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;LinkMat&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                      damp&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; eps&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                      niter&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                      niterMax&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; rankIndex&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; until R&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; rightRank&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;GenSeq&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Float&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt; rankIndex map&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;i&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; connected &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt; findConnected&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;i&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;A&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    connected&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;map&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;j&lt;span style=&#34;color:#66d9ef&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;Int&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&amp;gt;&lt;/span&gt; sumElements&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;R&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; A&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt; j&lt;span style=&#34;color:#f92672&#34;&gt;)}.&lt;/span&gt;sum
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;val&lt;/span&gt; newRank &lt;span style=&#34;color:#66d9ef&#34;&gt;=&lt;/span&gt; rightRank map &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;damp&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;_&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;damp&lt;span style=&#34;color:#f92672&#34;&gt;)/&lt;/span&gt;R&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;size&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;converged&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;newRank&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;R&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;eps&lt;span style=&#34;color:#f92672&#34;&gt;))&lt;/span&gt; newRank
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;niter&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt;niterMax&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    println&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Max iteration reached&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    newRank
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; compRank&lt;span style=&#34;color:#f92672&#34;&gt;(&lt;/span&gt;newRank&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;A&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;damp&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;eps&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;niter&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;,&lt;/span&gt;niterMax&lt;span style=&#34;color:#f92672&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We first compute the right term of the new rank formula &lt;code&gt;rightRank&lt;/code&gt; and plug it
in &lt;code&gt;newRank&lt;/code&gt;. The two vectors can be passed to &lt;code&gt;compare&lt;/code&gt; to determine if
&lt;code&gt;newRank&lt;/code&gt; can be returned as a final result or if further recursion is needed.
A recursion counter also avoids waiting too long for a result and warns in case
of maximum recursion reached by printing to the standard output.
Once again, a more functional way would have been to wrap the result in a
&lt;code&gt;Try&lt;/code&gt; monad (no panic, we&amp;rsquo;re NOT going to go through monads, we&amp;rsquo;ve lost enough
people with this).&lt;/p&gt;
&lt;p&gt;You&amp;rsquo;ve surely noticed the &lt;code&gt;@tailrec&lt;/code&gt; tag highlighting that this function is not
going to blow the stack up.&lt;/p&gt;
&lt;h2 id=&#34;result-on-a-study-case&#34;&gt;Result on a study case&lt;/h2&gt;
&lt;h3 id=&#34;the-enron-email-dataset&#34;&gt;The Enron email dataset&lt;/h3&gt;
&lt;p&gt;While surfing in a semi-random way to find a cool dataset for the application,
I found the &lt;a href=&#34;https://snap.stanford.edu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SNAP&lt;/a&gt; project
from Stanford on which the
&lt;a href=&#34;https://snap.stanford.edu/data/email-Enron.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Enron emails data&lt;/a&gt;
are presented and to be downloaded. If you look at the
&lt;a href=&#34;https://github.com/matbesancon/PageRank&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github repo&lt;/a&gt; for this project, I simply
removed the header from the txt file to make the parsing tasks easier.&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;As many phenomena dealing with &lt;a href=&#34;https://en.wikipedia.org/wiki/Pareto_principle&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;concentration of resources&lt;/a&gt;,
the distribution of ranks follows a Pareto distribution, which can be
visualized on a log-log scale. I used Python with numpy and matplotlib, finding
the current Scala libraries still to cumbersome for this simple task. Here is
the result:
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/pageRank/rankDist.png&#34; alt=&#34;Resulting log-rank&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;a-conclusion-on-the-functionalimperative-debate&#34;&gt;A conclusion on the functional/imperative debate&lt;/h2&gt;
&lt;p&gt;If some of you clone and try to run the project (you&amp;rsquo;ll just need sbt for that).
Some people could argue that the runtime is too long for what it does (whatever
too long means), and that an imperative solution with a mutable rank on which
we loop until convergence. And I suppose they are right, but parallel
imperative is objectively a pain to work with. &lt;strong&gt;Tell the architecture what you
want, not what to do and it will compute it for you, whatever its
configuration is&lt;/strong&gt;, from your laptop to several clusters. That&amp;rsquo;s a key reason
why &lt;a href=&#34;http://spark.apache.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Spark&lt;/a&gt; is functional for instance.&lt;/p&gt;
&lt;hr&gt;
</description>
    </item>
    
    <item>
      <title>Bringing data science to engineers</title>
      <link>https://matbesancon.xyz/post/2016-05-21-bringing-data-science-engineers/</link>
      <pubDate>Sat, 21 May 2016 00:00:00 +0000</pubDate>
      <guid>https://matbesancon.xyz/post/2016-05-21-bringing-data-science-engineers/</guid>
      <description>&lt;p&gt;The goal of this article is to present couple challenges waiting the industrial
data scientist or industrial data science teams, the deep reasons I believe are
the root of this inertia, based on my experience (in both data science and
engineering projects) and exchanges with engineers and data scientists. The
last part introduces some suggestions to make the collaboration richer for
both sides.&lt;/p&gt;
&lt;h2 id=&#34;why-isnt-data-science-already-everywhere-in-engineering&#34;&gt;Why isn&amp;rsquo;t data science already everywhere in engineering?&lt;/h2&gt;
&lt;p&gt;It is surprising that this transition hasn&amp;rsquo;t been so spontaneous. Indeed, one
could think that engineers, belonging to the &amp;ldquo;STEM family&amp;rdquo; (people studying or
working in fields related to Science, Technology, Engineering and Mathematics)
would easily embrace the concepts and methods of data science and moreover be
able to identify the potential gains, savings and improvements to carry out
complex projects in a more effective manner.&lt;/p&gt;
&lt;h3 id=&#34;silo-thinking-in-stem&#34;&gt;Silo thinking in STEM&lt;/h3&gt;
&lt;p&gt;That&amp;rsquo;s not the case, most engineers I&amp;rsquo;ve been discussing and working with never
considered these techniques as relevant to their current tasks. So why so
little enthusiasm? A recurrent problem I noticed is the silo thinking of
disciplines created by strong and early specializations, along with natural
distaste and reduction of unknown fields.&lt;/p&gt;
&lt;h3 id=&#34;were-not-google-deal-with-it&#34;&gt;We&amp;rsquo;re not Google, deal with it&lt;/h3&gt;
&lt;p&gt;So when someone will first pitch machine learning to an engineer, I would often
observe reactions of &amp;ldquo;it&amp;rsquo;s not relevant to my field/work/issues&amp;rdquo; because they
don&amp;rsquo;t consider being in a &amp;ldquo;tech&amp;rdquo; industry. This is the same reaction type
observed in companies facing digital disruption (see the excellent article of
Nicolas Colin
&lt;a href=&#34;http://www.thefamily.co/hot-news/the-five-stages-of-denial&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;As a personal example, as I was talking to a production manager about the
impact advanced predictive analytics could have on machine reliability and
availability, she advanced the &amp;ldquo;non-tech&amp;rdquo; argument, to which I answered with
examples of traditional manufacturing companies already using these techniques,
including General Electric for turbine monitoring (what they refer to as the
Industrial Internet). His last point was &amp;ldquo;Well sure but&amp;hellip; we&amp;rsquo;re not GE&amp;rdquo;, which
I understood as &amp;ldquo;I&amp;rsquo;m not able to learn from nor to work in that field totally
out of my comfort zone&amp;rdquo;. Although, her discomfort with the methods involved is
easily understandable since it requires key concepts in mathematics, statistics
and algorithm thinking which would often be considered as theory unusable in
their &amp;ldquo;real life&amp;rdquo;.&lt;/p&gt;
&lt;h3 id=&#34;my-subject-is-so-complex&#34;&gt;My subject is so complex&lt;/h3&gt;
&lt;p&gt;The other reaction one would observe is linked to an interesting thinking
process: People always tend to reduce the breadth of subjects they don&amp;rsquo;t know,
and to emphasize (not to say oversize) the width and complexity of their own
domain. I recently read a &amp;ldquo;conversation hack&amp;rdquo; to make a conversation pleasant
to someone, in three steps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Ask them what they do for a living&lt;/li&gt;
&lt;li&gt;Ask them some more details about how they manage things&lt;/li&gt;
&lt;li&gt;Look impressed, add &amp;ldquo;Wow, that sounds very complex&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;People don&amp;rsquo;t feel at ease with the introduction of quantitative, rational
methods and analytics for decision-making in their daily work because this
implies that a rather &amp;ldquo;simple&amp;rdquo; model can generate better decisions than them.
It revives this old phobia of losing their job to a machine.&lt;/p&gt;
&lt;h3 id=&#34;but-still-why-particularly-engineers&#34;&gt;But still&amp;hellip; why particularly engineers?&lt;/h3&gt;
&lt;p&gt;We didn&amp;rsquo;t address this question yet, and it still sounds counter-intuitive,
given our first statements. From my personal experience studying and working
with both junior and senior engineers, and relatively to business or social
science background, there is a stronger will to &amp;ldquo;master the model&amp;rdquo; and
understand most key aspects of the system they work on.&lt;/p&gt;
&lt;p&gt;Bank managers, marketing leaders or finance analysts totally feel comfortable
with the use of data base systems and business intelligence tools, even
statistical analyses or predictive modeling tools they can perfectly leverage,
but not often understand on the technical parts. They would just need to be
able to read, use and trust the results. Engineers, on the other hand don&amp;rsquo;t
feel legitimate when using tools they don&amp;rsquo;t master they feel the need of
understanding and controlling what&amp;rsquo;s going on under the hood.&lt;/p&gt;
&lt;p&gt;There is a common vision of the engineers in several cultures, they are the
handy people, able to answer most of your questions, master all techniques from
nuclear power generation to bio-technologies. They are all supposed to be Tony
Stark (or Elon Musk in a more realistic way). So their secret fear is not about
being afraid of getting their job &amp;ldquo;automated&amp;rdquo; but more about a situation where
they cannot handle their system anymore because a part of the decisions taken
is not under their control anymore.&lt;/p&gt;
&lt;h2 id=&#34;what-to-do-about-it&#34;&gt;What to do about it?&lt;/h2&gt;
&lt;h3 id=&#34;what-data-science-can-bring-to-their-organization&#34;&gt;What data science can bring to their organization&lt;/h3&gt;
&lt;p&gt;Proving the utility of data science is the easy part, the process is actually
almost identical to bringing data science to any other industry. The potential
users should be shown what pain points this new field would address in their
business, how similar businesses have already applied machine learning to
their issues, and how the processes should be adapted to these projects.&lt;/p&gt;
&lt;h3 id=&#34;how-it-actually-works&#34;&gt;How it actually works&lt;/h3&gt;
&lt;p&gt;Empowering the engineers through explanations of the key concepts might be
seemingly pointless and time-consuming, but helps them accepting the
techniques involved as a part of the &amp;ldquo;internal model&amp;rdquo; secretly hidden in each
engineer&amp;rsquo;s mind and used to think about their system and make decisions upon
it.&lt;/p&gt;
&lt;p&gt;Most engineers are usually used to (at least) basic algorithm structures. So
using it to make them understand the thinking pattern behind machine learning
may help them to understand the mechanisms and feel at ease with reapplying
it. Once you&amp;rsquo;ve covered the fundamentals, a modeling skill should be
developed. Indeed, being able to model a problem as a data science project
will give a pretty straightforward beginning (especially on variable
selections or feature engineering).&lt;/p&gt;
&lt;p&gt;Basic linear regression (and in general other curve fitting methods) have
already been seen for experimental purposes in most engineering fields. If one
has only time to explain key concepts, I would give the following order:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Classification principles, example of classification trees.&lt;/li&gt;
&lt;li&gt;Regression techniques (if not already known). Simple and multivariate linear regression, polynomial regression.&lt;/li&gt;
&lt;li&gt;Unsupervised learning, example of k-means clustering.&lt;/li&gt;
&lt;li&gt;Overfitting, cross-validation concept and techniques.&lt;/li&gt;
&lt;li&gt;Ensemble learning, example of random forests.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With clear but complete explanations of regression, classification and
unsupervised learning, along with a previous knowledge of regression
techniques, most engineers will be able to identify opportunities to get
deeper insights into the phenomena they investigate or to build robust
predictions through machine learning, which is the basic goal to break the
barriers we discussed. The 4th and 5th topics are a bonus allowing them to
understand what techniques data scientists would use, they would not need them
for opportunity identification but to extend their &amp;ldquo;internal model&amp;rdquo;, which can
only be beneficial.&lt;/p&gt;
&lt;h3 id=&#34;key-examples&#34;&gt;Key examples&lt;/h3&gt;
&lt;p&gt;These examples are taken from diverse projects, challenges and data sets
including some personal ones. Each case study is addressed to specific targets.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Process, Energy and Chemical Engineers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I studied once the Combined Cycle Power Plant dataset which can be found on
the UCI dataset repository here. Using machine learning allowed the research
group not to work on the basis of restrictive hypotheses on the thermodynamic
behavior of the gas or steam, nor on the heat exchange and fluid mechanics
phenomena involved (e.g. pressure drop in the pipes due to phase change). The
predictions based on data are a totally new way to combine formal model-based
approaches (including process optimization) and operational realities (the
good old &amp;ldquo;gut feeling&amp;rdquo; experienced staff will tell you about).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Biomedical Engineers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This also includes all high-level medical professions. Well-known applications
were found in several fields, including pattern recognition from medical
images and data, disease risk estimations from patient background
information.&lt;/p&gt;
&lt;p&gt;Predictive modeling systems will be a decisive disruption in physicist work,
they replace the human decision-making process, based on few variables and on
a biased and relative experience with the risk-based optimal decision backed
by millions of data points.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Industrial, Manufacturing and Quality Engineers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Those case studies are inspired by my personal experience and the solutions
offered by several software development companies.&lt;/p&gt;
&lt;p&gt;The first one is the application of classification trees to replace rules
defining the quality of a product (first, second class or discarded for
instance). Using proper data mining tools allows the production manager to
define the relative &amp;ldquo;cost&amp;rdquo; of false positives (good products declared as not
salable, which induces all the manufacturing costs without the revenue) and
false negatives (non-conform products sent to be sold, which induces a risk of
complaint, on operation product default, image issues or recall campaigns).&lt;/p&gt;
&lt;p&gt;The second example is combining time-series analysis and multi-variable
regression techniques to give risk estimations on the process stability and
trends. I observed several software solution providers to whom the transition
from statistics to predictive modeling was a simple and obvious evolution.&lt;/p&gt;
&lt;p&gt;Bringing machine learning to engineers is a challenge and must be considered
as a promising step for both data science and engineering. Formal modeling
approaches and experimental considerations will eventually be able to be
conciliated. Data science will gain a significant support and become an
accelerator for the development of new techniques.&lt;/p&gt;
&lt;p&gt;You&amp;rsquo;re an engineer, a data scientist? Have you ever experienced collaborating
with engineers on data science applications? Did you encounter some
difficulties specific to working with engineers? Please get in touch for
further discussion on these topics.&lt;/p&gt;
&lt;p&gt;Now that we have discussed what data science could bring to engineers, a
second article may come to explain how to build a predictive model from
scratch in an industrial context.&lt;/p&gt;
&lt;p&gt;Special thanks to Robert, Benoit and Florian for their feedback on the article.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Pythonic data science project: Part III</title>
      <link>https://matbesancon.xyz/post/2016-01-13-fraud-detection3/</link>
      <pubDate>Wed, 13 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://matbesancon.xyz/post/2016-01-13-fraud-detection3/</guid>
      <description>&lt;p&gt;[1]&lt;/p&gt;
&lt;p&gt;Part III: Model development&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;To follow the following article without any trouble, I would recommend to
start with the beginning.&lt;/p&gt;
&lt;h1 id=&#34;how-does-predictive-modeling-work&#34;&gt;How does predictive modeling work&lt;/h1&gt;
&lt;h2 id=&#34;keep-the-terminology-in-mind&#34;&gt;Keep the terminology in mind&lt;/h2&gt;
&lt;p&gt;This is important to understand the principles and
sub-disciplines of machine learning. We are trying to predict a specific
&lt;strong&gt;output&lt;/strong&gt;, our information of interest, which is the category of bank note
we observe (genuine or forged).
This task is therefore labeled as &lt;strong&gt;supervised learning&lt;/strong&gt;, as opposed to
&lt;strong&gt;unsupervised learning&lt;/strong&gt; which consists of finding patterns or groups from
data without a priori identification of those groups.&lt;/p&gt;
&lt;p&gt;Supervised learning can further be labeled as &lt;strong&gt;classification&lt;/strong&gt; or
&lt;strong&gt;regression&lt;/strong&gt;, depending on the nature of the outcome, respectively
categorical or numerical. It is essential to know because the two disciplines
don&amp;rsquo;t involve the same models. Some models work in both cases but their expected
behavior and performance would be different. In our case, the outcome is
categorical with two levels.&lt;/p&gt;
&lt;h2 id=&#34;how-does-classification-work&#34;&gt;How does classification work?&lt;/h2&gt;
&lt;p&gt;Based on a subset of the data, we train a
model, so we tune it to minimize its error on these data. To make a parallel
with Object-Oriented Programming, the model is an &lt;strong&gt;instance&lt;/strong&gt; of the
class which defines how it works. The attributes would be its parameters and
it would always have two methods (functions usable only from the object):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;train&lt;/strong&gt; the model from a set of observations (composed of predictive
variables and of the outcome)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;predict&lt;/strong&gt; the outcome given some new observations
Another optional method would be &lt;strong&gt;adapt&lt;/strong&gt; which takes new training data and
adjusts/corrects the parameters. A brute-force way to perform this is to call
the train method on both the old and new data, but for some models a more
efficient technique exists.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;independent-evaluation&#34;&gt;Independent evaluation&lt;/h2&gt;
&lt;p&gt;A last significant element: we mentioned using only a subset of the data to
train the model. The reason is that the performance of the model has to be
evaluated, but if we compute the error on the training data, the result will
be biased because the model was precisely trained to minimize the error on this
training set. So the evaluation has to be done on a separated subset of the
data, this is called &lt;strong&gt;cross validation&lt;/strong&gt;.&lt;/p&gt;
&lt;h1 id=&#34;our-model-logistic-regression&#34;&gt;Our model: logistic regression&lt;/h1&gt;
&lt;p&gt;This model was chosen mostly because
it is visually and intuitively easy to understand and simple to
implement from scratch.
Plus, it covers a central topic in data science, optimization.
The underlying reasoning is the following:
The logit function of the probability of a level of the classes is
linearly dependent on the predictors. This can be written as:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;log(p&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;p)) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; beta0 &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; beta[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; x[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; beta[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Why do we need the logit function here?
Well technically, a linear regression could be fitted with the class as output
(encoded as 0/1) and the features as predictive variables. However, for some
values of the predictors, the model would yield outputs below 0 or above 1.
The logistic function &lt;strong&gt;equation&lt;/strong&gt; yields an output between 0 and 1 and
is therefore well suited to model a probability.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/linear_binary.png&#34; alt=&#34;Linear regression on binary output&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/logistic_binary.png&#34; alt=&#34;Logistic regression on binary output&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;You can noticed a decision boundary, which is the limit between the
region where the model yields a prediction &amp;ldquo;0&amp;rdquo; and a prediction &amp;ldquo;1&amp;rdquo;.
The output of the model is a probability of the class &amp;ldquo;1&amp;rdquo;, the forged
bank notes, so the decision boundary can be put at p=0.5, which would be
our &amp;ldquo;best guess&amp;rdquo; for the transition between the two regions.&lt;/p&gt;
&lt;h2 id=&#34;required-parameters&#34;&gt;Required parameters&lt;/h2&gt;
&lt;p&gt;As you noticed in the previous explanation, the model takes a vector of
parameters which correspond to the weights of the different variables.
The intercept \beta_0 places the location of the point at which p=0.5,
it shifts the curve to the right or the left.
The coefficients of the variables correspond to the sharpness of the transition.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/logistic_coeff.png&#34; alt=&#34;Evolution of the model with different coefficient values&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;learning-process&#34;&gt;Learning process&lt;/h2&gt;
&lt;h3 id=&#34;parameters-identification-issue&#34;&gt;Parameters identification issue&lt;/h3&gt;
&lt;p&gt;Unlike linear regression, the learning process for logistic regression is not
a straight-forward computation of the parameters through simple linear algebra
operations. The criterion to optimize is the likelihood, or equivalently, the
log-likelihood of the parameters:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;L(beta&lt;span style=&#34;color:#f92672&#34;&gt;|&lt;/span&gt;(X,z)) &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; f(X,z)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&#34;parameters-update&#34;&gt;Parameters update&lt;/h3&gt;
&lt;p&gt;The best parameters in the sense of the log-likelihood are therefore found
where this function reaches its maximum.
For the logistic regression problem,
there is only one critical point, which is also the only maximum of the
log-likelihood. So the overall process is to start from a random set of
parameters and to update it in the direction that increases the
log-likelihood the most. This precise direction is given by the
&lt;strong&gt;gradient&lt;/strong&gt; of the log-likelihood. The updated weights at each iteration
can be written as:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;beta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; beta &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; gamma&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; gradient_log_likelihood(beta)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Several criteria can be used to determine if a given set of parameters is an
acceptable solution. A solution will be considered acceptable when the
difference between two iterations is low enough.&lt;/p&gt;
&lt;h3 id=&#34;optimal-learning-rate&#34;&gt;Optimal learning rate&lt;/h3&gt;
&lt;p&gt;The coefficient gamma is called the &lt;strong&gt;learning rate&lt;/strong&gt;. Higher values lead to
quicker variations of the parameters, but also to stability and convergence
issues. Too small values on the other increase the number of steps required to
reach an acceptable maximum. The best solution is often a varying learning
rate, adapting the rate of variations. The rate at step n is chosen as follows:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;gamma_n &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; alpha&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;min(c0,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(n)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Which means that the learning rate is constant for all first steps until the
following condition is reached:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;n &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;c0)&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;c0&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After this iteration, the learning rate slowly decreases because we assume the
parameters are getting closer to the right value, which we don&amp;rsquo;t want to
overshoot.&lt;/p&gt;
&lt;h2 id=&#34;decision-boundaries-and-2d-representation&#34;&gt;Decision boundaries and 2D-representation&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;decision region&lt;/strong&gt; is the subset of the features space within which the
decision taken by the model is identical. A &lt;strong&gt;decision boundary&lt;/strong&gt; is the
subset of the space where the decision &amp;ldquo;switches&amp;rdquo;. For most algorithms,
the decision taken on the boundary is arbitrary. The possible boundary
shapes are a key characteristic of machine learning algorithms.&lt;/p&gt;
&lt;p&gt;In our case, logistic regression models the logit of the probability,
which is strictly monotonous with the probability as linearly
proportional to the predictors. It can be deduced that the decision
boundary will be a straight line separating the two classes.
This can be visualized using two features of the data, &amp;ldquo;vari&amp;rdquo; and
&amp;ldquo;k_resid&amp;rdquo;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; learn_weights(data1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[:,(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;)])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# building the mesh&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;xmesh, ymesh &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;meshgrid(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(data1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;vari&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min()&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;,data1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;vari&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max()&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;.01&lt;/span&gt;),\
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(data1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;k_resid&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min()&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;,data1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;k_resid&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max()&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;.01&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pmap &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;DataFrame(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;c_[np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones((len(xmesh&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel()),)),xmesh&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel(),ymesh&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ravel()])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; pmap&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(p,(prob_log(line,w)))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(xmesh&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;contourf(xmesh, ymesh, np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;power(p,&lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;RdBu&amp;#39;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(data1[data1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;vari&amp;#34;&lt;/span&gt;],data1[data1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;k_resid&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Class 0&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(data1[data1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;vari&amp;#34;&lt;/span&gt;],data1[data1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;k_resid&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Class 1&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend(loc&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;upper right&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2-dimension logistic regression result&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vari&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k_resid&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grid()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/2dimension.png&#34; alt=&#34;Decision boundary for two dimensions&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;implementation&#34;&gt;Implementation&lt;/h1&gt;
&lt;h2 id=&#34;elementary-functions&#34;&gt;Elementary functions&lt;/h2&gt;
&lt;p&gt;Modularizing the code increases the readability, we define the
implementations of two mathematical functions:
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;prob_log&lt;/span&gt;(x,w):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    probability of an observation belonging
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    to the class &amp;#34;one&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    given the predictors x and weights w
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(x,w))&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;exp(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(x,w))&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;grad_log_like&lt;/span&gt;(X, y, w):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    computes the gradient of the log-likelihood from predictors X,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    output y and weights w
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(X&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;T,y&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_along_axis(&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: prob_log(x,w),&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,X))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape((len(w),))&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;
&lt;h2 id=&#34;learning-algorithm&#34;&gt;Learning algorithm&lt;/h2&gt;
&lt;p&gt;A function computes the optimal weights from iterations to find the maximal
log-likelihood of the parameters, using the two previous functions.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;learn_weights&lt;/span&gt;(df):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    computes and updates the weights until convergence
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    given the features and outcome in a data frame
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    X &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;c_[np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones(len(df)),np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[:,:df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array(df[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    niter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    error &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;.0001&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;],))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    w0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; w&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    alpha &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;.3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;while&lt;/span&gt; sum(abs(w0&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;w))&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;error &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; niter &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        niter&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        w0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; w
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        w &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; w &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; alpha&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;min(&lt;span style=&#34;color:#ae81ff&#34;&gt;.1&lt;/span&gt;,(&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(niter&lt;span style=&#34;color:#f92672&#34;&gt;**&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (grad_log_like(X,y,w))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; niter&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;10000&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Maximum iterations reached&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; w&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;prediction&#34;&gt;Prediction&lt;/h2&gt;
&lt;p&gt;Once the weights have been learnt, new probabilities can be predicted from
explanatory variables.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;predict_outcome&lt;/span&gt;(df,w):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    takes in a test data set and computed weights
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    returns a vector of predicted output, the confusion matrix
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    and the number of misclassifications
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    confusion_matrix &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    p &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; line &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; df&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,line[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        p&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(prob_log(x,w))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; (prob_log(x,w)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; line[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            confusion_matrix[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; (prob_log(x,w)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; line[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            confusion_matrix[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;elif&lt;/span&gt; (prob_log(x,w)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;and&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; line[&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            confusion_matrix[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            confusion_matrix[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; p, confusion_matrix, len(df)&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;sum(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;diag(confusion_matrix))&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;cross-validated-evaluation&#34;&gt;Cross-validated evaluation&lt;/h2&gt;
&lt;p&gt;Learning weights on a training subset and getting the error on an other subset
will allow us to estimate the real error rate of our prediction. 100 cross
validations are performed and for each of them, we add the error to a list.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;error &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;weights &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; test &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;100&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    trainIndex &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rand(len(data0)) &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.85&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    data_train &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data1[trainIndex]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    data_test &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data1[&lt;span style=&#34;color:#f92672&#34;&gt;~&lt;/span&gt;trainIndex]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    weights&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(learn_weights(data_train))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    error&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;append(predict_outcome(data_test,weights[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The following results were obtained:
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/GLM_errors.png&#34; alt=&#34;Evolution of the model with different coefficient values&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The model produces on average 2.66 mis-classifications for 100 evaluated
banknotes. Note that on each test, 85% of the observations
went into the training set, which is arbitrary. However, too few
training points would yield inaccurate models and higher error rates.&lt;/p&gt;
&lt;h1 id=&#34;improvement-perspectives-and-conclusion&#34;&gt;Improvement perspectives and conclusion&lt;/h1&gt;
&lt;p&gt;On this data set, we managed to build independent and reliable features and
model the probability of belonging to the forged banknotes class thanks to a
logistic regression model. This appeared to be quite successful from the error
estimation on the test set. However, few further progresses could be made.&lt;/p&gt;
&lt;h2 id=&#34;testing-other-models&#34;&gt;Testing other models&lt;/h2&gt;
&lt;p&gt;We only implemented the logistic regression from scratch, given that several
models would have increased the length of this article. But some other
algorithms would have been interesting, such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;K nearest neighbors&lt;/li&gt;
&lt;li&gt;Support Vector Machine&lt;/li&gt;
&lt;li&gt;Model-based predictions such as naive Bayes or Quadratic Discriminant Analysis&lt;/li&gt;
&lt;li&gt;Classification Tree&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Fact of interest: the two first algorithms also build linear decision
boundaries, but based on other criteria.&lt;/p&gt;
&lt;h2 id=&#34;adjusting-the-costs&#34;&gt;Adjusting the costs&lt;/h2&gt;
&lt;p&gt;We assumed that misclassifying a true banknote was just as bad as doing so for
a forged one. This is why using a limit at p=0.5 was the optimal choice. But
suppose that taking a forged banknote for a genuine one costs twice more than
the opposite error. Then the limit probability will be set at p = 0.25 to
minimize the overall cost. More generally, a &lt;strong&gt;cost matrix&lt;/strong&gt; can be built
to minimize the sum of the element-wise product of the cost matrix with the
confusion matrix. Here is an interesting
&lt;a href=&#34;http://stackoverflow.com/questions/17464229/weka-cost-matrix-interpretation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stack Overflow topic&lt;/a&gt;
topic on the matter.&lt;/p&gt;
&lt;h2 id=&#34;online-classification&#34;&gt;Online classification&lt;/h2&gt;
&lt;p&gt;The analysis carried on in this article is still far from the objective of some
data projects, which would be to build a reusable on-line classifier.
In our case, this could be used by bank to instantaneously verify bank notes
received. This raises some new issues like the update of different parameters
and the detection of new patterns.&lt;/p&gt;
&lt;p&gt;Special thanks to Rémi for reading the first awful drafts
and giving me some valuable feedback.&lt;/p&gt;
&lt;hr&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>A Pythonic data science project: Part II</title>
      <link>https://matbesancon.xyz/post/2016-01-12-fraud-detection2/</link>
      <pubDate>Tue, 12 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://matbesancon.xyz/post/2016-01-12-fraud-detection2/</guid>
      <description>&lt;p&gt;[1]&lt;/p&gt;
&lt;p&gt;Part II: Feature engineering&lt;/p&gt;
&lt;hr&gt;
&lt;h1 id=&#34;what-is-feature-engineering&#34;&gt;What is feature engineering?&lt;/h1&gt;
&lt;p&gt;It could be describe as the transformation of raw data to produce
a model input which will have better performance. The &lt;em&gt;features&lt;/em&gt; are
the new variables created in the process.
It is often described as based on domain knowledge and more of an
art than of a science. Therefore, it requires a great attention and
a more &amp;ldquo;manual&amp;rdquo; process than the rest of data science projects.&lt;/p&gt;
&lt;p&gt;Feature engineering tends to be heavier when raw data are far from
the expected input format of our learning models
(images or text for instance). It can be noticed that some feature
engineering was already performed on our data, since banknotes were
registered as images taken from a digital camera, and we only received
5 features for each image.&lt;/p&gt;
&lt;h1 id=&#34;correlated-variables&#34;&gt;Correlated variables&lt;/h1&gt;
&lt;h2 id=&#34;simple-linear-and-polynomial-regression&#34;&gt;Simple linear and polynomial regression&lt;/h2&gt;
&lt;p&gt;We noticed some strong dependencies between variables thanks to the
scatter plot. Those can deter the performance and robustness of
several machine learning models. Skewness and kurtosis seem to be
somehow related. A regression line can be fitted with the skewness as
explanatory variable:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a, b &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linregress(data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kurtosis&amp;#34;&lt;/span&gt;])[:&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kurtosis&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;g+&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;) ,b&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;a&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;),&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Simple linear regression&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Skewness&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Kurtosis&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/linear_reg.png&#34; alt=&#34;Linear regression&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The following result highlights a lack in the model. The slope and intercept
seem to be biased by a dense cluster of points with the skewness
between 1 and 2. The points with a low skewness are under-represented in the
model and do not follow the trend of the regression line. A robust regression
technique could correct this bias, but a polynomial regression is the most
straight-forward method to capture a higher part of the variance here.
The second-degree polynomial model can be written as:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; a&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;square(x) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and its coefficients can be determined through the minimization of least-square
error in numpy:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a, b, c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;polyfit(data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kurtosis&amp;#34;&lt;/span&gt;],deg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kurtosis&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;),a&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;b&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;c,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;2nd degree polynomial regression&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Skewness&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Kurtosis&amp;#39;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;A polynomial regression yields a much better output with balanced residuals.
The p-value for all coefficients is below the 1% confidence criterion.
One strong drawback can however be noticed: the polynomial model predicts an
increase in the kurtosis for skewness superior to 2, but there is no evidence
for this statement in our data, so the model could lead to stronger errors.&lt;/p&gt;
&lt;p&gt;The regression does not capture all the variance (and does not explain all
underlying phenomena) of the Kurtosis, so a transformed variable has to be kept,
which should be independent from the skewness. The most obvious value is the
residual of the polynomial regression we performed.&lt;/p&gt;
&lt;p&gt;We can can represent this residual versus the explanatory variable
to be assured that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The residuals are centered around 0&lt;/li&gt;
&lt;li&gt;The variance of the residuals is approximately constant with the skewness&lt;/li&gt;
&lt;li&gt;There are still patterns in the Kurtosis: the residuals are not just noise&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;p0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;b&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;a&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kurtosis&amp;#34;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt;,marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;p0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;b&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;a&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kurtosis&amp;#34;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;,marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Explanatory variable vs Regression residuals&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Skewness&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Residuals&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;0&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;The data is now much more uncorrelated, so the feature of interest is the
residual of the regression which will replace the kurtosis in the data.&lt;/p&gt;
&lt;h2 id=&#34;class-dependent-regression&#34;&gt;Class-dependent regression&lt;/h2&gt;
&lt;p&gt;We can try and repeat the same process for the entropy and skewness, which
also seem to be related to each other.
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;p0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;b&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;a&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kurtosis&amp;#34;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt;,marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;p0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter(d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;b&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;a&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kurtosis&amp;#34;&lt;/span&gt;],c&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt;,marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Explanatory variable vs Regression residuals&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Skewness&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Residuals&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend([&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;0&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Class 0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Class 1&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Skewness&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entropy&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grid()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/skew_entropy.png&#34; alt=&#34;Skewness-Entropy&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We can try can fit a 2nd-degree polynomial function:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ft &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;polyfit(data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],deg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Class 0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Class 1&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;14.5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         ft[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;14.5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;14.5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;ft[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;14.5&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;ft[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;,linewidth&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; ,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;         label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Fitted polynom&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Skewness&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entropy&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grid()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend(loc&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;bottom center&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/fit1_entropy.png&#34; alt=&#34;Polynomial regression on entropy&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;However, it seems that the model does not fit well our data and that the points
are not equally distributed on both side of the curve. There is another
pattern, which is class-dependent, so two polynomial curves should be fitted,
one for each class:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;polyfit(d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],deg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;14&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;.5&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;polyfit(d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],deg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x,f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Fitted 0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;+&amp;#39;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.7&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Class 0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(x,f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;-&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Fitted 1&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;m+&amp;#39;&lt;/span&gt;,alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;.7&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Class 1&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Class dependent fit&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Skewness&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Entropy&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grid()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend(loc&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;bottom center&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;savefig(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class_depend.png&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/class_depend.png&#34; alt=&#34;Class-dependent polynomial regression&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The model seems to capture more of the variance in our data, which we can
confirm by plotting the residuals of the class-dependent regression.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Class 0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Class 1&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grid()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Skewness&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Residuals&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;savefig(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;res_class_dep.png&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/res_class_dep.png&#34; alt=&#34;Residuals of the class-dependent polynomial regression&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;We have a proper working model, with just one problem: &lt;strong&gt;we used
the class to predict the entropy&lt;/strong&gt; whereas our classification
objective is to proceed the other way around. Since we noticed
that each class follows a different curve, a difference between
the distance to the first model and the distance to the second
model, which will be noted &amp;ldquo;d&amp;rdquo;, can be computed as:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(y &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(f0)) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(y&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply(f1))&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A positive &amp;ldquo;d&amp;rdquo; value indicates that the entropy of the observation
is closer to the model fitted on the class 1, this seems to be a
rather relevant indicator to use to build our models. However, this
variable seems correlated to the skewness. The latter could have become
unnecessary for our prediction, so we choose to eliminate it from
the features and take the risk of an information loss.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;d &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; abs(data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    abs(data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; d[data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; d[data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grid()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Class 0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d&amp;#34;&lt;/span&gt;],&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r+&amp;#39;&lt;/span&gt;,label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Class 1&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d vs skewness for each class&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Skewness&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/d_skew.png&#34; alt=&#34;distance vs skewness for each class&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;variable-scaling&#34;&gt;Variable scaling&lt;/h1&gt;
&lt;h2 id=&#34;common-scaling-techniques&#34;&gt;Common scaling techniques&lt;/h2&gt;
&lt;p&gt;Very different spreads could be noticed among variables during the exploratory
part. This can lead to a bias in the distance between two points. A possible
solution to this is &lt;strong&gt;scaling&lt;/strong&gt; or &lt;strong&gt;standardization&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Variance scaling&lt;/strong&gt; of a variable is the division of each value by the
variable standard deviation. The output is a variable with variance 1.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Min-Max standardization&lt;/strong&gt; of a variable is the division of each value by
the difference between the maximum and minimum values. The outcome values
are all contained in the interval [0,1].&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x_stand &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max()&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min())&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Other standardization operations exist, but those are the
most common because of the properties highlighted.&lt;/p&gt;
&lt;h2 id=&#34;advantages-and-risks&#34;&gt;Advantages and risks&lt;/h2&gt;
&lt;p&gt;Scaling variables may avoid the distance between data points
to be over-influenced by high-variance variables, because
the ability to classify the data points from a variable
is usually not proportional to the variable variance.&lt;/p&gt;
&lt;p&gt;Furthermore, all people with notions in physics and calculus
would find it awkward to compute a distance from heterogeneous
variables (which would have different units and meaning).&lt;/p&gt;
&lt;p&gt;However, scaling might increase the weight of variables carrying mostly
or only noise, to which the model would fit, increasing the error on
new data.&lt;/p&gt;
&lt;p&gt;For this case, the second risk seems very low: all variables seem to
carry information, which we could observe because of the low number of
variables.&lt;/p&gt;
&lt;h1 id=&#34;feature-engineering-pipeline&#34;&gt;Feature engineering pipeline&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;a, b, c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;polyfit(data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kurtosis&amp;#34;&lt;/span&gt;],deg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data0&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;copy() &lt;span style=&#34;color:#75715e&#34;&gt;# copying the data&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vari&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k_resid&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;entropy&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;class&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;k_resid&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kurtosis&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;square(a&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;(data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; b&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; c)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns  &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; [&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;vari&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;skew&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;k_resid&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;d&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;class&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#75715e&#34;&gt;# computing the feature from the entropy regression&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;polyfit(d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],deg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;polyfit(d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;],d1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;],deg&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data1[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d&amp;#34;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; abs(data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f0[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;\
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    abs(data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;f1[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;drop(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# removing skew&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[:,:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[:,:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;var(data1&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;iloc[:,:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;])) &lt;span style=&#34;color:#75715e&#34;&gt;# data normalization&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;data1&lt;/code&gt; can now be used in the next step which will consist in the
implementation of a basic machine learning algorithm. This is the key
part in an analysis-oriented data science project, and I hope to see you there.&lt;/p&gt;
&lt;hr&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
    <item>
      <title>A Pythonic data science project: Part I</title>
      <link>https://matbesancon.xyz/post/2016-01-11-fraud-detection/</link>
      <pubDate>Mon, 11 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://matbesancon.xyz/post/2016-01-11-fraud-detection/</guid>
      <description>&lt;h2 id=&#34;a-complete-predictive-modeling-project-in-python&#34;&gt;A complete predictive modeling project in Python&lt;/h2&gt;
&lt;p&gt;Part I: Preprocessing and exploratory analysis&lt;/p&gt;
&lt;p&gt;One of the amazing things with data science is the ability to tackle
complex problems involving hidden parallel phenomena interacting with each
other, just from the data they produce.&lt;/p&gt;
&lt;p&gt;As an example, we will use data extracted from images of forged and genuine
banknotes. The distinction between the two categories would be thought to
require a deep domain expertise, which limits the ability to check
more than a few banknotes at a time. An automated and trustable test would
be of interest for many businesses, governments and organizations.&lt;/p&gt;
&lt;p&gt;Starting from the data provided by H. Dörsken and
Volker Lohweg, from the University of Applied Science of Ostwestfalen-Lippe,
Germany on the
&lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/banknote&amp;#43;authentication&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;UCI Machine Learning Repository&lt;/a&gt;,
we will follow key steps of a data science project to build a performant, yet
scalable classifier.&lt;/p&gt;
&lt;p&gt;The dataset was built by applying a wavelet
transform on images of banknotes to extract 4 features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Variance, skewness, kurtosis of the wavelet transform (respectively second,
third and fourth moment of the distribution).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Entropy of the image, which can be interpreted as the amount of information
or randomness (which is represented by how different adjacent pixels are).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find further information on Wavelet on &lt;a href=&#34;https://en.wikipedia.org/wiki/Wavelet_transform&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wikipedia&lt;/a&gt;
or ask &lt;a href=&#34;https://www.quora.com/In-an-intuitive-explanation-what-is-a-wavelet-transform-and-how-does-it-work-in-an-image&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quora&lt;/a&gt;.
An explanation of entropy as meant in the image processing context can
be found &lt;a href=&#34;http://www.astro.cornell.edu/research/projects/compression/entropy.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To get a better understanding of the way the algorithms works,
the full model will be built from scratch or almost (not using a machine
learning library like scikit-learn on Python or caret on R).&lt;/p&gt;
&lt;p&gt;Basic statistic notions (variance, linear regression) and some basic python
knowledge is recommended to follow through the three articles.&lt;/p&gt;
&lt;h2 id=&#34;programming-choices-and-libraries&#34;&gt;Programming choices and libraries&lt;/h2&gt;
&lt;h3 id=&#34;language-and-environment&#34;&gt;Language and environment&lt;/h3&gt;
&lt;p&gt;Python, which is a great
compromise between practicality (with handy data format and manipulation)
and scalability (much easier to implement for large scale, automated
computation than R, Octave or Matlab). More precisely, Python 3.5.1 with
the Anaconda distribution 2.4.0, I personally use the Spyder environment
but feel free to keep your favorite tools.&lt;/p&gt;
&lt;h3 id=&#34;libraries&#34;&gt;Libraries&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Collections (built-in) for occurrence counting&lt;/li&gt;
&lt;li&gt;numpy 1.10.1, providing key data format, mathematical manipulation techniques.&lt;/li&gt;
&lt;li&gt;scipy 0.16.0, imported here for the distance matrix computation and the stat submodule for Quantile-Quantile plots.&lt;/li&gt;
&lt;li&gt;pandas 0.17.1 for advanced data format, high-level manipulation and visualization&lt;/li&gt;
&lt;li&gt;pyplot from matplotlib 1.5.0 for basic visualization&lt;/li&gt;
&lt;li&gt;ggplot 0.6.8, which I think is a much improved way to visualize data&lt;/li&gt;
&lt;li&gt;urllib3 to parse the data directly from the repository (no manual download)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So our first lines of code (once you placed your data in the proper repository)
should look like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pandas &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; pd
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; ggplot
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; matplotlib &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; pyplot &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; plt
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; scipy.stats &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; stats
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; scipy.spatial.distance
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; collections &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; Counter
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; urllib3&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&#34;source-files&#34;&gt;Source files&lt;/h3&gt;
&lt;p&gt;The source files will be available on the corresponding Github repository.
These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;preprocess.py to load the data and libraries&lt;/li&gt;
&lt;li&gt;exploratory.py for preliminary visualization&lt;/li&gt;
&lt;li&gt;feature_eng.py where the data will be transformed to boost the model performance&lt;/li&gt;
&lt;li&gt;model_GLM.py where we define key functions and build our model&lt;/li&gt;
&lt;li&gt;model.py where we will visualize characteristics of the model&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;dataset-overview-and-exploratory-analysis&#34;&gt;Dataset overview and exploratory analysis&lt;/h1&gt;
&lt;p&gt;Understanding intuitive phenomena in the data and test its underlying structure
are the objectives for this first (usually long) phase of a data science
project, especially if you were not involved in the data collection process.&lt;/p&gt;
&lt;h2 id=&#34;data-parsing&#34;&gt;Data parsing&lt;/h2&gt;
&lt;p&gt;Instead of manually downloading the data and placing it in our project
repository, we will download using the &lt;em&gt;urllib3&lt;/em&gt; library.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;url &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;http &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; urllib3&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;PoolManager()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;r &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; http&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;request(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;GET&amp;#39;&lt;/span&gt;,url)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; open(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data_banknote_authentication.txt&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;wb&amp;#39;&lt;/span&gt;) &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; f:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  f&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;write(r&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;data)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;r&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;release_conn()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;read_csv(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;data_banknote_authentication.txt&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  names&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;vari&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;skew&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;kurtosis&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;entropy&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;])&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&#34;key-statistics-and-overview&#34;&gt;Key statistics and overview&lt;/h2&gt;
&lt;p&gt;Since the data were loaded using pandas, key methods of the DataFrame
object can be used to find some key information in the data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data0&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;describe()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;vari&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;skew&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;kurtosis&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;entropy&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;class&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;count&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1372.000000&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1372.000000&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1372.000000&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1372.000000&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1372.000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;mean&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.433735&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.922353&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.397627&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-1.191657&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.444606&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;std&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.842763&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5.869047&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;4.310030&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.101013&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.497103&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;min&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-7.042100&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-13.773100&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-5.286100&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-8.548200&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;25%&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-1.773000&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-1.708200&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-1.574975&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-2.413450&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;50%&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.496180&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.319650&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.616630&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-0.586650&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;75%&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.821475&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.814625&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;3.179250&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.394810&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.000000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;max&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;6.824800&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;12.951600&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;17.927400&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;2.449500&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.000000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Negative values can be noticed in the variance and entropy, whereas it is
theoretically impossible, so it can be deduced that some preprocessing
operations were already performed.&lt;/p&gt;
&lt;p&gt;We are trying to detect forged banknotes thanks to the extracted features.
The dataset contains 1372 observations, including 610 forged banknotes, so
roughly 45%. The two classes are balanced in the data, which might be relevant
for some algorithms. Indeed, a higher proportion of a category in the
characteristic of interest (here whether the banknote is genuine or not) yields
a higher &lt;strong&gt;prior probability&lt;/strong&gt; for that outcome in Bayesian reasoning.&lt;/p&gt;
&lt;h2 id=&#34;kernel-density-estimation-for-each-variable-by-class&#34;&gt;Kernel Density Estimation for each variable by class&lt;/h2&gt;
&lt;p&gt;KDE are powerful tools to understand how 1-dimensional data are distributed.
The estimate can also be split by class to find differences in the
distributions. Using ggplot and the pandas &lt;code&gt;groupby&lt;/code&gt; method, the
plots can be generated and saved as such:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; data0&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns[:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ggplot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ggsave(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ggplot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ggplot(ggplot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;aes(x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;v, color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;class&amp;#39;&lt;/span&gt;),data&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;data0)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ggplot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;geom_density()&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ggplot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;geom_point(ggplot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;aes(y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;),alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.2&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ggplot&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;labs(title&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;KDE &amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;v,x&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;v,y&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;KDE&amp;#34;&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;KDE_&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;v&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;.png&amp;#39;&lt;/span&gt;,width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;18&lt;/span&gt;,height&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/KDE_entropy.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/KDE_Vari.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/KDE_skew.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/KDE_kurtosis.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Using this first simple visualization technique, we can deduce that the
variance may be much more efficient to separate the two banknotes
categories than the Kurtosis.&lt;/p&gt;
&lt;h2 id=&#34;visualizing-variable-combinations-with-scatter-plots&#34;&gt;Visualizing variable combinations with scatter plots&lt;/h2&gt;
&lt;p&gt;We generate a color list using for-comprehension:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;col &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; list(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;r&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; i&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;b&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pd&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tools&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plotting&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;scatter_matrix(data0&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ix[:,:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;],figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;6&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;color&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;col,diagonal&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;kde&amp;#39;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/scatter_matrix.png&#34; alt=&#34;Scatter matrix: red dots represent the class &amp;amp;ldquo;1&amp;amp;rdquo;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;A scatter plot is the most straight-forward way to understand intuitive and
obvious patterns in the data. It is especially efficient when the number of
variables and classes is limited, such as our data set. It allows us to
understand class-dependent, non-linear relationships between variables.&lt;/p&gt;
&lt;p&gt;This is much more efficient than a simple statistic, such as the correlation
coefficient which would not have found the skewness and entropy to be related.
From these rather strong relationships between variables, we now know that
some techniques based on independent features might not be efficient here.&lt;/p&gt;
&lt;h2 id=&#34;testing-a-distribution-with-quantile-quantile-plots&#34;&gt;Testing a distribution with Quantile-Quantile plots&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Subsetting the data by class&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;d0 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data0[data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;d1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; data0[data0[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# For each variable&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; v &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; data0&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;columns[:&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#set the figure size&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# define two subplots&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ax1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;121&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# compute the quantile-quantile plot with normal distribution&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;probplot(d0[v],dist&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;norm&amp;#39;&lt;/span&gt;,plot&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;plt)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# add title&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Normal QQ-plot &amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;v &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; - Class 0&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ax2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplot(&lt;span style=&#34;color:#ae81ff&#34;&gt;122&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stats&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;probplot(d1[v],dist&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;norm&amp;#39;&lt;/span&gt;,plot&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;plt)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Normal QQ-plot &amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;v &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; - Class 1&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;savefig(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;qqplot_&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;v&lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;.png&amp;#34;&lt;/span&gt;,width&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;700&lt;/span&gt;,height&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;250&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/qqplot_entropy.png&#34; alt=&#34;QQplot entropy&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/qqplot_skew.png&#34; alt=&#34;QQplot skewness&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/qqplot_vari.png&#34; alt=&#34;QQplot variance&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/img/posts/BankNotes/figures/qqplot_kurtosis.png&#34; alt=&#34;QQplot kurtosis&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Even though some variables are quite far from normally distributed, the
hypothesis would be acceptable for some model-based learning algorithms using
properties of Gaussian variables.&lt;/p&gt;
&lt;h2 id=&#34;non-parametric-distribution-with-boxplots&#34;&gt;Non-parametric distribution with boxplots&lt;/h2&gt;
&lt;p&gt;Boxplots represent the data using 25th, 50th and 75th percentiles which can be
more robust than mean and variance. The pandas library offers a quick method
and plotting tool to represent boxplots for each class and variable. It
highlights the differences in the spread of the data.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data0&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;groupby(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;class&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;boxplot(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;9&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;))&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://matbesancon.xyz/static/img/posts/BankNotes/figures/Boxplot.png&#34; alt=&#34;Boxplot representation&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;This will be useful in the next part, when the data will be transformed to
enhance the performance and robustness of predictive models.&lt;/p&gt;
&lt;p&gt;So see you in the next part for feature engineering!&lt;/p&gt;
&lt;hr&gt;
&lt;!-- raw HTML omitted --&gt;
</description>
    </item>
    
  </channel>
</rss>
